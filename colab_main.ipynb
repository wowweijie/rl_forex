{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"colab_main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-gi_uVTsR76T"},"source":["# Part 0. Google Colab Set Up"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-SYWCxXR4eM","executionInfo":{"status":"ok","timestamp":1624861405879,"user_tz":-480,"elapsed":16147,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"16e1ddd9-e6c3-41c0-b1fe-109259878222"},"source":["# Mount Google Drive\n","from google.colab import drive\n","\n","ROOT = \"/content/drive\"     \n","print(ROOT)                 \n","\n","drive.mount(ROOT, force_remount=True)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qda7kcwXR93P","executionInfo":{"status":"ok","timestamp":1624861409562,"user_tz":-480,"elapsed":2,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"e2aafd72-c23f-4d1b-d606-7df4dbe5e716"},"source":["% cd /content/drive/MyDrive/rl_forex"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/rl_forex\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWx-tgoqR__c","executionInfo":{"status":"ok","timestamp":1624861410813,"user_tz":-480,"elapsed":3,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"459b475c-e5c9-4694-c1cd-405e3e4f01c4"},"source":["% env PYTHONPATH="],"execution_count":3,"outputs":[{"output_type":"stream","text":["env: PYTHONPATH=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjAjWo6RSBUT","executionInfo":{"status":"ok","timestamp":1624861435721,"user_tz":-480,"elapsed":24910,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"3a71bb0b-884d-4a32-c61b-5116892b9c12"},"source":["%%bash\n","\n","MINICONDA_INSTALLER_SCRIPT=Miniconda3-py37_4.9.2-Linux-x86_64.sh\t\n","MINICONDA_PREFIX=/usr/local\n","chmod +x $MINICONDA_INSTALLER_SCRIPT\n","./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"],"execution_count":4,"outputs":[{"output_type":"stream","text":["PREFIX=/usr/local\n","Unpacking payload ...\n","Collecting package metadata (current_repodata.json): ...working... done\n","Solving environment: ...working... done\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - _libgcc_mutex==0.1=main\n","    - brotlipy==0.7.0=py37h27cfd23_1003\n","    - ca-certificates==2020.10.14=0\n","    - certifi==2020.6.20=pyhd3eb1b0_3\n","    - cffi==1.14.3=py37h261ae71_2\n","    - chardet==3.0.4=py37h06a4308_1003\n","    - conda-package-handling==1.7.2=py37h03888b9_0\n","    - conda==4.9.2=py37h06a4308_0\n","    - cryptography==3.2.1=py37h3c74f83_1\n","    - idna==2.10=py_0\n","    - ld_impl_linux-64==2.33.1=h53a641e_7\n","    - libedit==3.1.20191231=h14c3975_1\n","    - libffi==3.3=he6710b0_2\n","    - libgcc-ng==9.1.0=hdf63c60_0\n","    - libstdcxx-ng==9.1.0=hdf63c60_0\n","    - ncurses==6.2=he6710b0_1\n","    - openssl==1.1.1h=h7b6447c_0\n","    - pip==20.2.4=py37h06a4308_0\n","    - pycosat==0.6.3=py37h27cfd23_0\n","    - pycparser==2.20=py_2\n","    - pyopenssl==19.1.0=pyhd3eb1b0_1\n","    - pysocks==1.7.1=py37_1\n","    - python==3.7.9=h7579374_0\n","    - readline==8.0=h7b6447c_0\n","    - requests==2.24.0=py_0\n","    - ruamel_yaml==0.15.87=py37h7b6447c_1\n","    - setuptools==50.3.1=py37h06a4308_1\n","    - six==1.15.0=py37h06a4308_0\n","    - sqlite==3.33.0=h62c20be_0\n","    - tk==8.6.10=hbc83047_0\n","    - tqdm==4.51.0=pyhd3eb1b0_0\n","    - urllib3==1.25.11=py_0\n","    - wheel==0.35.1=pyhd3eb1b0_0\n","    - xz==5.2.5=h7b6447c_0\n","    - yaml==0.2.5=h7b6447c_0\n","    - zlib==1.2.11=h7b6447c_3\n","\n","\n","The following NEW packages will be INSTALLED:\n","\n","  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n","  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py37h27cfd23_1003\n","  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.10.14-0\n","  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3\n","  cffi               pkgs/main/linux-64::cffi-1.14.3-py37h261ae71_2\n","  chardet            pkgs/main/linux-64::chardet-3.0.4-py37h06a4308_1003\n","  conda              pkgs/main/linux-64::conda-4.9.2-py37h06a4308_0\n","  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.2-py37h03888b9_0\n","  cryptography       pkgs/main/linux-64::cryptography-3.2.1-py37h3c74f83_1\n","  idna               pkgs/main/noarch::idna-2.10-py_0\n","  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n","  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1\n","  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n","  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n","  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n","  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n","  openssl            pkgs/main/linux-64::openssl-1.1.1h-h7b6447c_0\n","  pip                pkgs/main/linux-64::pip-20.2.4-py37h06a4308_0\n","  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h27cfd23_0\n","  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n","  pyopenssl          pkgs/main/noarch::pyopenssl-19.1.0-pyhd3eb1b0_1\n","  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_1\n","  python             pkgs/main/linux-64::python-3.7.9-h7579374_0\n","  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n","  requests           pkgs/main/noarch::requests-2.24.0-py_0\n","  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_1\n","  setuptools         pkgs/main/linux-64::setuptools-50.3.1-py37h06a4308_1\n","  six                pkgs/main/linux-64::six-1.15.0-py37h06a4308_0\n","  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0\n","  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n","  tqdm               pkgs/main/noarch::tqdm-4.51.0-pyhd3eb1b0_0\n","  urllib3            pkgs/main/noarch::urllib3-1.25.11-py_0\n","  wheel              pkgs/main/noarch::wheel-0.35.1-pyhd3eb1b0_0\n","  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n","  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n","  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n","\n","\n","Preparing transaction: ...working... done\n","Executing transaction: ...working... done\n","installation finished.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/36 [00:00<?, ?it/s]\rExtracting : wheel-0.35.1-pyhd3eb1b0_0.conda:   0%|          | 0/36 [00:00<?, ?it/s]\rExtracting : wheel-0.35.1-pyhd3eb1b0_0.conda:   3%|▎         | 1/36 [00:00<00:03,  9.49it/s]\rExtracting : brotlipy-0.7.0-py37h27cfd23_1003.conda:   3%|▎         | 1/36 [00:00<00:03,  9.49it/s]\rExtracting : xz-5.2.5-h7b6447c_0.conda:   6%|▌         | 2/36 [00:00<00:03,  9.49it/s]             \rExtracting : libgcc-ng-9.1.0-hdf63c60_0.conda:   8%|▊         | 3/36 [00:00<00:03,  9.49it/s]\rExtracting : libgcc-ng-9.1.0-hdf63c60_0.conda:  11%|█         | 4/36 [00:00<00:02, 11.32it/s]\rExtracting : pip-20.2.4-py37h06a4308_0.conda:  11%|█         | 4/36 [00:00<00:02, 11.32it/s] \rExtracting : zlib-1.2.11-h7b6447c_3.conda:  14%|█▍        | 5/36 [00:00<00:02, 11.32it/s]   \rExtracting : python-3.7.9-h7579374_0.conda:  17%|█▋        | 6/36 [00:00<00:02, 11.32it/s]\rExtracting : python-3.7.9-h7579374_0.conda:  19%|█▉        | 7/36 [00:00<00:03,  7.39it/s]\rExtracting : requests-2.24.0-py_0.conda:  19%|█▉        | 7/36 [00:00<00:03,  7.39it/s]   \rExtracting : ruamel_yaml-0.15.87-py37h7b6447c_1.conda:  22%|██▏       | 8/36 [00:00<00:03,  7.39it/s]\rExtracting : libstdcxx-ng-9.1.0-hdf63c60_0.conda:  25%|██▌       | 9/36 [00:00<00:03,  7.39it/s]     \rExtracting : libffi-3.3-he6710b0_2.conda:  28%|██▊       | 10/36 [00:00<00:03,  7.39it/s]       \rExtracting : sqlite-3.33.0-h62c20be_0.conda:  31%|███       | 11/36 [00:00<00:03,  7.39it/s]\rExtracting : setuptools-50.3.1-py37h06a4308_1.conda:  33%|███▎      | 12/36 [00:00<00:03,  7.39it/s]\rExtracting : cryptography-3.2.1-py37h3c74f83_1.conda:  36%|███▌      | 13/36 [00:00<00:03,  7.39it/s]\rExtracting : libedit-3.1.20191231-h14c3975_1.conda:  39%|███▉      | 14/36 [00:00<00:02,  7.39it/s]  \rExtracting : urllib3-1.25.11-py_0.conda:  42%|████▏     | 15/36 [00:00<00:02,  7.39it/s]           \rExtracting : tqdm-4.51.0-pyhd3eb1b0_0.conda:  44%|████▍     | 16/36 [00:00<00:02,  7.39it/s]\rExtracting : cffi-1.14.3-py37h261ae71_2.conda:  47%|████▋     | 17/36 [00:00<00:02,  7.39it/s]\rExtracting : yaml-0.2.5-h7b6447c_0.conda:  50%|█████     | 18/36 [00:00<00:02,  7.39it/s]     \rExtracting : ca-certificates-2020.10.14-0.conda:  53%|█████▎    | 19/36 [00:00<00:02,  7.39it/s]\rExtracting : idna-2.10-py_0.conda:  56%|█████▌    | 20/36 [00:00<00:02,  7.39it/s]              \rExtracting : pysocks-1.7.1-py37_1.conda:  58%|█████▊    | 21/36 [00:00<00:02,  7.39it/s]\rExtracting : readline-8.0-h7b6447c_0.conda:  61%|██████    | 22/36 [00:00<00:01,  7.39it/s]\rExtracting : pycosat-0.6.3-py37h27cfd23_0.conda:  64%|██████▍   | 23/36 [00:00<00:01,  7.39it/s]\rExtracting : _libgcc_mutex-0.1-main.conda:  67%|██████▋   | 24/36 [00:00<00:01,  7.39it/s]      \rExtracting : chardet-3.0.4-py37h06a4308_1003.conda:  69%|██████▉   | 25/36 [00:00<00:01,  7.39it/s]\rExtracting : ncurses-6.2-he6710b0_1.conda:  72%|███████▏  | 26/36 [00:01<00:01,  7.39it/s]         \rExtracting : pycparser-2.20-py_2.conda:  75%|███████▌  | 27/36 [00:01<00:01,  7.39it/s]   \rExtracting : pyopenssl-19.1.0-pyhd3eb1b0_1.conda:  78%|███████▊  | 28/36 [00:01<00:01,  7.39it/s]\rExtracting : ld_impl_linux-64-2.33.1-h53a641e_7.conda:  81%|████████  | 29/36 [00:01<00:00,  7.39it/s]\rExtracting : six-1.15.0-py37h06a4308_0.conda:  83%|████████▎ | 30/36 [00:01<00:00,  7.39it/s]         \rExtracting : conda-4.9.2-py37h06a4308_0.conda:  86%|████████▌ | 31/36 [00:01<00:00,  7.39it/s]\rExtracting : conda-package-handling-1.7.2-py37h03888b9_0.conda:  89%|████████▉ | 32/36 [00:01<00:00,  7.39it/s]\rExtracting : tk-8.6.10-hbc83047_0.conda:  92%|█████████▏| 33/36 [00:01<00:00,  7.39it/s]                       \rExtracting : tk-8.6.10-hbc83047_0.conda:  94%|█████████▍| 34/36 [00:01<00:00, 10.30it/s]\rExtracting : openssl-1.1.1h-h7b6447c_0.conda:  94%|█████████▍| 34/36 [00:01<00:00, 10.30it/s]\rExtracting : certifi-2020.6.20-pyhd3eb1b0_3.conda:  97%|█████████▋| 35/36 [00:01<00:00, 10.30it/s]\r                                                                                                  \r"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw-tloqZSCwD","executionInfo":{"status":"ok","timestamp":1624861443229,"user_tz":-480,"elapsed":7515,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"422aa2e2-c249-4743-982b-3acaccf5ad5a"},"source":["%%bash\n","\n","conda install --channel defaults conda=4.9.2 python=3.7 --yes\n","conda config --add channels conda-forge\n","conda config --set channel_priority strict"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting package metadata (current_repodata.json): ...working... done\n","Solving environment: ...working... done\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - conda=4.9.2\n","    - python=3.7\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    ca-certificates-2021.5.25  |       h06a4308_1         112 KB\n","    certifi-2021.5.30          |   py37h06a4308_0         139 KB\n","    openssl-1.1.1k             |       h27cfd23_0         2.5 MB\n","    python-3.7.10              |       hdb3f193_0        45.2 MB\n","    ------------------------------------------------------------\n","                                           Total:        48.0 MB\n","\n","The following packages will be UPDATED:\n","\n","  ca-certificates                              2020.10.14-0 --> 2021.5.25-h06a4308_1\n","  certifi            pkgs/main/noarch::certifi-2020.6.20-p~ --> pkgs/main/linux-64::certifi-2021.5.30-py37h06a4308_0\n","  openssl                                 1.1.1h-h7b6447c_0 --> 1.1.1k-h27cfd23_0\n","  python                                   3.7.9-h7579374_0 --> 3.7.10-hdb3f193_0\n","\n","\n","\n","Downloading and Extracting Packages\n","\rca-certificates-2021 | 112 KB    |            |   0% \rca-certificates-2021 | 112 KB    | ########## | 100% \n","\rcertifi-2021.5.30    | 139 KB    |            |   0% \rcertifi-2021.5.30    | 139 KB    | ########## | 100% \n","\ropenssl-1.1.1k       | 2.5 MB    |            |   0% \ropenssl-1.1.1k       | 2.5 MB    | ########## | 100% \ropenssl-1.1.1k       | 2.5 MB    | ########## | 100% \n","\rpython-3.7.10        | 45.2 MB   |            |   0% \rpython-3.7.10        | 45.2 MB   | #5         |  15% \rpython-3.7.10        | 45.2 MB   | ###4       |  35% \rpython-3.7.10        | 45.2 MB   | #####4     |  55% \rpython-3.7.10        | 45.2 MB   | #######5   |  75% \rpython-3.7.10        | 45.2 MB   | #########6 |  96% \rpython-3.7.10        | 45.2 MB   | ########## | 100% \n","Preparing transaction: ...working... done\n","Verifying transaction: ...working... done\n","Executing transaction: ...working... done\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 4.9.2\n","  latest version: 4.10.1\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c defaults conda\n","\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZibHI9-SHPY","executionInfo":{"status":"ok","timestamp":1624861625395,"user_tz":-480,"elapsed":182173,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}},"outputId":"47d47c23-4d22-4769-b1b5-8f0942d2fc11"},"source":["%%bash\n","\n","conda env create -f environment.yml"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting package metadata (repodata.json): ...working... done\n","Solving environment: ...working... done\n","\n","Downloading and Extracting Packages\n","\rlibgomp-9.3.0        | 311 KB    |            |   0% \rlibgomp-9.3.0        | 311 KB    | ########## | 100% \rlibgomp-9.3.0        | 311 KB    | ########## | 100% \n","\rqtpy-1.9.0           | 38 KB     |            |   0% \rqtpy-1.9.0           | 38 KB     | ########## | 100% \rqtpy-1.9.0           | 38 KB     | ########## | 100% \n","\ripython_genutils-0.2 | 27 KB     |            |   0% \ripython_genutils-0.2 | 27 KB     | ########## | 100% \n","\rlibvpx-1.7.0         | 1.2 MB    |            |   0% \rlibvpx-1.7.0         | 1.2 MB    | ########## | 100% \rlibvpx-1.7.0         | 1.2 MB    | ########## | 100% \n","\rld_impl_linux-64-2.3 | 586 KB    |            |   0% \rld_impl_linux-64-2.3 | 586 KB    | ########## | 100% \rld_impl_linux-64-2.3 | 586 KB    | ########## | 100% \n","\rglib-2.68.2          | 3.0 MB    |            |   0% \rglib-2.68.2          | 3.0 MB    | ########## | 100% \rglib-2.68.2          | 3.0 MB    | ########## | 100% \n","\rtyping-extensions-3. | 12 KB     |            |   0% \rtyping-extensions-3. | 12 KB     | ########## | 100% \n","\rmatplotlib-base-3.3. | 5.1 MB    |            |   0% \rmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \rmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \n","\rpandas-1.2.5         | 8.5 MB    |            |   0% \rpandas-1.2.5         | 8.5 MB    | ########## | 100% \rpandas-1.2.5         | 8.5 MB    | ########## | 100% \n","\rlibstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \rlibstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \rlibstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n","\rpcre-8.45            | 207 KB    |            |   0% \rpcre-8.45            | 207 KB    | ########## | 100% \rpcre-8.45            | 207 KB    | ########## | 100% \n","\rnettle-3.7.3         | 809 KB    |            |   0% \rnettle-3.7.3         | 809 KB    | ########## | 100% \rnettle-3.7.3         | 809 KB    | ########## | 100% \n","\rgstreamer-1.14.0     | 3.2 MB    |            |   0% \rgstreamer-1.14.0     | 3.2 MB    | ########## | 100% \rgstreamer-1.14.0     | 3.2 MB    | ########## | 100% \n","\rsip-4.19.8           | 274 KB    |            |   0% \rsip-4.19.8           | 274 KB    | ########## | 100% \rsip-4.19.8           | 274 KB    | ########## | 100% \n","\rzipp-3.4.1           | 15 KB     |            |   0% \rzipp-3.4.1           | 15 KB     | ########## | 100% \n","\rpyqt-5.9.2           | 4.5 MB    |            |   0% \rpyqt-5.9.2           | 4.5 MB    | ########## | 100% \rpyqt-5.9.2           | 4.5 MB    | ########## | 100% \n","\rlibopenblas-0.3.13   | 4.8 MB    |            |   0% \rlibopenblas-0.3.13   | 4.8 MB    | ########## | 100% \rlibopenblas-0.3.13   | 4.8 MB    | ########## | 100% \n","\rchardet-4.0.0        | 195 KB    |            |   0% \rchardet-4.0.0        | 195 KB    | ########## | 100% \rchardet-4.0.0        | 195 KB    | ########## | 100% \n","\rsetuptools-52.0.0    | 710 KB    |            |   0% \rsetuptools-52.0.0    | 710 KB    | ########## | 100% \rsetuptools-52.0.0    | 710 KB    | ########## | 100% \n","\rpytz-2021.1          | 181 KB    |            |   0% \rpytz-2021.1          | 181 KB    | ########## | 100% \rpytz-2021.1          | 181 KB    | ########## | 100% \n","\rterminado-0.9.4      | 25 KB     |            |   0% \rterminado-0.9.4      | 25 KB     | ########## | 100% \rterminado-0.9.4      | 25 KB     | ########## | 100% \n","\rurllib3-1.26.4       | 105 KB    |            |   0% \rurllib3-1.26.4       | 105 KB    | ########## | 100% \rurllib3-1.26.4       | 105 KB    | ########## | 100% \n","\rasync_generator-1.10 | 39 KB     |            |   0% \rasync_generator-1.10 | 39 KB     | ########## | 100% \rasync_generator-1.10 | 39 KB     | ########## | 100% \n","\rtestpath-0.5.0       | 81 KB     |            |   0% \rtestpath-0.5.0       | 81 KB     | ########## | 100% \rtestpath-0.5.0       | 81 KB     | ########## | 100% \n","\rgnutls-3.6.15        | 1.0 MB    |            |   0% \rgnutls-3.6.15        | 1.0 MB    | ########## | 100% \rgnutls-3.6.15        | 1.0 MB    | ########## | 100% \n","\rparso-0.8.2          | 69 KB     |            |   0% \rparso-0.8.2          | 69 KB     | ########## | 100% \rparso-0.8.2          | 69 KB     | ########## | 100% \n","\rmsgpack-python-1.0.2 | 81 KB     |            |   0% \rmsgpack-python-1.0.2 | 81 KB     | ########## | 100% \n","\rbzip2-1.0.8          | 78 KB     |            |   0% \rbzip2-1.0.8          | 78 KB     | ########## | 100% \rbzip2-1.0.8          | 78 KB     | ########## | 100% \n","\rpyparsing-2.4.7      | 59 KB     |            |   0% \rpyparsing-2.4.7      | 59 KB     | ########## | 100% \n","\rlibuuid-1.0.3        | 15 KB     |            |   0% \rlibuuid-1.0.3        | 15 KB     | ########## | 100% \rlibuuid-1.0.3        | 15 KB     | ########## | 100% \n","\rjupyter_core-4.7.1   | 68 KB     |            |   0% \rjupyter_core-4.7.1   | 68 KB     | ########## | 100% \rjupyter_core-4.7.1   | 68 KB     | ########## | 100% \n","\rgym-0.18.0           | 1.9 MB    |            |   0% \rgym-0.18.0           | 1.9 MB    |            |   1% \rgym-0.18.0           | 1.9 MB    | 5          |   6% \rgym-0.18.0           | 1.9 MB    | 9          |   9% \rgym-0.18.0           | 1.9 MB    | #5         |  16% \rgym-0.18.0           | 1.9 MB    | ##9        |  29% \rgym-0.18.0           | 1.9 MB    | ####1      |  41% \rgym-0.18.0           | 1.9 MB    | #####7     |  58% \rgym-0.18.0           | 1.9 MB    | ########1  |  81% \rgym-0.18.0           | 1.9 MB    | ########## | 100% \rgym-0.18.0           | 1.9 MB    | ########## | 100% \n","\rwcwidth-0.2.5        | 29 KB     |            |   0% \rwcwidth-0.2.5        | 29 KB     | ########## | 100% \n","\rpython-dateutil-2.8. | 221 KB    |            |   0% \rpython-dateutil-2.8. | 221 KB    | ########## | 100% \n","\rnbformat-5.1.3       | 44 KB     |            |   0% \rnbformat-5.1.3       | 44 KB     | ########## | 100% \rnbformat-5.1.3       | 44 KB     | ########## | 100% \n","\rprometheus_client-0. | 47 KB     |            |   0% \rprometheus_client-0. | 47 KB     | ########## | 100% \rprometheus_client-0. | 47 KB     | ########## | 100% \n","\rzeromq-4.3.4         | 331 KB    |            |   0% \rzeromq-4.3.4         | 331 KB    | ########## | 100% \rzeromq-4.3.4         | 331 KB    | ########## | 100% \n","\rjupyter_console-6.4. | 23 KB     |            |   0% \rjupyter_console-6.4. | 23 KB     | ########## | 100% \n","\rtyped-ast-1.4.2      | 185 KB    |            |   0% \rtyped-ast-1.4.2      | 185 KB    | ########## | 100% \rtyped-ast-1.4.2      | 185 KB    | ########## | 100% \n","\rblas-1.0             | 46 KB     |            |   0% \rblas-1.0             | 46 KB     | ########## | 100% \n","\rjinja2-3.0.1         | 110 KB    |            |   0% \rjinja2-3.0.1         | 110 KB    | ########## | 100% \n","\rpandocfilters-1.4.3  | 14 KB     |            |   0% \rpandocfilters-1.4.3  | 14 KB     | ########## | 100% \rpandocfilters-1.4.3  | 14 KB     | ########## | 100% \n","\rbleach-3.3.0         | 113 KB    |            |   0% \rbleach-3.3.0         | 113 KB    | ########## | 100% \n","\rpackaging-20.9       | 37 KB     |            |   0% \rpackaging-20.9       | 37 KB     | ########## | 100% \rpackaging-20.9       | 37 KB     | ########## | 100% \n","\rkiwisolver-1.3.1     | 80 KB     |            |   0% \rkiwisolver-1.3.1     | 80 KB     | ########## | 100% \n","\rjsonschema-3.2.0     | 47 KB     |            |   0% \rjsonschema-3.2.0     | 47 KB     | ########## | 100% \n","\rx264-1!157.20191217  | 922 KB    |            |   0% \rx264-1!157.20191217  | 922 KB    | ########## | 100% \rx264-1!157.20191217  | 922 KB    | ########## | 100% \n","\rjupyter_client-6.1.1 | 88 KB     |            |   0% \rjupyter_client-6.1.1 | 88 KB     | ########## | 100% \rjupyter_client-6.1.1 | 88 KB     | ########## | 100% \n","\rwheel-0.36.2         | 33 KB     |            |   0% \rwheel-0.36.2         | 33 KB     | ########## | 100% \n","\rlz4-c-1.9.3          | 186 KB    |            |   0% \rlz4-c-1.9.3          | 186 KB    | ########## | 100% \rlz4-c-1.9.3          | 186 KB    | ########## | 100% \n","\rbackcall-0.2.0       | 13 KB     |            |   0% \rbackcall-0.2.0       | 13 KB     | ########## | 100% \n","\rqtconsole-5.1.0      | 98 KB     |            |   0% \rqtconsole-5.1.0      | 98 KB     | ########## | 100% \rqtconsole-5.1.0      | 98 KB     | ########## | 100% \n","\ripywidgets-7.6.3     | 105 KB    |            |   0% \ripywidgets-7.6.3     | 105 KB    | ########## | 100% \ripywidgets-7.6.3     | 105 KB    | ########## | 100% \n","\rlibopus-1.3.1        | 491 KB    |            |   0% \rlibopus-1.3.1        | 491 KB    | ########## | 100% \rlibopus-1.3.1        | 491 KB    | ########## | 100% \n","\rzstd-1.4.9           | 480 KB    |            |   0% \rzstd-1.4.9           | 480 KB    | ########## | 100% \rzstd-1.4.9           | 480 KB    | ########## | 100% \n","\ridna-2.10            | 52 KB     |            |   0% \ridna-2.10            | 52 KB     | ########## | 100% \n","\rjpeg-9b              | 214 KB    |            |   0% \rjpeg-9b              | 214 KB    | ########## | 100% \rjpeg-9b              | 214 KB    | ########## | 100% \n","\rpygments-2.9.0       | 721 KB    |            |   0% \rpygments-2.9.0       | 721 KB    | ########## | 100% \rpygments-2.9.0       | 721 KB    | ########## | 100% \n","\rflake8-3.9.2         | 129 KB    |            |   0% \rflake8-3.9.2         | 129 KB    | ########## | 100% \rflake8-3.9.2         | 129 KB    | ########## | 100% \n","\rlazy-object-proxy-1. | 30 KB     |            |   0% \rlazy-object-proxy-1. | 30 KB     | ########## | 100% \n","\rpython_abi-3.7       | 4 KB      |            |   0% \rpython_abi-3.7       | 4 KB      | ########## | 100% \n","\rcycler-0.10.0        | 13 KB     |            |   0% \rcycler-0.10.0        | 13 KB     | ########## | 100% \rcycler-0.10.0        | 13 KB     | ########## | 100% \n","\rlibtiff-4.2.0        | 502 KB    |            |   0% \rlibtiff-4.2.0        | 502 KB    | ########## | 100% \rlibtiff-4.2.0        | 502 KB    | ########## | 100% \n","\rattrs-21.2.0         | 46 KB     |            |   0% \rattrs-21.2.0         | 46 KB     | ########## | 100% \n","\rmarkupsafe-2.0.1     | 21 KB     |            |   0% \rmarkupsafe-2.0.1     | 21 KB     | ########## | 100% \n","\rgmp-6.2.1            | 539 KB    |            |   0% \rgmp-6.2.1            | 539 KB    | ########## | 100% \rgmp-6.2.1            | 539 KB    | ########## | 100% \n","\rfontconfig-2.13.1    | 250 KB    |            |   0% \rfontconfig-2.13.1    | 250 KB    | ########## | 100% \rfontconfig-2.13.1    | 250 KB    | ########## | 100% \n","\rnbconvert-6.1.0      | 483 KB    |            |   0% \rnbconvert-6.1.0      | 483 KB    | ########## | 100% \rnbconvert-6.1.0      | 483 KB    | ########## | 100% \n","\rnbclient-0.5.3       | 62 KB     |            |   0% \rnbclient-0.5.3       | 62 KB     | ########## | 100% \rnbclient-0.5.3       | 62 KB     | ########## | 100% \n","\rolefile-0.46         | 50 KB     |            |   0% \rolefile-0.46         | 50 KB     | ########## | 100% \n","\rpyaml-20.4.0         | 19 KB     |            |   0% \rpyaml-20.4.0         | 19 KB     | ########6  |  86% \rpyaml-20.4.0         | 19 KB     | ########## | 100% \n","\rpyzmq-20.0.0         | 439 KB    |            |   0% \rpyzmq-20.0.0         | 439 KB    | ########## | 100% \rpyzmq-20.0.0         | 439 KB    | ########## | 100% \n","\rprompt-toolkit-3.0.1 | 256 KB    |            |   0% \rprompt-toolkit-3.0.1 | 256 KB    | ########## | 100% \rprompt-toolkit-3.0.1 | 256 KB    | ########## | 100% \n","\rlibxml2-2.9.12       | 1.2 MB    |            |   0% \rlibxml2-2.9.12       | 1.2 MB    | ########## | 100% \rlibxml2-2.9.12       | 1.2 MB    | ########## | 100% \n","\rscipy-1.5.2          | 14.3 MB   |            |   0% \rscipy-1.5.2          | 14.3 MB   |            |   0% \rscipy-1.5.2          | 14.3 MB   | 2          |   2% \rscipy-1.5.2          | 14.3 MB   | 4          |   4% \rscipy-1.5.2          | 14.3 MB   | 6          |   6% \rscipy-1.5.2          | 14.3 MB   | 8          |   8% \rscipy-1.5.2          | 14.3 MB   | #3         |  13% \rscipy-1.5.2          | 14.3 MB   | #7         |  18% \rscipy-1.5.2          | 14.3 MB   | ##3        |  24% \rscipy-1.5.2          | 14.3 MB   | ##9        |  30% \rscipy-1.5.2          | 14.3 MB   | ###4       |  35% \rscipy-1.5.2          | 14.3 MB   | ####2      |  42% \rscipy-1.5.2          | 14.3 MB   | ####7      |  48% \rscipy-1.5.2          | 14.3 MB   | #####4     |  54% \rscipy-1.5.2          | 14.3 MB   | #####9     |  60% \rscipy-1.5.2          | 14.3 MB   | ######5    |  65% \rscipy-1.5.2          | 14.3 MB   | #######1   |  72% \rscipy-1.5.2          | 14.3 MB   | #######7   |  78% \rscipy-1.5.2          | 14.3 MB   | ########4  |  84% \rscipy-1.5.2          | 14.3 MB   | ########9  |  90% \rscipy-1.5.2          | 14.3 MB   | #########6 |  97% \rscipy-1.5.2          | 14.3 MB   | ########## | 100% \n","\rlibta-lib-0.4.0      | 503 KB    |            |   0% \rlibta-lib-0.4.0      | 503 KB    | ########## | 100% \rlibta-lib-0.4.0      | 503 KB    | ########## | 100% \n","\rmistune-0.8.4        | 54 KB     |            |   0% \rmistune-0.8.4        | 54 KB     | ########## | 100% \rmistune-0.8.4        | 54 KB     | ########## | 100% \n","\rlibgcc-ng-9.3.0      | 4.8 MB    |            |   0% \rlibgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \rlibgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n","\rsend2trash-1.5.0     | 14 KB     |            |   0% \rsend2trash-1.5.0     | 14 KB     | ########## | 100% \rsend2trash-1.5.0     | 14 KB     | ########## | 100% \n","\rlame-3.100           | 323 KB    |            |   0% \rlame-3.100           | 323 KB    | ########## | 100% \rlame-3.100           | 323 KB    | ########## | 100% \n","\rcloudpickle-1.6.0    | 30 KB     |            |   0% \rcloudpickle-1.6.0    | 30 KB     | ########## | 100% \rcloudpickle-1.6.0    | 30 KB     | ########## | 100% \n","\ripython-7.22.0       | 992 KB    |            |   0% \ripython-7.22.0       | 992 KB    | ########## | 100% \ripython-7.22.0       | 992 KB    | ########## | 100% \n","\rlibidn2-2.3.1        | 85 KB     |            |   0% \rlibidn2-2.3.1        | 85 KB     | ########## | 100% \n","\rcryptography-3.4.7   | 904 KB    |            |   0% \rcryptography-3.4.7   | 904 KB    | ########## | 100% \rcryptography-3.4.7   | 904 KB    | ########## | 100% \n","\rimportlib_metadata-3 | 11 KB     |            |   0% \rimportlib_metadata-3 | 11 KB     | ########## | 100% \n","\rjoblib-1.0.1         | 208 KB    |            |   0% \rjoblib-1.0.1         | 208 KB    | ########## | 100% \rjoblib-1.0.1         | 208 KB    | ########## | 100% \n","\rfreetype-2.10.4      | 596 KB    |            |   0% \rfreetype-2.10.4      | 596 KB    | ########## | 100% \rfreetype-2.10.4      | 596 KB    | ########## | 100% \n","\rpyyaml-5.4.1         | 168 KB    |            |   0% \rpyyaml-5.4.1         | 168 KB    | ########## | 100% \rpyyaml-5.4.1         | 168 KB    | ########## | 100% \n","\rqt-5.9.7             | 68.5 MB   |            |   0% \rqt-5.9.7             | 68.5 MB   | 8          |   9% \rqt-5.9.7             | 68.5 MB   | ##         |  20% \rqt-5.9.7             | 68.5 MB   | ###1       |  32% \rqt-5.9.7             | 68.5 MB   | ####3      |  44% \rqt-5.9.7             | 68.5 MB   | #####7     |  57% \rqt-5.9.7             | 68.5 MB   | #######    |  71% \rqt-5.9.7             | 68.5 MB   | ########4  |  85% \rqt-5.9.7             | 68.5 MB   | ########## | 100% \rqt-5.9.7             | 68.5 MB   | ########## | 100% \n","\rwidgetsnbextension-3 | 862 KB    |            |   0% \rwidgetsnbextension-3 | 862 KB    | ########## | 100% \rwidgetsnbextension-3 | 862 KB    | ########## | 100% \n","\rjedi-0.17.0          | 775 KB    |            |   0% \rjedi-0.17.0          | 775 KB    | ########## | 100% \rjedi-0.17.0          | 775 KB    | ########## | 100% \n","\rjupyterlab_widgets-1 | 109 KB    |            |   0% \rjupyterlab_widgets-1 | 109 KB    | ########## | 100% \rjupyterlab_widgets-1 | 109 KB    | ########## | 100% \n","\rptyprocess-0.7.0     | 17 KB     |            |   0% \rptyprocess-0.7.0     | 17 KB     | ########## | 100% \rptyprocess-0.7.0     | 17 KB     | ########## | 100% \n","\rta-lib-0.4.19        | 407 KB    |            |   0% \rta-lib-0.4.19        | 407 KB    | ########## | 100% \n","\rtyping_extensions-3. | 28 KB     |            |   0% \rtyping_extensions-3. | 28 KB     | ########## | 100% \rtyping_extensions-3. | 28 KB     | ########## | 100% \n","\rreadline-8.1         | 362 KB    |            |   0% \rreadline-8.1         | 362 KB    | ########## | 100% \rreadline-8.1         | 362 KB    | ########## | 100% \n","\rdbus-1.13.18         | 504 KB    |            |   0% \rdbus-1.13.18         | 504 KB    | ########## | 100% \rdbus-1.13.18         | 504 KB    | ########## | 100% \n","\rpip-21.0.1           | 1.8 MB    |            |   0% \rpip-21.0.1           | 1.8 MB    | ########## | 100% \rpip-21.0.1           | 1.8 MB    | ########## | 100% \n","\rjupyter-1.0.0        | 6 KB      |            |   0% \rjupyter-1.0.0        | 6 KB      | ########## | 100% \n","\rtoml-0.10.2          | 20 KB     |            |   0% \rtoml-0.10.2          | 20 KB     | ########## | 100% \n","\rbayesian-optimizatio | 12 KB     |            |   0% \rbayesian-optimizatio | 12 KB     | ########## | 100% \rbayesian-optimizatio | 12 KB     | ########## | 100% \n","\rfuture-0.18.2        | 631 KB    |            |   0% \rfuture-0.18.2        | 631 KB    | ########## | 100% \rfuture-0.18.2        | 631 KB    | ########## | 100% \n","\rscikit-learn-0.22.1  | 5.3 MB    |            |   0% \rscikit-learn-0.22.1  | 5.3 MB    |            |   0% \rscikit-learn-0.22.1  | 5.3 MB    | 2          |   2% \rscikit-learn-0.22.1  | 5.3 MB    | 5          |   5% \rscikit-learn-0.22.1  | 5.3 MB    | 7          |   8% \rscikit-learn-0.22.1  | 5.3 MB    | #2         |  12% \rscikit-learn-0.22.1  | 5.3 MB    | #6         |  17% \rscikit-learn-0.22.1  | 5.3 MB    | ##3        |  23% \rscikit-learn-0.22.1  | 5.3 MB    | ###3       |  34% \rscikit-learn-0.22.1  | 5.3 MB    | ####5      |  45% \rscikit-learn-0.22.1  | 5.3 MB    | ######     |  61% \rscikit-learn-0.22.1  | 5.3 MB    | #######8   |  78% \rscikit-learn-0.22.1  | 5.3 MB    | #########1 |  92% \rscikit-learn-0.22.1  | 5.3 MB    | ########## | 100% \n","\ripykernel-5.3.4      | 179 KB    |            |   0% \ripykernel-5.3.4      | 179 KB    | ########## | 100% \ripykernel-5.3.4      | 179 KB    | ########## | 100% \n","\rentrypoints-0.3      | 12 KB     |            |   0% \rentrypoints-0.3      | 12 KB     | ########## | 100% \n","\rdefusedxml-0.7.1     | 23 KB     |            |   0% \rdefusedxml-0.7.1     | 23 KB     | ########## | 100% \n","\rprompt_toolkit-3.0.1 | 12 KB     |            |   0% \rprompt_toolkit-3.0.1 | 12 KB     | ########## | 100% \rprompt_toolkit-3.0.1 | 12 KB     | ########## | 100% \n","\rmatplotlib-3.3.4     | 26 KB     |            |   0% \rmatplotlib-3.3.4     | 26 KB     | ########## | 100% \n","\rpyopenssl-20.0.1     | 49 KB     |            |   0% \rpyopenssl-20.0.1     | 49 KB     | ########## | 100% \rpyopenssl-20.0.1     | 49 KB     | ########## | 100% \n","\rjupyterlab_pygments- | 8 KB      |            |   0% \rjupyterlab_pygments- | 8 KB      | ########## | 100% \rjupyterlab_pygments- | 8 KB      | ########## | 100% \n","\rlibsodium-1.0.18     | 244 KB    |            |   0% \rlibsodium-1.0.18     | 244 KB    | ########## | 100% \rlibsodium-1.0.18     | 244 KB    | ########## | 100% \n","\rmccabe-0.6.1         | 14 KB     |            |   0% \rmccabe-0.6.1         | 14 KB     | ########## | 100% \rmccabe-0.6.1         | 14 KB     | ########## | 100% \n","\rlibpng-1.6.37        | 278 KB    |            |   0% \rlibpng-1.6.37        | 278 KB    | ########## | 100% \n","\ricu-58.2             | 10.5 MB   |            |   0% \ricu-58.2             | 10.5 MB   | #######5   |  75% \ricu-58.2             | 10.5 MB   | ########## | 100% \ricu-58.2             | 10.5 MB   | ########## | 100% \n","\rpexpect-4.8.0        | 53 KB     |            |   0% \rpexpect-4.8.0        | 53 KB     | ########## | 100% \rpexpect-4.8.0        | 53 KB     | ########## | 100% \n","\rlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \rlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n","\rwebencodings-0.5.1   | 19 KB     |            |   0% \rwebencodings-0.5.1   | 19 KB     | ########## | 100% \n","\rffmpeg-4.2.2         | 59.6 MB   |            |   0% \rffmpeg-4.2.2         | 59.6 MB   | #5         |  15% \rffmpeg-4.2.2         | 59.6 MB   | ###4       |  34% \rffmpeg-4.2.2         | 59.6 MB   | #####3     |  54% \rffmpeg-4.2.2         | 59.6 MB   | #######3   |  73% \rffmpeg-4.2.2         | 59.6 MB   | #########1 |  92% \rffmpeg-4.2.2         | 59.6 MB   | ########## | 100% \n","\rlibwebp-base-1.2.0   | 437 KB    |            |   0% \rlibwebp-base-1.2.0   | 437 KB    | ########## | 100% \rlibwebp-base-1.2.0   | 437 KB    | ########## | 100% \n","\rpillow-8.2.0         | 622 KB    |            |   0% \rpillow-8.2.0         | 622 KB    | ########## | 100% \rpillow-8.2.0         | 622 KB    | ########## | 100% \n","\rpyglet-1.5.16        | 1.5 MB    |            |   0% \rpyglet-1.5.16        | 1.5 MB    | 1          |   1% \rpyglet-1.5.16        | 1.5 MB    | ########## | 100% \rpyglet-1.5.16        | 1.5 MB    | ########## | 100% \n","\rlibxcb-1.14          | 505 KB    |            |   0% \rlibxcb-1.14          | 505 KB    | ########## | 100% \rlibxcb-1.14          | 505 KB    | ########## | 100% \n","\rexpat-2.4.1          | 168 KB    |            |   0% \rexpat-2.4.1          | 168 KB    | ########## | 100% \rexpat-2.4.1          | 168 KB    | ########## | 100% \n","\rscikit-optimize-0.8. | 74 KB     |            |   0% \rscikit-optimize-0.8. | 74 KB     | ########## | 100% \n","\rargon2-cffi-20.1.0   | 46 KB     |            |   0% \rargon2-cffi-20.1.0   | 46 KB     | ########## | 100% \rargon2-cffi-20.1.0   | 46 KB     | ########## | 100% \n","\rastroid-2.6.0        | 307 KB    |            |   0% \rastroid-2.6.0        | 307 KB    | ########## | 100% \rastroid-2.6.0        | 307 KB    | ########## | 100% \n","\rgst-plugins-base-1.1 | 4.9 MB    |            |   0% \rgst-plugins-base-1.1 | 4.9 MB    | ########## | 100% \rgst-plugins-base-1.1 | 4.9 MB    | ########## | 100% \n","\rtraitlets-5.0.5      | 81 KB     |            |   0% \rtraitlets-5.0.5      | 81 KB     | ########## | 100% \n","\rpylint-2.8.3         | 469 KB    |            |   0% \rpylint-2.8.3         | 469 KB    | ########## | 100% \rpylint-2.8.3         | 469 KB    | ########## | 100% \n","\rtornado-6.1          | 589 KB    |            |   0% \rtornado-6.1          | 589 KB    | ########## | 100% \rtornado-6.1          | 589 KB    | ########## | 100% \n","\rpyflakes-2.3.1       | 60 KB     |            |   0% \rpyflakes-2.3.1       | 60 KB     | ########## | 100% \rpyflakes-2.3.1       | 60 KB     | ########## | 100% \n","\ropenh264-2.1.0       | 722 KB    |            |   0% \ropenh264-2.1.0       | 722 KB    | ########## | 100% \ropenh264-2.1.0       | 722 KB    | ########## | 100% \n","\rpycodestyle-2.7.0    | 41 KB     |            |   0% \rpycodestyle-2.7.0    | 41 KB     | ########## | 100% \rpycodestyle-2.7.0    | 41 KB     | ########## | 100% \n","\rimportlib-metadata-3 | 33 KB     |            |   0% \rimportlib-metadata-3 | 33 KB     | ########## | 100% \n","\rinfluxdb-5.3.1       | 54 KB     |            |   0% \rinfluxdb-5.3.1       | 54 KB     | ########## | 100% \n","\rsqlite-3.36.0        | 990 KB    |            |   0% \rsqlite-3.36.0        | 990 KB    | ########## | 100% \rsqlite-3.36.0        | 990 KB    | ########## | 100% \n","\rlibunistring-0.9.10  | 536 KB    |            |   0% \rlibunistring-0.9.10  | 536 KB    | ########## | 100% \rlibunistring-0.9.10  | 536 KB    | ########## | 100% \n","\rnest-asyncio-1.5.1   | 10 KB     |            |   0% \rnest-asyncio-1.5.1   | 10 KB     | ########## | 100% \n","\risort-5.9.1          | 83 KB     |            |   0% \risort-5.9.1          | 83 KB     | ########## | 100% \risort-5.9.1          | 83 KB     | ########## | 100% \n","\rdecorator-5.0.9      | 12 KB     |            |   0% \rdecorator-5.0.9      | 12 KB     | ########## | 100% \rdecorator-5.0.9      | 12 KB     | ########## | 100% \n","\rlcms2-2.12           | 312 KB    |            |   0% \rlcms2-2.12           | 312 KB    | ########## | 100% \rlcms2-2.12           | 312 KB    | ########## | 100% \n","\rpickleshare-0.7.5    | 13 KB     |            |   0% \rpickleshare-0.7.5    | 13 KB     | ########## | 100% \n","\rcffi-1.14.5          | 224 KB    |            |   0% \rcffi-1.14.5          | 224 KB    | ########## | 100% \rcffi-1.14.5          | 224 KB    | ########## | 100% \n","\rwrapt-1.12.1         | 49 KB     |            |   0% \rwrapt-1.12.1         | 49 KB     | ########## | 100% \rwrapt-1.12.1         | 49 KB     | ########## | 100% \n","\rlibtasn1-4.16.0      | 58 KB     |            |   0% \rlibtasn1-4.16.0      | 58 KB     | ########## | 100% \rlibtasn1-4.16.0      | 58 KB     | ########## | 100% \n","\r_openmp_mutex-4.5    | 22 KB     |            |   0% \r_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n","\rnumpy-base-1.20.2    | 4.5 MB    |            |   0% \rnumpy-base-1.20.2    | 4.5 MB    |            |   0% \rnumpy-base-1.20.2    | 4.5 MB    | 7          |   7% \rnumpy-base-1.20.2    | 4.5 MB    | #1         |  11% \rnumpy-base-1.20.2    | 4.5 MB    | #8         |  18% \rnumpy-base-1.20.2    | 4.5 MB    | ##5        |  25% \rnumpy-base-1.20.2    | 4.5 MB    | ###8       |  39% \rnumpy-base-1.20.2    | 4.5 MB    | #####3     |  54% \rnumpy-base-1.20.2    | 4.5 MB    | #######2   |  73% \rnumpy-base-1.20.2    | 4.5 MB    | #########2 |  92% \rnumpy-base-1.20.2    | 4.5 MB    | ########## | 100% \n","\rnumpy-1.20.2         | 23 KB     |            |   0% \rnumpy-1.20.2         | 23 KB     | #######    |  70% \rnumpy-1.20.2         | 23 KB     | ########## | 100% \rnumpy-1.20.2         | 23 KB     | ########## | 100% \n","\rnotebook-6.4.0       | 4.1 MB    |            |   0% \rnotebook-6.4.0       | 4.1 MB    | ########## | 100% \rnotebook-6.4.0       | 4.1 MB    | ########## | 100% \n","\rstrict-rfc3339-0.7   | 22 KB     |            |   0% \rstrict-rfc3339-0.7   | 22 KB     | #######2   |  72% \rstrict-rfc3339-0.7   | 22 KB     | ########## | 100% \n","\rlibgfortran4-7.5.0   | 995 KB    |            |   0% \rlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \rlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n","\rpyrsistent-0.17.3    | 89 KB     |            |   0% \rpyrsistent-0.17.3    | 89 KB     | ########## | 100% \rpyrsistent-0.17.3    | 89 KB     | ########## | 100% \n","\rsix-1.16.0           | 18 KB     |            |   0% \rsix-1.16.0           | 18 KB     | ########## | 100% \rsix-1.16.0           | 18 KB     | ########## | 100% \n","\rrequests-2.25.1      | 52 KB     |            |   0% \rrequests-2.25.1      | 52 KB     | ########## | 100% \rrequests-2.25.1      | 52 KB     | ########## | 100% \n","Preparing transaction: ...working... done\n","Verifying transaction: ...working... done\n","Executing transaction: ...working... done\n","Installing pip dependencies: ...working... Ran pip subprocess with arguments:\n","['/usr/local/envs/rl_fx/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt']\n","Pip subprocess output:\n","Collecting stable-baselines==2.10.2\n","  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n","Collecting stable-baselines3==0.10.0\n","  Downloading stable_baselines3-0.10.0-py3-none-any.whl (145 kB)\n","Collecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from -r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 4)) (3.7.4.3)\n","Collecting pyfolio==0.9.2\n","  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n","Collecting yfinance==0.1.55\n","  Downloading yfinance-0.1.55.tar.gz (23 kB)\n","Collecting plotext==2.3.1\n","  Downloading plotext-2.3.1-py3-none-any.whl (16 kB)\n","Collecting tensorflow==1.15.0\n","  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n","Collecting empyrical==0.5.5\n","  Downloading empyrical-0.5.5.tar.gz (52 kB)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from empyrical==0.5.5->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 9)) (1.20.2)\n","Requirement already satisfied: pandas>=0.16.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from empyrical==0.5.5->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 9)) (1.2.5)\n","Requirement already satisfied: scipy>=0.15.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from empyrical==0.5.5->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 9)) (1.5.2)\n","Collecting pandas-datareader>=0.2\n","  Downloading pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n","Requirement already satisfied: ipython>=3.2.3 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (7.22.0)\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (3.3.4)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (2021.1)\n","Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.22.1)\n","Collecting seaborn>=0.7.1\n","  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n","Requirement already satisfied: joblib in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from stable-baselines==2.10.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from stable-baselines==2.10.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 1)) (1.6.0)\n","Collecting opencv-python\n","  Downloading opencv_python-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (51.0 MB)\n","Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from stable-baselines==2.10.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 1)) (0.18.0)\n","Collecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","Collecting google-pasta>=0.1.6\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from tensorflow==1.15.0->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 8)) (0.36.2)\n","Collecting grpcio>=1.8.6\n","  Downloading grpcio-1.38.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from tensorflow==1.15.0->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 8)) (1.12.1)\n","Collecting protobuf>=3.6.1\n","  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","Collecting astor>=0.6.0\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting keras-preprocessing>=1.0.5\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from tensorflow==1.15.0->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 8)) (1.16.0)\n","Collecting absl-py>=0.7.0\n","  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from yfinance==0.1.55->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 6)) (2.25.1)\n","Collecting multitasking>=0.0.7\n","  Downloading multitasking-0.0.9.tar.gz (8.1 kB)\n","Collecting lxml>=4.5.1\n","  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n","Collecting atari-py~=0.2.0\n","  Downloading atari_py-0.2.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (5.0.9)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.17.0)\n","Requirement already satisfied: pickleshare in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (52.0.0.post20210125)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (5.0.5)\n","Requirement already satisfied: pygments in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (2.9.0)\n","Requirement already satisfied: backcall in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (3.0.17)\n","Requirement already satisfied: parso>=0.7.0 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.8.2)\n","Collecting h5py\n","  Downloading h5py-3.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (2.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (8.2.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.2.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.55->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 6)) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.55->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.55->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 6)) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from requests>=2.20->yfinance==0.1.55->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 6)) (1.26.4)\n","Collecting werkzeug>=0.11.15\n","  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 8)) (3.10.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio==0.9.2->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 5)) (0.2.0)\n","Collecting cached-property\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/envs/rl_fx/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r /content/drive/MyDrive/rl_forex/condaenv.vdp_e2z7.requirements.txt (line 8)) (3.4.1)\n","Building wheels for collected packages: empyrical, pyfolio, yfinance, gast, multitasking, termcolor\n","  Building wheel for empyrical (setup.py): started\n","  Building wheel for empyrical (setup.py): finished with status 'done'\n","  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39764 sha256=de8874043adcca6da5dca5ab4feffd4329f32e97b0a1fcf90ba298f31e297133\n","  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n","  Building wheel for pyfolio (setup.py): started\n","  Building wheel for pyfolio (setup.py): finished with status 'done'\n","  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88667 sha256=36274d8f18bcb822a818b5f9d7830edcc971afc18733a5bd243c173c2e5c3e6d\n","  Stored in directory: /root/.cache/pip/wheels/e4/96/9b/0dfff5453e702fd780a099b7c850521099c5ec0dfafae189f9\n","  Building wheel for yfinance (setup.py): started\n","  Building wheel for yfinance (setup.py): finished with status 'done'\n","  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=afeb695e0df439840fde7fae1fc2398b412d27c81fd40efb2ec007438fca491e\n","  Stored in directory: /root/.cache/pip/wheels/aa/8a/36/59ed4f6fbcb6100967618eeb0696046bf9777a41ac2ff1f9b9\n","  Building wheel for gast (setup.py): started\n","  Building wheel for gast (setup.py): finished with status 'done'\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7538 sha256=a1e157e85cd2da63f107f2ad587ff88599a963ca083f491e041879d82cd14f52\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","  Building wheel for multitasking (setup.py): started\n","  Building wheel for multitasking (setup.py): finished with status 'done'\n","  Created wheel for multitasking: filename=multitasking-0.0.9-py3-none-any.whl size=8368 sha256=7f53a08dd60c848d543fad0ac6cd18e5f75ff1622dc8e63f2efd1b8dfb3c581e\n","  Stored in directory: /root/.cache/pip/wheels/ae/25/47/4d68431a7ec1b6c4b5233365934b74c1d4e665bf5f968d363a\n","  Building wheel for termcolor (setup.py): started\n","  Building wheel for termcolor (setup.py): finished with status 'done'\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=eb691a8890022545492ce612b852ebc7aa06f91aad5b64966f254e52c3d9146b\n","  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n","Successfully built empyrical pyfolio yfinance gast multitasking termcolor\n","Installing collected packages: lxml, cached-property, werkzeug, protobuf, pandas-datareader, opencv-python, markdown, h5py, grpcio, atari-py, absl-py, torch, termcolor, tensorflow-estimator, tensorboard, seaborn, opt-einsum, multitasking, keras-preprocessing, keras-applications, google-pasta, gast, empyrical, astor, yfinance, tensorflow, stable-baselines3, stable-baselines, pyfolio, plotext\n","Successfully installed absl-py-0.13.0 astor-0.8.1 atari-py-0.2.9 cached-property-1.5.2 empyrical-0.5.5 gast-0.2.2 google-pasta-0.2.0 grpcio-1.38.1 h5py-3.3.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 lxml-4.6.3 markdown-3.3.4 multitasking-0.0.9 opencv-python-4.5.2.54 opt-einsum-3.3.0 pandas-datareader-0.9.0 plotext-2.3.1 protobuf-3.17.3 pyfolio-0.9.2 seaborn-0.11.1 stable-baselines-2.10.2 stable-baselines3-0.10.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-1.1.0 torch-1.7.1 werkzeug-2.0.1 yfinance-0.1.55\n","\n","done\n","#\n","# To activate this environment, use\n","#\n","#     $ conda activate rl_fx\n","#\n","# To deactivate an active environment, use\n","#\n","#     $ conda deactivate\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 4.9.2\n","  latest version: 4.10.1\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c defaults conda\n","\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"z07LghakSJsR"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"jMkY4BeuSECM","executionInfo":{"status":"ok","timestamp":1624861625395,"user_tz":-480,"elapsed":3,"user":{"displayName":"Wei Jie Wong","photoUrl":"","userId":"02487461390156571104"}}},"source":["import sys\n"," \n","# Add conda packages to PATH\n","_ = (sys.path\n","        .append(\"/usr/local/envs/rl_fx/lib/python3.7/site-packages\"))\n","\n","# Remove Colab preinstalled libraries\n","sys.path.remove('/usr/local/lib/python3.7/dist-packages')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtDs7X1oRxdM","outputId":"50d0c7b0-e85a-4385-c589-303eaa99d1a4"},"source":["%load_ext autoreload\n","%autoreload\n","from finrl.autotrain.training import continual_training\n","\n","continual_training()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","environment/total_reward -6083.208867719863\n","environment/total_reward_pct -6.083208867719862\n","environment/total_cost 0.0\n","environment/total_trades 8484\n","train/episode_reward -0.0009841960636695149\n","---------------------------------\n","| explained_variance | 0.142    |\n","| fps                | 149      |\n","| nupdates           | 12800    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 256000   |\n","| value_loss         | 0.000305 |\n","---------------------------------\n","environment/nop_value 92609.275538719\n","environment/total_reward -7390.724461281003\n","environment/total_reward_pct -7.390724461281002\n","environment/total_cost 0.0\n","environment/total_trades 8390\n","train/episode_reward -0.003146192322211573\n","---------------------------------\n","| explained_variance | -0.0116  |\n","| fps                | 149      |\n","| nupdates           | 12900    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 258000   |\n","| value_loss         | 2.24e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.19    |\n","| fps                | 149      |\n","| nupdates           | 13000    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 260000   |\n","| value_loss         | 1.21e-05 |\n","---------------------------------\n","environment/nop_value 93532.87512259893\n","environment/total_reward -6467.124877401075\n","environment/total_reward_pct -6.467124877401075\n","environment/total_cost 0.0\n","environment/total_trades 8631\n","train/episode_reward -0.0026673260052484694\n","---------------------------------\n","| explained_variance | 0.0628   |\n","| fps                | 149      |\n","| nupdates           | 13100    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 262000   |\n","| value_loss         | 9.62e-06 |\n","---------------------------------\n","step: 2653, episode: 100\n","end_total_asset: 93354.27\n","total_reward: -6645.73\n","total_cost: 0.00\n","total_trades: 8311\n","=================================\n","environment/nop_value 93354.26762058567\n","environment/total_reward -6645.73237941433\n","environment/total_reward_pct -6.645732379414331\n","environment/total_cost 0.0\n","environment/total_trades 8311\n","train/episode_reward -0.0033107330576982352\n","---------------------------------\n","| explained_variance | -0.371   |\n","| fps                | 149      |\n","| nupdates           | 13200    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 264000   |\n","| value_loss         | 0.000161 |\n","---------------------------------\n","environment/nop_value 92179.18992981831\n","environment/total_reward -7820.8100701816875\n","environment/total_reward_pct -7.820810070181687\n","environment/total_cost 0.0\n","environment/total_trades 8150\n","train/episode_reward -0.0028019572139019147\n","---------------------------------\n","| explained_variance | -6.45    |\n","| fps                | 149      |\n","| nupdates           | 13300    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 266000   |\n","| value_loss         | 2.35e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -2.12    |\n","| fps                | 149      |\n","| nupdates           | 13400    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 268000   |\n","| value_loss         | 1.47e-05 |\n","---------------------------------\n","environment/nop_value 93544.18563228966\n","environment/total_reward -6455.814367710336\n","environment/total_reward_pct -6.455814367710336\n","environment/total_cost 0.0\n","environment/total_trades 8254\n","train/episode_reward -0.0003895471670562984\n","---------------------------------\n","| explained_variance | -0.178   |\n","| fps                | 149      |\n","| nupdates           | 13500    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 270000   |\n","| value_loss         | 4.74e-05 |\n","---------------------------------\n","environment/nop_value 95359.00060777288\n","environment/total_reward -4640.999392227124\n","environment/total_reward_pct -4.640999392227124\n","environment/total_cost 0.0\n","environment/total_trades 8342\n","train/episode_reward -0.0026990603099751754\n","---------------------------------\n","| explained_variance | -0.15    |\n","| fps                | 149      |\n","| nupdates           | 13600    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 272000   |\n","| value_loss         | 0.00012  |\n","---------------------------------\n","environment/nop_value 93857.55960271737\n","environment/total_reward -6142.440397282626\n","environment/total_reward_pct -6.142440397282626\n","environment/total_cost 0.0\n","environment/total_trades 8578\n","train/episode_reward -0.002715349747434084\n","---------------------------------\n","| explained_variance | 0.283    |\n","| fps                | 149      |\n","| nupdates           | 13700    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 274000   |\n","| value_loss         | 4.06e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -83.1    |\n","| fps                | 149      |\n","| nupdates           | 13800    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 276000   |\n","| value_loss         | 0.000135 |\n","---------------------------------\n","environment/nop_value 93905.42071661941\n","environment/total_reward -6094.57928338059\n","environment/total_reward_pct -6.09457928338059\n","environment/total_cost 0.0\n","environment/total_trades 8521\n","train/episode_reward -0.0021831158507528018\n","----------------------------------\n","| explained_variance | -0.000737 |\n","| fps                | 149       |\n","| nupdates           | 13900     |\n","| policy_entropy     | 20.7      |\n","| total_timesteps    | 278000    |\n","| value_loss         | 0.00189   |\n","----------------------------------\n","environment/nop_value 92029.81026878124\n","environment/total_reward -7970.189731218765\n","environment/total_reward_pct -7.970189731218764\n","environment/total_cost 0.0\n","environment/total_trades 8548\n","train/episode_reward -0.0018952243063235074\n","---------------------------------\n","| explained_variance | -0.631   |\n","| fps                | 149      |\n","| nupdates           | 14000    |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 280000   |\n","| value_loss         | 1.53e-05 |\n","---------------------------------\n","environment/nop_value 92603.81089412274\n","environment/total_reward -7396.18910587726\n","environment/total_reward_pct -7.39618910587726\n","environment/total_cost 0.0\n","environment/total_trades 8215\n","train/episode_reward -0.002542567638558103\n","---------------------------------\n","| explained_variance | -0.0514  |\n","| fps                | 149      |\n","| nupdates           | 14100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 282000   |\n","| value_loss         | 5.62e-05 |\n","---------------------------------\n","environment/nop_value 91921.37748830797\n","environment/total_reward -8078.622511692025\n","environment/total_reward_pct -8.078622511692025\n","environment/total_cost 0.0\n","environment/total_trades 8613\n","train/episode_reward -0.0010809784628829221\n","---------------------------------\n","| explained_variance | -0.146   |\n","| fps                | 149      |\n","| nupdates           | 14200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 284000   |\n","| value_loss         | 0.000246 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.00355  |\n","| fps                | 149      |\n","| nupdates           | 14300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 286000   |\n","| value_loss         | 5.49e-05 |\n","---------------------------------\n","environment/nop_value 92154.40823338997\n","environment/total_reward -7845.591766610029\n","environment/total_reward_pct -7.8455917666100286\n","environment/total_cost 0.0\n","environment/total_trades 8124\n","train/episode_reward -0.003234688073252619\n","---------------------------------\n","| explained_variance | -0.0366  |\n","| fps                | 149      |\n","| nupdates           | 14400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 288000   |\n","| value_loss         | 0.000101 |\n","---------------------------------\n","step: 2653, episode: 110\n","end_total_asset: 93323.89\n","total_reward: -6676.11\n","total_cost: 0.00\n","total_trades: 8408\n","=================================\n","environment/nop_value 93323.88750875133\n","environment/total_reward -6676.11249124867\n","environment/total_reward_pct -6.67611249124867\n","environment/total_cost 0.0\n","environment/total_trades 8408\n","train/episode_reward -0.0027339687660249182\n","---------------------------------\n","| explained_variance | 0.00235  |\n","| fps                | 149      |\n","| nupdates           | 14500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 290000   |\n","| value_loss         | 0.000111 |\n","---------------------------------\n","environment/nop_value 93474.59300062341\n","environment/total_reward -6525.406999376588\n","environment/total_reward_pct -6.525406999376587\n","environment/total_cost 0.0\n","environment/total_trades 7872\n","train/episode_reward -0.0031922087623344852\n","---------------------------------\n","| explained_variance | -0.765   |\n","| fps                | 149      |\n","| nupdates           | 14600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 292000   |\n","| value_loss         | 6.07e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.00249 |\n","| fps                | 149      |\n","| nupdates           | 14700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 294000   |\n","| value_loss         | 5.93e-05 |\n","---------------------------------\n","environment/nop_value 93060.42378706492\n","environment/total_reward -6939.576212935077\n","environment/total_reward_pct -6.939576212935076\n","environment/total_cost 0.0\n","environment/total_trades 8420\n","train/episode_reward -0.00115415065533889\n","---------------------------------\n","| explained_variance | -0.288   |\n","| fps                | 149      |\n","| nupdates           | 14800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 296000   |\n","| value_loss         | 8.96e-05 |\n","---------------------------------\n","environment/nop_value 91859.20220243059\n","environment/total_reward -8140.797797569408\n","environment/total_reward_pct -8.140797797569409\n","environment/total_cost 0.0\n","environment/total_trades 8542\n","train/episode_reward -0.0023976468649183516\n","---------------------------------\n","| explained_variance | -0.0845  |\n","| fps                | 149      |\n","| nupdates           | 14900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 298000   |\n","| value_loss         | 7.6e-05  |\n","---------------------------------\n","environment/nop_value 94084.2552990024\n","environment/total_reward -5915.744700997602\n","environment/total_reward_pct -5.915744700997602\n","environment/total_cost 0.0\n","environment/total_trades 8335\n","train/episode_reward -0.0027814112277686947\n","---------------------------------\n","| explained_variance | -0.279   |\n","| fps                | 149      |\n","| nupdates           | 15000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 300000   |\n","| value_loss         | 2.48e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.235    |\n","| fps                | 149      |\n","| nupdates           | 15100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 302000   |\n","| value_loss         | 3.17e-05 |\n","---------------------------------\n","environment/nop_value 94027.1363878134\n","environment/total_reward -5972.8636121866\n","environment/total_reward_pct -5.9728636121866\n","environment/total_cost 0.0\n","environment/total_trades 8262\n","train/episode_reward -0.003211078422908031\n","---------------------------------\n","| explained_variance | -0.00674 |\n","| fps                | 149      |\n","| nupdates           | 15200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 304000   |\n","| value_loss         | 0.000367 |\n","---------------------------------\n","environment/nop_value 92251.58396628188\n","environment/total_reward -7748.416033718124\n","environment/total_reward_pct -7.748416033718124\n","environment/total_cost 0.0\n","environment/total_trades 8307\n","train/episode_reward -0.0028538717653311327\n","---------------------------------\n","| explained_variance | -0.0652  |\n","| fps                | 149      |\n","| nupdates           | 15300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 306000   |\n","| value_loss         | 0.000171 |\n","---------------------------------\n","environment/nop_value 93249.48587410207\n","environment/total_reward -6750.514125897927\n","environment/total_reward_pct -6.7505141258979275\n","environment/total_cost 0.0\n","environment/total_trades 8236\n","train/episode_reward -0.0015095516548957676\n","---------------------------------\n","| explained_variance | -0.199   |\n","| fps                | 149      |\n","| nupdates           | 15400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 308000   |\n","| value_loss         | 3.23e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.028    |\n","| fps                | 149      |\n","| nupdates           | 15500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 310000   |\n","| value_loss         | 0.000296 |\n","---------------------------------\n","environment/nop_value 91786.29724957235\n","environment/total_reward -8213.702750427648\n","environment/total_reward_pct -8.213702750427649\n","environment/total_cost 0.0\n","environment/total_trades 8489\n","train/episode_reward -0.0032587945838691667\n","---------------------------------\n","| explained_variance | 0.00484  |\n","| fps                | 149      |\n","| nupdates           | 15600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 312000   |\n","| value_loss         | 0.00118  |\n","---------------------------------\n","environment/nop_value 93219.95418801474\n","environment/total_reward -6780.045811985256\n","environment/total_reward_pct -6.780045811985255\n","environment/total_cost 0.0\n","environment/total_trades 8488\n","train/episode_reward -0.00299522710829624\n","---------------------------------\n","| explained_variance | -0.21    |\n","| fps                | 149      |\n","| nupdates           | 15700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 314000   |\n","| value_loss         | 1.73e-05 |\n","---------------------------------\n","step: 2653, episode: 120\n","end_total_asset: 93626.65\n","total_reward: -6373.35\n","total_cost: 0.00\n","total_trades: 8475\n","=================================\n","environment/nop_value 93626.6524113816\n","environment/total_reward -6373.347588618402\n","environment/total_reward_pct -6.373347588618403\n","environment/total_cost 0.0\n","environment/total_trades 8475\n","train/episode_reward -0.001507348576275399\n","---------------------------------\n","| explained_variance | 0.085    |\n","| fps                | 149      |\n","| nupdates           | 15800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 316000   |\n","| value_loss         | 0.000116 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.13     |\n","| fps                | 149      |\n","| nupdates           | 15900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 318000   |\n","| value_loss         | 0.000116 |\n","---------------------------------\n","environment/nop_value 93373.10459778123\n","environment/total_reward -6626.895402218768\n","environment/total_reward_pct -6.626895402218769\n","environment/total_cost 0.0\n","environment/total_trades 8273\n","train/episode_reward -0.0010732975330320187\n","---------------------------------\n","| explained_variance | -0.661   |\n","| fps                | 149      |\n","| nupdates           | 16000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 320000   |\n","| value_loss         | 9.06e-05 |\n","---------------------------------\n","environment/nop_value 94331.43872315288\n","environment/total_reward -5668.561276847118\n","environment/total_reward_pct -5.668561276847119\n","environment/total_cost 0.0\n","environment/total_trades 8232\n","train/episode_reward -0.003221470515026886\n","---------------------------------\n","| explained_variance | -0.156   |\n","| fps                | 149      |\n","| nupdates           | 16100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 322000   |\n","| value_loss         | 4.84e-05 |\n","---------------------------------\n","environment/nop_value 92589.37205774353\n","environment/total_reward -7410.627942256469\n","environment/total_reward_pct -7.410627942256469\n","environment/total_cost 0.0\n","environment/total_trades 8430\n","train/episode_reward -0.0023453897753541245\n","---------------------------------\n","| explained_variance | 0.00554  |\n","| fps                | 149      |\n","| nupdates           | 16200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 324000   |\n","| value_loss         | 0.000578 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.981   |\n","| fps                | 149      |\n","| nupdates           | 16300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 326000   |\n","| value_loss         | 1.2e-05  |\n","---------------------------------\n","environment/nop_value 93698.47476874417\n","environment/total_reward -6301.52523125583\n","environment/total_reward_pct -6.301525231255829\n","environment/total_cost 0.0\n","environment/total_trades 8360\n","train/episode_reward -0.003547931271759444\n","---------------------------------\n","| explained_variance | -0.211   |\n","| fps                | 149      |\n","| nupdates           | 16400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 328000   |\n","| value_loss         | 0.000117 |\n","---------------------------------\n","environment/nop_value 93566.22543784065\n","environment/total_reward -6433.774562159349\n","environment/total_reward_pct -6.43377456215935\n","environment/total_cost 0.0\n","environment/total_trades 8278\n","train/episode_reward -0.0012902580561843934\n","---------------------------------\n","| explained_variance | 1.23e-05 |\n","| fps                | 149      |\n","| nupdates           | 16500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 330000   |\n","| value_loss         | 5.46e-05 |\n","---------------------------------\n","environment/nop_value 93198.8624949139\n","environment/total_reward -6801.137505086095\n","environment/total_reward_pct -6.801137505086095\n","environment/total_cost 0.0\n","environment/total_trades 8145\n","train/episode_reward -0.0013728361591827708\n","---------------------------------\n","| explained_variance | -0.381   |\n","| fps                | 149      |\n","| nupdates           | 16600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 332000   |\n","| value_loss         | 0.000254 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.013   |\n","| fps                | 149      |\n","| nupdates           | 16700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 334000   |\n","| value_loss         | 0.000137 |\n","---------------------------------\n","environment/nop_value 92182.29106553728\n","environment/total_reward -7817.708934462717\n","environment/total_reward_pct -7.817708934462717\n","environment/total_cost 0.0\n","environment/total_trades 8189\n","train/episode_reward -0.0031480759404803396\n","---------------------------------\n","| explained_variance | -0.0396  |\n","| fps                | 149      |\n","| nupdates           | 16800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 336000   |\n","| value_loss         | 2.21e-05 |\n","---------------------------------\n","environment/nop_value 93244.51035987042\n","environment/total_reward -6755.489640129585\n","environment/total_reward_pct -6.755489640129585\n","environment/total_cost 0.0\n","environment/total_trades 8581\n","train/episode_reward -0.002411209230439272\n","---------------------------------\n","| explained_variance | -0.226   |\n","| fps                | 149      |\n","| nupdates           | 16900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 338000   |\n","| value_loss         | 4.89e-05 |\n","---------------------------------\n","environment/nop_value 91516.92296283077\n","environment/total_reward -8483.077037169234\n","environment/total_reward_pct -8.483077037169235\n","environment/total_cost 0.0\n","environment/total_trades 8145\n","train/episode_reward -0.0031818303549734995\n","---------------------------------\n","| explained_variance | -0.194   |\n","| fps                | 149      |\n","| nupdates           | 17000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 340000   |\n","| value_loss         | 9.78e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.806   |\n","| fps                | 149      |\n","| nupdates           | 17100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 342000   |\n","| value_loss         | 7.37e-05 |\n","---------------------------------\n","step: 2653, episode: 130\n","end_total_asset: 92935.38\n","total_reward: -7064.62\n","total_cost: 0.00\n","total_trades: 8547\n","=================================\n","environment/nop_value 92935.3835341191\n","environment/total_reward -7064.616465880899\n","environment/total_reward_pct -7.064616465880899\n","environment/total_cost 0.0\n","environment/total_trades 8547\n","train/episode_reward -0.0029855088639509633\n","---------------------------------\n","| explained_variance | 0.0376   |\n","| fps                | 149      |\n","| nupdates           | 17200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 344000   |\n","| value_loss         | 3.72e-05 |\n","---------------------------------\n","environment/nop_value 93734.52469027352\n","environment/total_reward -6265.475309726477\n","environment/total_reward_pct -6.265475309726476\n","environment/total_cost 0.0\n","environment/total_trades 8244\n","train/episode_reward -0.002395557202611235\n","---------------------------------\n","| explained_variance | -2.33    |\n","| fps                | 149      |\n","| nupdates           | 17300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 346000   |\n","| value_loss         | 0.000247 |\n","---------------------------------\n","environment/nop_value 94298.08580745324\n","environment/total_reward -5701.914192546756\n","environment/total_reward_pct -5.701914192546756\n","environment/total_cost 0.0\n","environment/total_trades 8090\n","train/episode_reward -0.0019235153507819634\n","---------------------------------\n","| explained_variance | -1.28    |\n","| fps                | 149      |\n","| nupdates           | 17400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 348000   |\n","| value_loss         | 2.97e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.327   |\n","| fps                | 149      |\n","| nupdates           | 17500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 350000   |\n","| value_loss         | 4.9e-05  |\n","---------------------------------\n","environment/nop_value 92923.45054478256\n","environment/total_reward -7076.549455217435\n","environment/total_reward_pct -7.076549455217434\n","environment/total_cost 0.0\n","environment/total_trades 8531\n","train/episode_reward -0.0010669244399876335\n","---------------------------------\n","| explained_variance | 0.128    |\n","| fps                | 149      |\n","| nupdates           | 17600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 352000   |\n","| value_loss         | 5.52e-05 |\n","---------------------------------\n","environment/nop_value 93077.65221780492\n","environment/total_reward -6922.34778219508\n","environment/total_reward_pct -6.9223477821950805\n","environment/total_cost 0.0\n","environment/total_trades 8297\n","train/episode_reward -0.0035236826009189827\n","---------------------------------\n","| explained_variance | -2.17    |\n","| fps                | 149      |\n","| nupdates           | 17700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 354000   |\n","| value_loss         | 5.89e-06 |\n","---------------------------------\n","environment/nop_value 92753.46009404672\n","environment/total_reward -7246.539905953279\n","environment/total_reward_pct -7.24653990595328\n","environment/total_cost 0.0\n","environment/total_trades 8259\n","train/episode_reward -0.0019965825395731373\n","---------------------------------\n","| explained_variance | 0.0333   |\n","| fps                | 149      |\n","| nupdates           | 17800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 356000   |\n","| value_loss         | 0.000172 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.66    |\n","| fps                | 149      |\n","| nupdates           | 17900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 358000   |\n","| value_loss         | 7.74e-06 |\n","---------------------------------\n","environment/nop_value 94459.10665722638\n","environment/total_reward -5540.893342773619\n","environment/total_reward_pct -5.54089334277362\n","environment/total_cost 0.0\n","environment/total_trades 8300\n","train/episode_reward -0.0025875256756015008\n","---------------------------------\n","| explained_variance | -0.0733  |\n","| fps                | 149      |\n","| nupdates           | 18000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 360000   |\n","| value_loss         | 2.13e-05 |\n","---------------------------------\n","environment/nop_value 94186.12715310842\n","environment/total_reward -5813.87284689158\n","environment/total_reward_pct -5.81387284689158\n","environment/total_cost 0.0\n","environment/total_trades 8319\n","train/episode_reward -0.002376855301836622\n","---------------------------------\n","| explained_variance | -0.043   |\n","| fps                | 149      |\n","| nupdates           | 18100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 362000   |\n","| value_loss         | 0.00029  |\n","---------------------------------\n","environment/nop_value 93195.41755398024\n","environment/total_reward -6804.582446019762\n","environment/total_reward_pct -6.804582446019762\n","environment/total_cost 0.0\n","environment/total_trades 8365\n","train/episode_reward -0.0026875071546033726\n","---------------------------------\n","| explained_variance | 0.0108   |\n","| fps                | 149      |\n","| nupdates           | 18200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 364000   |\n","| value_loss         | 0.000558 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.172   |\n","| fps                | 149      |\n","| nupdates           | 18300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 366000   |\n","| value_loss         | 3.77e-05 |\n","---------------------------------\n","environment/nop_value 92994.82934124094\n","environment/total_reward -7005.17065875906\n","environment/total_reward_pct -7.005170658759059\n","environment/total_cost 0.0\n","environment/total_trades 8448\n","train/episode_reward -0.002784825998854649\n","---------------------------------\n","| explained_variance | -4.53    |\n","| fps                | 149      |\n","| nupdates           | 18400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 368000   |\n","| value_loss         | 0.000248 |\n","---------------------------------\n","step: 2653, episode: 140\n","end_total_asset: 92578.17\n","total_reward: -7421.83\n","total_cost: 0.00\n","total_trades: 8254\n","=================================\n","environment/nop_value 92578.16541030671\n","environment/total_reward -7421.834589693288\n","environment/total_reward_pct -7.4218345896932885\n","environment/total_cost 0.0\n","environment/total_trades 8254\n","train/episode_reward -0.0031266806319938042\n","---------------------------------\n","| explained_variance | 0.0183   |\n","| fps                | 149      |\n","| nupdates           | 18500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 370000   |\n","| value_loss         | 1.55e-05 |\n","---------------------------------\n","environment/nop_value 94351.31357673493\n","environment/total_reward -5648.68642326507\n","environment/total_reward_pct -5.64868642326507\n","environment/total_cost 0.0\n","environment/total_trades 8403\n","train/episode_reward -0.0013431339213057073\n","---------------------------------\n","| explained_variance | -0.102   |\n","| fps                | 149      |\n","| nupdates           | 18600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 372000   |\n","| value_loss         | 3.94e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.136   |\n","| fps                | 149      |\n","| nupdates           | 18700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 374000   |\n","| value_loss         | 3.77e-05 |\n","---------------------------------\n","environment/nop_value 92941.01251979469\n","environment/total_reward -7058.987480205309\n","environment/total_reward_pct -7.0589874802053085\n","environment/total_cost 0.0\n","environment/total_trades 8464\n","train/episode_reward -0.0027593986585954557\n","---------------------------------\n","| explained_variance | 0.132    |\n","| fps                | 149      |\n","| nupdates           | 18800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 376000   |\n","| value_loss         | 1.25e-05 |\n","---------------------------------\n","environment/nop_value 93528.65356766724\n","environment/total_reward -6471.346432332764\n","environment/total_reward_pct -6.471346432332764\n","environment/total_cost 0.0\n","environment/total_trades 8341\n","train/episode_reward -0.0025310059037044995\n","---------------------------------\n","| explained_variance | -0.0278  |\n","| fps                | 149      |\n","| nupdates           | 18900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 378000   |\n","| value_loss         | 4.35e-05 |\n","---------------------------------\n","environment/nop_value 93481.0897361147\n","environment/total_reward -6518.910263885293\n","environment/total_reward_pct -6.518910263885293\n","environment/total_cost 0.0\n","environment/total_trades 8370\n","train/episode_reward -0.002674649520304229\n","---------------------------------\n","| explained_variance | -0.546   |\n","| fps                | 149      |\n","| nupdates           | 19000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 380000   |\n","| value_loss         | 1.54e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0565  |\n","| fps                | 149      |\n","| nupdates           | 19100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 382000   |\n","| value_loss         | 2.17e-06 |\n","---------------------------------\n","environment/nop_value 93217.25986538119\n","environment/total_reward -6782.740134618813\n","environment/total_reward_pct -6.7827401346188125\n","environment/total_cost 0.0\n","environment/total_trades 8547\n","train/episode_reward -0.0030716022612381497\n","---------------------------------\n","| explained_variance | -0.0185  |\n","| fps                | 149      |\n","| nupdates           | 19200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 384000   |\n","| value_loss         | 0.000149 |\n","---------------------------------\n","environment/nop_value 92964.10909265443\n","environment/total_reward -7035.8909073455725\n","environment/total_reward_pct -7.035890907345572\n","environment/total_cost 0.0\n","environment/total_trades 8314\n","train/episode_reward -0.0035251594623099663\n","---------------------------------\n","| explained_variance | 0.00992  |\n","| fps                | 149      |\n","| nupdates           | 19300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 386000   |\n","| value_loss         | 0.000283 |\n","---------------------------------\n","environment/nop_value 92795.37742302255\n","environment/total_reward -7204.622576977446\n","environment/total_reward_pct -7.204622576977446\n","environment/total_cost 0.0\n","environment/total_trades 8530\n","train/episode_reward -0.0007576489228347782\n","---------------------------------\n","| explained_variance | -0.0519  |\n","| fps                | 149      |\n","| nupdates           | 19400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 388000   |\n","| value_loss         | 6.74e-06 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.357   |\n","| fps                | 149      |\n","| nupdates           | 19500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 390000   |\n","| value_loss         | 1.37e-05 |\n","---------------------------------\n","environment/nop_value 92552.59678617126\n","environment/total_reward -7447.403213828744\n","environment/total_reward_pct -7.447403213828744\n","environment/total_cost 0.0\n","environment/total_trades 8225\n","train/episode_reward -0.0019714498610730515\n","---------------------------------\n","| explained_variance | -0.00278 |\n","| fps                | 149      |\n","| nupdates           | 19600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 392000   |\n","| value_loss         | 3.96e-05 |\n","---------------------------------\n","environment/nop_value 92517.77368656102\n","environment/total_reward -7482.22631343898\n","environment/total_reward_pct -7.4822263134389795\n","environment/total_cost 0.0\n","environment/total_trades 8667\n","train/episode_reward -0.0015413140270582517\n","---------------------------------\n","| explained_variance | 0.0723   |\n","| fps                | 149      |\n","| nupdates           | 19700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 394000   |\n","| value_loss         | 0.000148 |\n","---------------------------------\n","step: 2653, episode: 150\n","end_total_asset: 93910.15\n","total_reward: -6089.85\n","total_cost: 0.00\n","total_trades: 8563\n","=================================\n","environment/nop_value 93910.1519654676\n","environment/total_reward -6089.848034532406\n","environment/total_reward_pct -6.089848034532406\n","environment/total_cost 0.0\n","environment/total_trades 8563\n","train/episode_reward -0.003387255529413233\n","---------------------------------\n","| explained_variance | 0.00508  |\n","| fps                | 149      |\n","| nupdates           | 19800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 396000   |\n","| value_loss         | 1.18e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0115  |\n","| fps                | 149      |\n","| nupdates           | 19900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 398000   |\n","| value_loss         | 1.49e-06 |\n","---------------------------------\n","environment/nop_value 93426.32056847063\n","environment/total_reward -6573.679431529366\n","environment/total_reward_pct -6.573679431529367\n","environment/total_cost 0.0\n","environment/total_trades 8576\n","train/episode_reward -0.0022877020400119364\n","---------------------------------\n","| explained_variance | -0.182   |\n","| fps                | 149      |\n","| nupdates           | 20000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 400000   |\n","| value_loss         | 0.000436 |\n","---------------------------------\n","environment/nop_value 93143.26267584816\n","environment/total_reward -6856.737324151836\n","environment/total_reward_pct -6.856737324151836\n","environment/total_cost 0.0\n","environment/total_trades 8490\n","train/episode_reward -0.0008828144031765988\n","---------------------------------\n","| explained_variance | -0.0716  |\n","| fps                | 149      |\n","| nupdates           | 20100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 402000   |\n","| value_loss         | 0.000126 |\n","---------------------------------\n","environment/nop_value 93579.03894235063\n","environment/total_reward -6420.961057649372\n","environment/total_reward_pct -6.4209610576493725\n","environment/total_cost 0.0\n","environment/total_trades 8390\n","train/episode_reward -0.003195775648689596\n","---------------------------------\n","| explained_variance | -0.622   |\n","| fps                | 149      |\n","| nupdates           | 20200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 404000   |\n","| value_loss         | 2.07e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.71    |\n","| fps                | 149      |\n","| nupdates           | 20300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 406000   |\n","| value_loss         | 2.94e-06 |\n","---------------------------------\n","environment/nop_value 93311.16338211336\n","environment/total_reward -6688.836617886642\n","environment/total_reward_pct -6.688836617886642\n","environment/total_cost 0.0\n","environment/total_trades 8293\n","train/episode_reward -0.0012612599832122215\n","---------------------------------\n","| explained_variance | -0.0603  |\n","| fps                | 149      |\n","| nupdates           | 20400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 408000   |\n","| value_loss         | 1.74e-05 |\n","---------------------------------\n","environment/nop_value 92951.62059702678\n","environment/total_reward -7048.3794029732235\n","environment/total_reward_pct -7.048379402973223\n","environment/total_cost 0.0\n","environment/total_trades 8384\n","train/episode_reward -0.0034347738798504\n","---------------------------------\n","| explained_variance | -0.169   |\n","| fps                | 149      |\n","| nupdates           | 20500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 410000   |\n","| value_loss         | 0.000145 |\n","---------------------------------\n","environment/nop_value 93555.29448536487\n","environment/total_reward -6444.705514635134\n","environment/total_reward_pct -6.4447055146351335\n","environment/total_cost 0.0\n","environment/total_trades 8381\n","train/episode_reward -0.002777185278455727\n","---------------------------------\n","| explained_variance | -1.05    |\n","| fps                | 149      |\n","| nupdates           | 20600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 412000   |\n","| value_loss         | 8.34e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.181   |\n","| fps                | 149      |\n","| nupdates           | 20700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 414000   |\n","| value_loss         | 3.27e-06 |\n","---------------------------------\n","environment/nop_value 92776.72917331614\n","environment/total_reward -7223.27082668386\n","environment/total_reward_pct -7.22327082668386\n","environment/total_cost 0.0\n","environment/total_trades 8416\n","train/episode_reward -0.0029590677422937006\n","---------------------------------\n","| explained_variance | -0.034   |\n","| fps                | 149      |\n","| nupdates           | 20800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 416000   |\n","| value_loss         | 0.00229  |\n","---------------------------------\n","environment/nop_value 91999.20518245504\n","environment/total_reward -8000.7948175449565\n","environment/total_reward_pct -8.000794817544957\n","environment/total_cost 0.0\n","environment/total_trades 8396\n","train/episode_reward -0.0015844108289718862\n","---------------------------------\n","| explained_variance | 0.0422   |\n","| fps                | 149      |\n","| nupdates           | 20900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 418000   |\n","| value_loss         | 0.000277 |\n","---------------------------------\n","environment/nop_value 93195.61356546282\n","environment/total_reward -6804.386434537184\n","environment/total_reward_pct -6.804386434537184\n","environment/total_cost 0.0\n","environment/total_trades 8159\n","train/episode_reward -0.0010755206825677306\n","---------------------------------\n","| explained_variance | 0.0223   |\n","| fps                | 149      |\n","| nupdates           | 21000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 420000   |\n","| value_loss         | 2.29e-05 |\n","---------------------------------\n","step: 2653, episode: 160\n","end_total_asset: 93143.68\n","total_reward: -6856.32\n","total_cost: 0.00\n","total_trades: 8235\n","=================================\n","environment/nop_value 93143.6758668694\n","environment/total_reward -6856.324133130605\n","environment/total_reward_pct -6.856324133130605\n","environment/total_cost 0.0\n","environment/total_trades 8235\n","train/episode_reward -0.0035393028605059957\n","---------------------------------\n","| explained_variance | -0.572   |\n","| fps                | 149      |\n","| nupdates           | 21100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 422000   |\n","| value_loss         | 0.000136 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.00247  |\n","| fps                | 149      |\n","| nupdates           | 21200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 424000   |\n","| value_loss         | 8.62e-05 |\n","---------------------------------\n","environment/nop_value 94147.20280782055\n","environment/total_reward -5852.797192179452\n","environment/total_reward_pct -5.852797192179452\n","environment/total_cost 0.0\n","environment/total_trades 8244\n","train/episode_reward -0.0028888469843601342\n","---------------------------------\n","| explained_variance | -0.0286  |\n","| fps                | 149      |\n","| nupdates           | 21300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 426000   |\n","| value_loss         | 0.000154 |\n","---------------------------------\n","environment/nop_value 94069.58331540381\n","environment/total_reward -5930.416684596188\n","environment/total_reward_pct -5.930416684596188\n","environment/total_cost 0.0\n","environment/total_trades 8437\n","train/episode_reward -0.00291595744301012\n","---------------------------------\n","| explained_variance | 0.0392   |\n","| fps                | 149      |\n","| nupdates           | 21400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 428000   |\n","| value_loss         | 0.00035  |\n","---------------------------------\n","environment/nop_value 94139.9779346561\n","environment/total_reward -5860.022065343903\n","environment/total_reward_pct -5.860022065343903\n","environment/total_cost 0.0\n","environment/total_trades 8408\n","train/episode_reward -0.0008772266778512858\n","---------------------------------\n","| explained_variance | -0.465   |\n","| fps                | 149      |\n","| nupdates           | 21500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 430000   |\n","| value_loss         | 9.44e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.0192   |\n","| fps                | 149      |\n","| nupdates           | 21600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 432000   |\n","| value_loss         | 3.57e-05 |\n","---------------------------------\n","environment/nop_value 93372.8560235839\n","environment/total_reward -6627.143976416104\n","environment/total_reward_pct -6.627143976416104\n","environment/total_cost 0.0\n","environment/total_trades 8510\n","train/episode_reward -0.003000448790079099\n","---------------------------------\n","| explained_variance | -0.0539  |\n","| fps                | 149      |\n","| nupdates           | 21700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 434000   |\n","| value_loss         | 0.000264 |\n","---------------------------------\n","environment/nop_value 92383.6255765292\n","environment/total_reward -7616.374423470799\n","environment/total_reward_pct -7.616374423470799\n","environment/total_cost 0.0\n","environment/total_trades 8333\n","train/episode_reward -0.002632895952591207\n","---------------------------------\n","| explained_variance | -0.055   |\n","| fps                | 149      |\n","| nupdates           | 21800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 436000   |\n","| value_loss         | 8.41e-05 |\n","---------------------------------\n","environment/nop_value 93235.03754921618\n","environment/total_reward -6764.962450783816\n","environment/total_reward_pct -6.764962450783816\n","environment/total_cost 0.0\n","environment/total_trades 8629\n","train/episode_reward -0.0025062919586329373\n","---------------------------------\n","| explained_variance | -0.0433  |\n","| fps                | 149      |\n","| nupdates           | 21900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 438000   |\n","| value_loss         | 7.88e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.00262 |\n","| fps                | 149      |\n","| nupdates           | 22000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 440000   |\n","| value_loss         | 0.000165 |\n","---------------------------------\n","environment/nop_value 94687.9550227698\n","environment/total_reward -5312.0449772301945\n","environment/total_reward_pct -5.312044977230195\n","environment/total_cost 0.0\n","environment/total_trades 8168\n","train/episode_reward -0.0032499239548196787\n","---------------------------------\n","| explained_variance | 0.0485   |\n","| fps                | 149      |\n","| nupdates           | 22100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 442000   |\n","| value_loss         | 0.000108 |\n","---------------------------------\n","environment/nop_value 92752.69935575029\n","environment/total_reward -7247.3006442497135\n","environment/total_reward_pct -7.247300644249713\n","environment/total_cost 0.0\n","environment/total_trades 8429\n","train/episode_reward -0.0013772801527782578\n","---------------------------------\n","| explained_variance | 0.00843  |\n","| fps                | 149      |\n","| nupdates           | 22200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 444000   |\n","| value_loss         | 9.69e-05 |\n","---------------------------------\n","environment/nop_value 91168.4766952466\n","environment/total_reward -8831.523304753398\n","environment/total_reward_pct -8.831523304753398\n","environment/total_cost 0.0\n","environment/total_trades 8471\n","train/episode_reward -0.003120660167875758\n","---------------------------------\n","| explained_variance | 0.00181  |\n","| fps                | 149      |\n","| nupdates           | 22300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 446000   |\n","| value_loss         | 5.75e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.267   |\n","| fps                | 149      |\n","| nupdates           | 22400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 448000   |\n","| value_loss         | 2.43e-05 |\n","---------------------------------\n","step: 2653, episode: 170\n","end_total_asset: 93067.25\n","total_reward: -6932.75\n","total_cost: 0.00\n","total_trades: 8246\n","=================================\n","environment/nop_value 93067.24994876506\n","environment/total_reward -6932.750051234936\n","environment/total_reward_pct -6.932750051234936\n","environment/total_cost 0.0\n","environment/total_trades 8246\n","train/episode_reward -0.0032585504969378236\n","---------------------------------\n","| explained_variance | 0.0877   |\n","| fps                | 149      |\n","| nupdates           | 22500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 450000   |\n","| value_loss         | 0.00018  |\n","---------------------------------\n","environment/nop_value 94049.52302426696\n","environment/total_reward -5950.476975733036\n","environment/total_reward_pct -5.950476975733036\n","environment/total_cost 0.0\n","environment/total_trades 8349\n","train/episode_reward -0.0023259278417230235\n","---------------------------------\n","| explained_variance | 0.048    |\n","| fps                | 149      |\n","| nupdates           | 22600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 452000   |\n","| value_loss         | 0.000139 |\n","---------------------------------\n","environment/nop_value 94513.5507619751\n","environment/total_reward -5486.449238024899\n","environment/total_reward_pct -5.4864492380249\n","environment/total_cost 0.0\n","environment/total_trades 8625\n","train/episode_reward -0.003445943664618244\n","---------------------------------\n","| explained_variance | 0.0416   |\n","| fps                | 149      |\n","| nupdates           | 22700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 454000   |\n","| value_loss         | 1.37e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.142   |\n","| fps                | 149      |\n","| nupdates           | 22800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 456000   |\n","| value_loss         | 1.37e-05 |\n","---------------------------------\n","environment/nop_value 92537.46157993937\n","environment/total_reward -7462.538420060635\n","environment/total_reward_pct -7.4625384200606355\n","environment/total_cost 0.0\n","environment/total_trades 8679\n","train/episode_reward -0.003247769555717241\n","---------------------------------\n","| explained_variance | -0.062   |\n","| fps                | 149      |\n","| nupdates           | 22900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 458000   |\n","| value_loss         | 4.13e-05 |\n","---------------------------------\n","environment/nop_value 93597.53054574881\n","environment/total_reward -6402.469454251186\n","environment/total_reward_pct -6.402469454251186\n","environment/total_cost 0.0\n","environment/total_trades 8154\n","train/episode_reward -0.002107189877452038\n","---------------------------------\n","| explained_variance | -0.176   |\n","| fps                | 149      |\n","| nupdates           | 23000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 460000   |\n","| value_loss         | 7.07e-05 |\n","---------------------------------\n","environment/nop_value 92314.71906096107\n","environment/total_reward -7685.28093903893\n","environment/total_reward_pct -7.68528093903893\n","environment/total_cost 0.0\n","environment/total_trades 8298\n","train/episode_reward -0.0011852163545874646\n","---------------------------------\n","| explained_variance | 0.00597  |\n","| fps                | 149      |\n","| nupdates           | 23100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 462000   |\n","| value_loss         | 5.77e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.296   |\n","| fps                | 149      |\n","| nupdates           | 23200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 464000   |\n","| value_loss         | 3.72e-05 |\n","---------------------------------\n","environment/nop_value 91867.50302505602\n","environment/total_reward -8132.496974943977\n","environment/total_reward_pct -8.132496974943978\n","environment/total_cost 0.0\n","environment/total_trades 8411\n","train/episode_reward -0.0015044218615395948\n","---------------------------------\n","| explained_variance | 0.381    |\n","| fps                | 149      |\n","| nupdates           | 23300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 466000   |\n","| value_loss         | 6.42e-05 |\n","---------------------------------\n","environment/nop_value 92843.81374318979\n","environment/total_reward -7156.186256810208\n","environment/total_reward_pct -7.156186256810209\n","environment/total_cost 0.0\n","environment/total_trades 8026\n","train/episode_reward -0.002109537740457745\n","---------------------------------\n","| explained_variance | 0.165    |\n","| fps                | 149      |\n","| nupdates           | 23400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 468000   |\n","| value_loss         | 2.17e-05 |\n","---------------------------------\n","environment/nop_value 92014.1246323429\n","environment/total_reward -7985.875367657107\n","environment/total_reward_pct -7.985875367657107\n","environment/total_cost 0.0\n","environment/total_trades 8612\n","train/episode_reward -0.001651410769240465\n","---------------------------------\n","| explained_variance | -0.007   |\n","| fps                | 149      |\n","| nupdates           | 23500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 470000   |\n","| value_loss         | 0.000805 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.0385   |\n","| fps                | 149      |\n","| nupdates           | 23600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 472000   |\n","| value_loss         | 7.54e-05 |\n","---------------------------------\n","environment/nop_value 93236.67056149464\n","environment/total_reward -6763.32943850536\n","environment/total_reward_pct -6.76332943850536\n","environment/total_cost 0.0\n","environment/total_trades 8352\n","train/episode_reward -0.0013816828179202276\n","---------------------------------\n","| explained_variance | -0.0385  |\n","| fps                | 149      |\n","| nupdates           | 23700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 474000   |\n","| value_loss         | 1.73e-05 |\n","---------------------------------\n","step: 2653, episode: 180\n","end_total_asset: 93069.24\n","total_reward: -6930.76\n","total_cost: 0.00\n","total_trades: 8117\n","=================================\n","environment/nop_value 93069.2422844406\n","environment/total_reward -6930.7577155594045\n","environment/total_reward_pct -6.9307577155594045\n","environment/total_cost 0.0\n","environment/total_trades 8117\n","train/episode_reward -0.0017208573098789204\n","---------------------------------\n","| explained_variance | 0.127    |\n","| fps                | 149      |\n","| nupdates           | 23800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 476000   |\n","| value_loss         | 3.2e-05  |\n","---------------------------------\n","environment/nop_value 93705.02536995607\n","environment/total_reward -6294.974630043929\n","environment/total_reward_pct -6.294974630043929\n","environment/total_cost 0.0\n","environment/total_trades 8461\n","train/episode_reward -0.0021734751282958317\n","---------------------------------\n","| explained_variance | 0.0341   |\n","| fps                | 149      |\n","| nupdates           | 23900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 478000   |\n","| value_loss         | 1.49e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.00042  |\n","| fps                | 149      |\n","| nupdates           | 24000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 480000   |\n","| value_loss         | 3.94e-05 |\n","---------------------------------\n","environment/nop_value 94767.77804417428\n","environment/total_reward -5232.22195582572\n","environment/total_reward_pct -5.23222195582572\n","environment/total_cost 0.0\n","environment/total_trades 8180\n","train/episode_reward -0.003048086144293484\n","---------------------------------\n","| explained_variance | -0.00399 |\n","| fps                | 149      |\n","| nupdates           | 24100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 482000   |\n","| value_loss         | 0.000281 |\n","---------------------------------\n","environment/nop_value 93911.25646919633\n","environment/total_reward -6088.743530803666\n","environment/total_reward_pct -6.088743530803666\n","environment/total_cost 0.0\n","environment/total_trades 8371\n","train/episode_reward -0.0028291508281225106\n","---------------------------------\n","| explained_variance | -0.367   |\n","| fps                | 149      |\n","| nupdates           | 24200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 484000   |\n","| value_loss         | 0.000106 |\n","---------------------------------\n","environment/nop_value 94202.26902437811\n","environment/total_reward -5797.730975621889\n","environment/total_reward_pct -5.797730975621889\n","environment/total_cost 0.0\n","environment/total_trades 8595\n","train/episode_reward -0.002027757623772777\n","---------------------------------\n","| explained_variance | 0.0274   |\n","| fps                | 149      |\n","| nupdates           | 24300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 486000   |\n","| value_loss         | 4.78e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.153    |\n","| fps                | 149      |\n","| nupdates           | 24400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 488000   |\n","| value_loss         | 3.2e-05  |\n","---------------------------------\n","environment/nop_value 93232.3187859701\n","environment/total_reward -6767.681214029901\n","environment/total_reward_pct -6.767681214029901\n","environment/total_cost 0.0\n","environment/total_trades 8559\n","train/episode_reward -0.0017500485251890497\n","---------------------------------\n","| explained_variance | -0.149   |\n","| fps                | 149      |\n","| nupdates           | 24500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 490000   |\n","| value_loss         | 0.000166 |\n","---------------------------------\n","environment/nop_value 92944.99268170891\n","environment/total_reward -7055.0073182910855\n","environment/total_reward_pct -7.055007318291086\n","environment/total_cost 0.0\n","environment/total_trades 8456\n","train/episode_reward -0.002271652883999923\n","---------------------------------\n","| explained_variance | -0.571   |\n","| fps                | 149      |\n","| nupdates           | 24600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 492000   |\n","| value_loss         | 1.75e-05 |\n","---------------------------------\n","environment/nop_value 93369.01988401651\n","environment/total_reward -6630.98011598349\n","environment/total_reward_pct -6.63098011598349\n","environment/total_cost 0.0\n","environment/total_trades 8404\n","train/episode_reward -0.0033687755712075163\n","---------------------------------\n","| explained_variance | -0.126   |\n","| fps                | 149      |\n","| nupdates           | 24700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 494000   |\n","| value_loss         | 0.000856 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.308   |\n","| fps                | 149      |\n","| nupdates           | 24800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 496000   |\n","| value_loss         | 1.3e-05  |\n","---------------------------------\n","environment/nop_value 94727.90127458789\n","environment/total_reward -5272.098725412114\n","environment/total_reward_pct -5.272098725412114\n","environment/total_cost 0.0\n","environment/total_trades 8670\n","train/episode_reward -0.002680638732036459\n","----------------------------------\n","| explained_variance | -0.000601 |\n","| fps                | 149       |\n","| nupdates           | 24900     |\n","| policy_entropy     | 20.8      |\n","| total_timesteps    | 498000    |\n","| value_loss         | 4.89e-05  |\n","----------------------------------\n","environment/nop_value 91998.17782291144\n","environment/total_reward -8001.8221770885575\n","environment/total_reward_pct -8.001822177088558\n","environment/total_cost 0.0\n","environment/total_trades 8503\n","train/episode_reward -0.0019006873776976137\n","---------------------------------\n","| explained_variance | -0.015   |\n","| fps                | 149      |\n","| nupdates           | 25000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 500000   |\n","| value_loss         | 0.000241 |\n","---------------------------------\n","step: 2653, episode: 190\n","end_total_asset: 93568.92\n","total_reward: -6431.08\n","total_cost: 0.00\n","total_trades: 8289\n","=================================\n","environment/nop_value 93568.91601665066\n","environment/total_reward -6431.083983349337\n","environment/total_reward_pct -6.431083983349338\n","environment/total_cost 0.0\n","environment/total_trades 8289\n","train/episode_reward -0.0027308980183806853\n","---------------------------------\n","| explained_variance | -0.179   |\n","| fps                | 149      |\n","| nupdates           | 25100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 502000   |\n","| value_loss         | 1.78e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.07    |\n","| fps                | 149      |\n","| nupdates           | 25200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 504000   |\n","| value_loss         | 6.1e-05  |\n","---------------------------------\n","environment/nop_value 92774.22433030109\n","environment/total_reward -7225.775669698909\n","environment/total_reward_pct -7.225775669698908\n","environment/total_cost 0.0\n","environment/total_trades 8224\n","train/episode_reward -0.0032354391446278896\n","---------------------------------\n","| explained_variance | -0.00544 |\n","| fps                | 149      |\n","| nupdates           | 25300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 506000   |\n","| value_loss         | 9.14e-05 |\n","---------------------------------\n","environment/nop_value 93997.37965988551\n","environment/total_reward -6002.6203401144885\n","environment/total_reward_pct -6.002620340114489\n","environment/total_cost 0.0\n","environment/total_trades 8297\n","train/episode_reward -0.003324934150796617\n","---------------------------------\n","| explained_variance | -0.00772 |\n","| fps                | 149      |\n","| nupdates           | 25400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 508000   |\n","| value_loss         | 0.000145 |\n","---------------------------------\n","environment/nop_value 94475.63803022946\n","environment/total_reward -5524.3619697705435\n","environment/total_reward_pct -5.524361969770544\n","environment/total_cost 0.0\n","environment/total_trades 8663\n","train/episode_reward -0.0014192640854380444\n","---------------------------------\n","| explained_variance | 0.0355   |\n","| fps                | 149      |\n","| nupdates           | 25500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 510000   |\n","| value_loss         | 7.02e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0201  |\n","| fps                | 149      |\n","| nupdates           | 25600    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 512000   |\n","| value_loss         | 8.12e-05 |\n","---------------------------------\n","environment/nop_value 92611.2554326246\n","environment/total_reward -7388.744567375397\n","environment/total_reward_pct -7.388744567375398\n","environment/total_cost 0.0\n","environment/total_trades 8180\n","train/episode_reward -0.0027311074721757906\n","---------------------------------\n","| explained_variance | 0.0263   |\n","| fps                | 149      |\n","| nupdates           | 25700    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 514000   |\n","| value_loss         | 4.63e-05 |\n","---------------------------------\n","environment/nop_value 93250.74551462471\n","environment/total_reward -6749.254485375292\n","environment/total_reward_pct -6.749254485375292\n","environment/total_cost 0.0\n","environment/total_trades 8256\n","train/episode_reward -0.0034086151417926885\n","---------------------------------\n","| explained_variance | -0.0254  |\n","| fps                | 149      |\n","| nupdates           | 25800    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 516000   |\n","| value_loss         | 4.15e-05 |\n","---------------------------------\n","environment/nop_value 93115.13847353004\n","environment/total_reward -6884.861526469962\n","environment/total_reward_pct -6.884861526469963\n","environment/total_cost 0.0\n","environment/total_trades 8121\n","train/episode_reward -0.0010141548014536966\n","---------------------------------\n","| explained_variance | -0.282   |\n","| fps                | 149      |\n","| nupdates           | 25900    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 518000   |\n","| value_loss         | 5.85e-06 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.1     |\n","| fps                | 149      |\n","| nupdates           | 26000    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 520000   |\n","| value_loss         | 5.96e-06 |\n","---------------------------------\n","environment/nop_value 93383.64432463438\n","environment/total_reward -6616.355675365616\n","environment/total_reward_pct -6.616355675365616\n","environment/total_cost 0.0\n","environment/total_trades 8387\n","train/episode_reward -0.0029754949412745192\n","---------------------------------\n","| explained_variance | 0.11     |\n","| fps                | 149      |\n","| nupdates           | 26100    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 522000   |\n","| value_loss         | 7.55e-05 |\n","---------------------------------\n","environment/nop_value 93198.57613142935\n","environment/total_reward -6801.423868570651\n","environment/total_reward_pct -6.801423868570651\n","environment/total_cost 0.0\n","environment/total_trades 8369\n","train/episode_reward -0.002937724296114175\n","---------------------------------\n","| explained_variance | -0.224   |\n","| fps                | 149      |\n","| nupdates           | 26200    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 524000   |\n","| value_loss         | 0.000195 |\n","---------------------------------\n","environment/nop_value 93812.94469585553\n","environment/total_reward -6187.0553041444655\n","environment/total_reward_pct -6.187055304144465\n","environment/total_cost 0.0\n","environment/total_trades 8211\n","train/episode_reward -0.0003889679324027384\n","---------------------------------\n","| explained_variance | -0.0243  |\n","| fps                | 149      |\n","| nupdates           | 26300    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 526000   |\n","| value_loss         | 1.39e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0709  |\n","| fps                | 149      |\n","| nupdates           | 26400    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 528000   |\n","| value_loss         | 8.61e-06 |\n","---------------------------------\n","step: 2653, episode: 200\n","end_total_asset: 94072.48\n","total_reward: -5927.52\n","total_cost: 0.00\n","total_trades: 8319\n","=================================\n","environment/nop_value 94072.48373518884\n","environment/total_reward -5927.516264811158\n","environment/total_reward_pct -5.927516264811159\n","environment/total_cost 0.0\n","environment/total_trades 8319\n","train/episode_reward -0.0015951676809418133\n","---------------------------------\n","| explained_variance | 0.0792   |\n","| fps                | 149      |\n","| nupdates           | 26500    |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 530000   |\n","| value_loss         | 7.2e-05  |\n","---------------------------------\n","environment/nop_value 94194.27168527657\n","environment/total_reward -5805.728314723427\n","environment/total_reward_pct -5.805728314723427\n","environment/total_cost 0.0\n","environment/total_trades 8175\n","train/episode_reward -0.0025927761939397898\n","states ->  [[ 4.73786950e-01 -1.50311179e-03 -1.39529437e-01  2.03940228e-01\n","   4.60722335e-02 -1.27891794e-01  3.03208917e-01  2.53323972e-01\n","  -3.72866929e-01 -1.70240775e-02 -2.54588366e-01  6.60072327e-01\n","  -3.77539098e-01  2.77645051e-01  5.49737215e-01 -1.79772496e-01\n","  -3.27411413e-01 -2.87286460e-01 -6.30013287e-01 -7.00622201e-01\n","   3.45907919e-02 -7.74927214e-02 -9.99122709e-02 -6.16048992e-01\n","  -3.51065636e-01 -1.68663964e-01  7.37203658e-01 -4.57504332e-01\n","  -1.37429342e-01  3.79238188e-01  3.61494482e-01 -9.36573297e-02\n","  -5.65444469e-01 -1.02490932e-01  4.12136495e-01 -9.83672291e-02\n","   1.38352692e-01  8.64976719e-02 -2.55901180e-03  1.30302496e-02\n","  -1.50760025e-01 -2.27722913e-01 -1.78462610e-01  3.20390165e-01\n","  -1.85176760e-01  2.55203962e-01  9.33144689e-02  2.52754271e-01\n","  -3.12458873e-02  7.51156881e-02 -1.90081298e-01 -1.96059346e-01\n","  -1.68328345e-01 -3.43443781e-01  2.41519034e-01 -5.81960320e-01\n","   2.85176814e-01  3.33760977e-01 -1.13817811e-01 -5.62649786e-01\n","   8.96183699e-02  1.63009763e-03  5.22888243e-01 -1.11351103e-01\n","  -3.90289165e-02 -4.36792761e-01  4.41549659e-01  6.36637062e-02\n","   1.47055732e-02 -6.94783270e-01  4.28832114e-01 -1.01385880e-02\n","   3.00443824e-02 -9.97360423e-03 -3.47285509e-01  4.95738029e-01\n","  -3.77545625e-01 -4.15548265e-01 -1.10600770e-01 -2.18938962e-01\n","   2.25080550e-01 -4.29384783e-02  2.54306227e-01  3.40947300e-01\n","   8.69259089e-02 -1.58841521e-01  2.91488618e-01 -1.08860433e-01\n","   3.89149249e-01 -2.34938115e-01 -6.64376393e-02 -1.74075924e-03\n","  -4.58199888e-01  2.79214859e-01 -1.52974669e-02 -1.19786754e-01\n","  -3.48385811e-01  4.24996734e-01 -4.12892580e-01  5.99596202e-01\n","  -2.38658309e-01  5.79780161e-01 -1.71754539e-01  5.26483953e-02\n","   2.51521468e-01 -3.81038189e-01  4.04901683e-01  4.62805390e-01\n","   1.36135310e-01  1.43700436e-01 -2.04196870e-01 -4.84440550e-02\n","  -4.67261493e-01 -2.74270713e-01  1.39059708e-01 -1.38713270e-01\n","  -9.32199836e-01  6.24723434e-01  4.05109599e-02  3.81534934e-01\n","  -6.82636142e-01 -1.32941753e-01 -2.64044218e-02  1.87644452e-01\n","   4.50455904e-01  1.37222290e-01  5.57603538e-01  3.75890374e-01\n","  -4.06404734e-01  4.07166064e-01  3.65264237e-01  2.80231953e-01\n","  -8.55855942e-02  2.64594138e-01 -4.61886883e-01 -2.83233285e-01\n","  -1.13844097e-01 -2.53249377e-01  3.70738022e-02  1.87905014e-01\n","   3.52859974e-01  1.38500690e-01 -2.97266066e-01  1.51511580e-01\n","   5.53815782e-01  2.98676342e-01 -3.64219159e-01  7.48248458e-01\n","  -2.28008013e-02  3.29680622e-01  2.30203196e-01  3.56889457e-01\n","   2.86470592e-01  1.76518783e-01  1.38558373e-02  7.46979341e-02\n","   2.05497473e-01 -1.23097315e-01  1.76596388e-01  2.80172110e-01\n","   3.04837048e-01  7.20102787e-02 -1.77380383e-01  5.74423671e-02\n","  -3.23757261e-01 -6.60077110e-02 -1.91846460e-01 -1.77497771e-02\n","  -1.18502825e-01 -4.14083660e-01 -3.34091447e-02  5.22998795e-02\n","  -9.36362613e-03  2.34955758e-01 -3.59737277e-01 -4.55555737e-01\n","   1.40153706e-01 -3.77887964e-01  9.85796936e-03  1.20935157e-01\n","  -5.82373083e-01  6.88366741e-02  2.84354329e-01 -1.86835781e-01\n","  -2.10968018e-01  5.02143085e-01  6.10512681e-04 -2.50047624e-01\n","  -5.04160225e-02 -9.58503783e-02  1.32131249e-01 -6.02023974e-02\n","  -4.52741086e-01  7.93962598e-01  6.03792369e-01 -1.47020429e-01\n","   3.32804322e-02 -3.36964160e-01  5.90124279e-02 -7.06108510e-02\n","  -1.46018401e-01  5.65127611e-01  4.24454689e-01  4.91975367e-01\n","  -4.63688970e-01 -4.45380986e-01  1.04223311e-01  4.52125371e-02\n","  -3.55117500e-01 -1.31784141e-01 -2.04411313e-01 -5.78499079e-01\n","   1.48048416e-01  6.90868571e-02 -1.12300530e-01 -1.99397147e-01\n","   4.82538998e-01  2.71289736e-01 -5.39754510e-01  9.76167023e-02\n","   2.21298903e-01  1.80878207e-01  1.97066128e-01  1.13161832e-01\n","   7.47180134e-02 -1.45157278e-01  2.37259656e-01  6.49944395e-02\n","  -3.49190742e-01  2.37481907e-01 -3.78959417e-01 -1.20070979e-01\n","   3.91824991e-02 -4.10805792e-01  1.24047231e-03  2.95139730e-01\n","  -4.52974141e-01  3.22726309e-01  2.99558997e-01 -1.39746234e-01\n","  -2.54779190e-01  2.54585922e-01 -6.62602007e-01 -2.55366743e-01\n","   6.65789843e-01 -1.23275004e-01 -3.59709933e-02 -4.76873606e-01\n","  -1.60777852e-01 -2.45649487e-01 -1.15886450e-01  3.55441928e-01\n","  -4.21839476e-01 -3.92296523e-01  2.05556214e-01  2.13135064e-01\n","   2.48124853e-01 -6.36305951e-04 -7.03188777e-02  9.40771848e-02\n","   2.44868770e-02 -5.87746464e-02  1.61970347e-01  1.30680710e-01\n","  -1.66341528e-01 -8.52409936e-03 -1.20198861e-01  3.58133495e-01\n","  -1.87790513e-01  1.43746346e-01  2.44022295e-01 -8.29415694e-02\n","  -1.59384951e-01 -1.30704552e-01 -3.22554141e-01 -2.60535330e-01\n","   1.83149725e-02 -3.83521803e-02 -4.37824987e-02 -2.97200799e-01\n","  -1.40052959e-01 -7.61842877e-02  3.83644491e-01 -2.20969364e-01\n","  -7.80391246e-02  1.54663295e-01  1.52002215e-01 -4.92519811e-02\n","  -2.98941880e-01 -4.27888893e-02  2.10877880e-01 -4.63160090e-02\n","   7.60822892e-02  4.22022417e-02 -1.19870214e-03  5.50023140e-03\n","  -8.38627741e-02 -1.12639770e-01 -9.82430726e-02  1.76530972e-01\n","  -1.04506709e-01  1.42605096e-01  4.45999019e-02  1.16748750e-01\n","  -1.61022358e-02  2.82151829e-02 -9.52283964e-02 -9.59968865e-02\n","  -9.49171707e-02 -1.72768474e-01  1.37844950e-01 -2.60891587e-01\n","   1.39352530e-01  1.37153089e-01 -5.52955084e-02 -2.82314807e-01\n","   4.60041352e-02  8.53418082e-04  2.96866924e-01 -4.78023998e-02\n","  -1.83791667e-02 -2.34961718e-01  1.69643983e-01  3.20435315e-02\n","   6.81195222e-03 -3.24925303e-01  2.00256333e-01 -5.64499665e-03\n","   1.79251619e-02 -4.98335296e-03 -1.76334500e-01  2.64102340e-01\n","  -1.84601173e-01 -2.14822516e-01 -4.95093949e-02 -1.06448680e-01\n","   9.58621502e-02 -1.97922625e-02  1.41171604e-01  1.82978436e-01\n","   4.47107367e-02 -8.40068683e-02  1.20015867e-01 -5.94739206e-02\n","   2.02511549e-01 -9.57321525e-02 -2.92017777e-02 -8.08337296e-04\n","  -2.05869734e-01  1.33197606e-01 -8.84344801e-03 -6.61920384e-02\n","  -1.74698234e-01  2.05599174e-01 -1.81061074e-01  3.05210620e-01\n","  -1.15642920e-01  2.76405156e-01 -8.55386779e-02  2.65654419e-02\n","   1.41569823e-01 -1.69035167e-01  1.68223009e-01  2.31889203e-01\n","   5.37162460e-02  6.95384070e-02 -9.71769392e-02 -2.10889801e-02\n","  -2.31512114e-01 -1.32324487e-01  6.34428933e-02 -7.66259432e-02\n","  -3.88954580e-01  3.45291674e-01  1.80578623e-02  1.58811942e-01\n","  -2.64326066e-01 -6.51432127e-02 -1.50487497e-02  9.23438370e-02\n","   1.96342826e-01  7.04736263e-02  2.78243810e-01  1.39473662e-01\n","  -2.01916516e-01  2.02755019e-01  2.12832436e-01  1.09688573e-01\n","  -4.48607095e-02  1.27278849e-01 -2.36905977e-01 -1.30439609e-01\n","  -5.51359318e-02 -1.00346446e-01  1.93967130e-02  8.94320384e-02\n","   1.52057663e-01  6.79504499e-02 -1.41115218e-01  9.15332809e-02\n","   2.41862372e-01  1.53796390e-01 -1.70113638e-01  3.90985072e-01\n","  -1.15155363e-02  1.52856097e-01  1.18964083e-01  1.48758009e-01\n","   1.08919725e-01  7.85644427e-02  7.30343722e-03  3.38650420e-02\n","   8.96779075e-02 -6.62192404e-02  8.52693468e-02  1.32001027e-01\n","   1.37369275e-01  3.04581784e-02 -8.10951442e-02  3.03607956e-02\n","  -1.39763445e-01 -3.65717076e-02 -9.84445810e-02 -8.16059299e-03\n","  -5.97083941e-02 -1.73370257e-01 -1.52777852e-02  2.01760530e-02\n","  -4.52704402e-03  1.13378480e-01 -1.70733809e-01 -1.90584883e-01\n","   6.86760768e-02 -1.52201369e-01  4.35676659e-03  6.07376695e-02\n","  -2.77882934e-01  3.31040174e-02  1.43040702e-01 -9.77479443e-02\n","  -9.59310085e-02  2.51340419e-01  3.38001875e-04 -1.13276042e-01\n","  -2.15271711e-02 -5.32713383e-02  6.49619922e-02 -3.23569700e-02\n","  -2.23207444e-01  4.01058346e-01  3.15978497e-01 -7.82242417e-02\n","   1.35211889e-02 -1.66764855e-01  3.34676690e-02 -3.49435173e-02\n","  -8.00514892e-02  3.08049709e-01  1.99988231e-01  2.79664159e-01\n","  -2.26152629e-01 -2.42787004e-01  4.71199192e-02  2.30682380e-02\n","  -1.47790134e-01 -6.98580891e-02 -8.98579210e-02 -2.53934443e-01\n","   6.98601082e-02  3.27936411e-02 -4.83167768e-02 -9.11563560e-02\n","   2.44658217e-01  1.19659796e-01 -2.86632836e-01  4.24615480e-02\n","   1.11744940e-01  8.76154006e-02  8.69555697e-02  6.00319095e-02\n","   3.31164636e-02 -6.96583092e-02  1.14033259e-01  3.06473561e-02\n","  -1.72098726e-01  1.13804445e-01 -2.03374088e-01 -5.77256493e-02\n","   2.12641954e-02 -1.85132831e-01  7.26925500e-04  1.26059949e-01\n","  -2.33940557e-01  1.74144626e-01  1.44910172e-01 -6.62555993e-02\n","  -1.22381464e-01  1.31686360e-01 -3.48765254e-01 -1.37780979e-01\n","   3.49258155e-01 -5.77597953e-02 -1.70555189e-02 -2.14704901e-01\n","  -7.70279840e-02 -1.23424530e-01 -6.73713684e-02  1.63272485e-01\n","  -2.41022229e-01 -1.99779525e-01  7.80734941e-02  1.10745199e-01]]\n","environment/nop_value 93228.26950768488\n","environment/total_reward -6771.730492315124\n","environment/total_reward_pct -6.7717304923151245\n","environment/total_cost 0.0\n","environment/total_trades 8609\n","train/episode_reward -0.0035051763563809803\n","environment/nop_value 92658.01027412793\n","environment/total_reward -7341.989725872074\n","environment/total_reward_pct -7.341989725872073\n","environment/total_cost 0.0\n","environment/total_trades 8441\n","train/episode_reward -4.866983168903971e-05\n","environment/nop_value 93600.1667519451\n","environment/total_reward -6399.8332480549\n","environment/total_reward_pct -6.399833248054899\n","environment/total_cost 0.0\n","environment/total_trades 8346\n","train/episode_reward -0.003008211576474423\n","environment/nop_value 92898.67498136638\n","environment/total_reward -7101.325018633623\n","environment/total_reward_pct -7.101325018633623\n","environment/total_cost 0.0\n","environment/total_trades 8358\n","train/episode_reward -0.0028759702793991894\n","environment/nop_value 94288.413991741\n","environment/total_reward -5711.586008258993\n","environment/total_reward_pct -5.711586008258993\n","environment/total_cost 0.0\n","environment/total_trades 8116\n","train/episode_reward -0.0025795725875213974\n","Successfully added technical indicators\n","Successfully added technical indicators\n","Successfully added technical indicators\n","Successfully added technical indicators\n","Observation Dimension: 4, State Space: 125\n","Input Dimension: 4, State Space: 125\n","environment/nop_value 97399.55094829701\n","environment/total_reward -2600.4490517029917\n","environment/total_reward_pct -2.600449051702992\n","environment/total_cost 0.0\n","environment/total_trades 9059\n","train/episode_reward 0.00665131689125119\n","environment/nop_value 95623.24096933368\n","environment/total_reward -4376.759030666319\n","environment/total_reward_pct -4.376759030666319\n","environment/total_cost 0.0\n","environment/total_trades 9177\n","train/episode_reward -0.00018004173904482743\n","environment/nop_value 95510.99444826646\n","environment/total_reward -4489.005551733542\n","environment/total_reward_pct -4.489005551733542\n","environment/total_cost 0.0\n","environment/total_trades 9262\n","train/episode_reward 0.004322516217512021\n","environment/nop_value 96482.05080668887\n","environment/total_reward -3517.9491933111276\n","environment/total_reward_pct -3.5179491933111278\n","environment/total_cost 0.0\n","environment/total_trades 8771\n","train/episode_reward 0.0025309113678114955\n","environment/nop_value 96573.46565665622\n","environment/total_reward -3426.534343343781\n","environment/total_reward_pct -3.426534343343781\n","environment/total_cost 0.0\n","environment/total_trades 9192\n","train/episode_reward -0.00068448954665364\n","Mean Episodic Reward :  -0.5173093583110288\n","Sortino Ratio : -1.1020227242055416\n","Elapsed time:  3767.003108739853\n","index   date         2017-04-03 08:30:00+00:00\n","EURUSD  ask_open                       1.06719\n","        ask_high                       1.06742\n","        ask_low                        1.06681\n","        ask_close                      1.06717\n","                               ...            \n","USDCHF  kama_30                        111.394\n","        t3_5                           111.427\n","        atr_14                       0.0743423\n","        natr_14                      0.0667663\n","        tsf_14                         111.412\n","Name: 0, Length: 181, dtype: object\n","{'target': -1.4911565303434615, 'params': {'epsilon': 1e-06, 'learning_rate_val': 0.00040243020567183065}, 'datetime': {'datetime': '2021-06-28 20:16:37', 'elapsed': 0.0, 'delta': 0.0}}\n","{'target': -1.5098408467791014, 'params': {'epsilon': 8.923418089348907e-06, 'learning_rate_val': 0.0014434457419498945}, 'datetime': {'datetime': '2021-06-28 21:29:15', 'elapsed': 4357.79571, 'delta': 4357.79571}}\n","{'target': -1.1754971803618288, 'params': {'epsilon': 2e-05, 'learning_rate_val': 1e-05}, 'datetime': {'datetime': '2021-06-28 22:41:49', 'elapsed': 8711.623977, 'delta': 4353.828267}}\n","{'target': -1.5098408467791014, 'params': {'epsilon': 2e-05, 'learning_rate_val': 0.002}, 'datetime': {'datetime': '2021-06-28 23:51:24', 'elapsed': 12887.049022, 'delta': 4175.425045}}\n","best_iteration : 2\n","params: {'epsilon': 2e-05, 'learning_rate_val': 1e-05}\n","<class 'finrl.model.a2c.A2C'>\n","{'n_steps': 20, 'gamma': 0.99, 'vf_coef': 0.25, 'ent_coef': 0.001, 'max_grad_norm': 0.5, 'alpha': 0.99, 'momentum': 0.0, 'epsilon': 8.923418089348907e-06, 'lr_schedule': 'constant', 'learning_rate': 0.0014434457419498945, 'tensorboard_log': None, 'full_tensorboard_log': False, 'learning_rate_ph': <tf.Tensor 'loss/learning_rate_ph:0' shape=() dtype=float32>, 'n_batch': 20, 'actions_ph': <tf.Tensor 'loss/action_ph:0' shape=(?, 4) dtype=float32>, 'advs_ph': <tf.Tensor 'loss/advs_ph:0' shape=(?,) dtype=float32>, 'rewards_ph': <tf.Tensor 'loss/rewards_ph:0' shape=(?,) dtype=float32>, 'pg_loss': <tf.Tensor 'loss/Mean_1:0' shape=() dtype=float32>, 'vf_loss': <tf.Tensor 'loss/Mean_2:0' shape=() dtype=float32>, 'entropy': <tf.Tensor 'loss/Mean:0' shape=() dtype=float32>, 'apply_backprop': <tf.Operation 'RMSProp' type=NoOp>, 'train_model': <stable_baselines.common.policies.MlpLstmPolicy object at 0x7faa704e80d0>, 'step_model': <stable_baselines.common.policies.MlpLstmPolicy object at 0x7faa0ddab610>, 'proba_step': <bound method LstmPolicy.proba_step of <stable_baselines.common.policies.MlpLstmPolicy object at 0x7faa0ddab610>>, 'value': <bound method LstmPolicy.value of <stable_baselines.common.policies.MlpLstmPolicy object at 0x7faa0ddab610>>, 'initial_state': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","      dtype=float32), 'learning_rate_schedule': None, 'summary': <tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>, 'policy': <class 'stable_baselines.common.policies.MlpLstmPolicy'>, 'env': <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7faa0f885a90>, 'verbose': 1, '_requires_vec_env': True, 'policy_kwargs': {}, 'observation_space': Box(-inf, inf, (130,), float32), 'action_space': Box(-1.0, 1.0, (4,), float32), 'n_envs': 1, '_vectorize_action': False, 'num_timesteps': 0, 'graph': <tensorflow.python.framework.ops.Graph object at 0x7faa0f8848d0>, 'sess': <tensorflow.python.client.session.Session object at 0x7faa0ae28ed0>, 'params': [<tf.Variable 'model/pi_fc0/w:0' shape=(130, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/w:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(64, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(256, 4) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(4,) dtype=float32_ref>, <tf.Variable 'model/pi/logstd:0' shape=(1, 4) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(256, 4) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(4,) dtype=float32_ref>], 'seed': 1, '_param_load_ops': OrderedDict([('model/pi_fc0/w:0', (<tf.Tensor 'Placeholder:0' shape=(130, 64) dtype=float32>, <tf.Tensor 'Assign:0' shape=(130, 64) dtype=float32_ref>)), ('model/pi_fc0/b:0', (<tf.Tensor 'Placeholder_1:0' shape=(64,) dtype=float32>, <tf.Tensor 'Assign_1:0' shape=(64,) dtype=float32_ref>)), ('model/pi_fc1/w:0', (<tf.Tensor 'Placeholder_2:0' shape=(64, 64) dtype=float32>, <tf.Tensor 'Assign_2:0' shape=(64, 64) dtype=float32_ref>)), ('model/pi_fc1/b:0', (<tf.Tensor 'Placeholder_3:0' shape=(64,) dtype=float32>, <tf.Tensor 'Assign_3:0' shape=(64,) dtype=float32_ref>)), ('model/lstm1/wx:0', (<tf.Tensor 'Placeholder_4:0' shape=(64, 1024) dtype=float32>, <tf.Tensor 'Assign_4:0' shape=(64, 1024) dtype=float32_ref>)), ('model/lstm1/wh:0', (<tf.Tensor 'Placeholder_5:0' shape=(256, 1024) dtype=float32>, <tf.Tensor 'Assign_5:0' shape=(256, 1024) dtype=float32_ref>)), ('model/lstm1/b:0', (<tf.Tensor 'Placeholder_6:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Assign_6:0' shape=(1024,) dtype=float32_ref>)), ('model/vf/w:0', (<tf.Tensor 'Placeholder_7:0' shape=(256, 1) dtype=float32>, <tf.Tensor 'Assign_7:0' shape=(256, 1) dtype=float32_ref>)), ('model/vf/b:0', (<tf.Tensor 'Placeholder_8:0' shape=(1,) dtype=float32>, <tf.Tensor 'Assign_8:0' shape=(1,) dtype=float32_ref>)), ('model/pi/w:0', (<tf.Tensor 'Placeholder_9:0' shape=(256, 4) dtype=float32>, <tf.Tensor 'Assign_9:0' shape=(256, 4) dtype=float32_ref>)), ('model/pi/b:0', (<tf.Tensor 'Placeholder_10:0' shape=(4,) dtype=float32>, <tf.Tensor 'Assign_10:0' shape=(4,) dtype=float32_ref>)), ('model/pi/logstd:0', (<tf.Tensor 'Placeholder_11:0' shape=(1, 4) dtype=float32>, <tf.Tensor 'Assign_11:0' shape=(1, 4) dtype=float32_ref>)), ('model/q/w:0', (<tf.Tensor 'Placeholder_12:0' shape=(256, 4) dtype=float32>, <tf.Tensor 'Assign_12:0' shape=(256, 4) dtype=float32_ref>)), ('model/q/b:0', (<tf.Tensor 'Placeholder_13:0' shape=(4,) dtype=float32>, <tf.Tensor 'Assign_13:0' shape=(4,) dtype=float32_ref>))]), 'n_cpu_tf_sess': None, 'episode_reward': None, 'ep_info_buf': None, '_vec_normalize_env': None, 'step': <bound method LstmPolicy.step of <stable_baselines.common.policies.MlpLstmPolicy object at 0x7faa0ddab610>>, '_runner': None}\n","---------------------------------\n","| explained_variance | -0.381   |\n","| fps                | 31       |\n","| nupdates           | 1        |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 20       |\n","| value_loss         | 4.17e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.46    |\n","| fps                | 144      |\n","| nupdates           | 100      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 2000     |\n","| value_loss         | 3.48e-05 |\n","---------------------------------\n","environment/nop_value 94576.38325845181\n","environment/total_reward -5423.6167415481905\n","environment/total_reward_pct -5.423616741548191\n","environment/total_cost 0.0\n","environment/total_trades 8570\n","train/episode_reward -0.003229843146794883\n","---------------------------------\n","| explained_variance | 0.0177   |\n","| fps                | 146      |\n","| nupdates           | 200      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 4000     |\n","| value_loss         | 1.31e-05 |\n","---------------------------------\n","environment/nop_value 93334.23328096123\n","environment/total_reward -6665.766719038773\n","environment/total_reward_pct -6.665766719038772\n","environment/total_cost 0.0\n","environment/total_trades 8517\n","train/episode_reward -0.0017417249591613654\n","---------------------------------\n","| explained_variance | -0.121   |\n","| fps                | 147      |\n","| nupdates           | 300      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 6000     |\n","| value_loss         | 1.47e-05 |\n","---------------------------------\n","environment/nop_value 94002.32456868948\n","environment/total_reward -5997.675431310519\n","environment/total_reward_pct -5.99767543131052\n","environment/total_cost 0.0\n","environment/total_trades 8093\n","train/episode_reward -0.0026579621648474133\n","---------------------------------\n","| explained_variance | -0.0303  |\n","| fps                | 148      |\n","| nupdates           | 400      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 8000     |\n","| value_loss         | 0.000231 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.18    |\n","| fps                | 148      |\n","| nupdates           | 500      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 10000    |\n","| value_loss         | 0.000254 |\n","---------------------------------\n","environment/nop_value 94516.51756820614\n","environment/total_reward -5483.482431793862\n","environment/total_reward_pct -5.4834824317938615\n","environment/total_cost 0.0\n","environment/total_trades 8186\n","train/episode_reward -0.0011969859238553909\n","---------------------------------\n","| explained_variance | -0.0927  |\n","| fps                | 147      |\n","| nupdates           | 600      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 12000    |\n","| value_loss         | 9.66e-05 |\n","---------------------------------\n","environment/nop_value 95053.5047338978\n","environment/total_reward -4946.495266102196\n","environment/total_reward_pct -4.946495266102196\n","environment/total_cost 0.0\n","environment/total_trades 8424\n","train/episode_reward -0.0018245583586423892\n","---------------------------------\n","| explained_variance | -0.08    |\n","| fps                | 147      |\n","| nupdates           | 700      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 14000    |\n","| value_loss         | 0.000107 |\n","---------------------------------\n","environment/nop_value 93639.74290837925\n","environment/total_reward -6360.257091620748\n","environment/total_reward_pct -6.360257091620748\n","environment/total_cost 0.0\n","environment/total_trades 8173\n","train/episode_reward -0.0033780209113872845\n","---------------------------------\n","| explained_variance | -0.161   |\n","| fps                | 148      |\n","| nupdates           | 800      |\n","| policy_entropy     | 20.7     |\n","| total_timesteps    | 16000    |\n","| value_loss         | 0.000129 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.671   |\n","| fps                | 148      |\n","| nupdates           | 900      |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 18000    |\n","| value_loss         | 4.7e-05  |\n","---------------------------------\n","environment/nop_value 92966.74612082283\n","environment/total_reward -7033.253879177166\n","environment/total_reward_pct -7.033253879177166\n","environment/total_cost 0.0\n","environment/total_trades 8325\n","train/episode_reward -0.001506507334865455\n","---------------------------------\n","| explained_variance | 0.0391   |\n","| fps                | 148      |\n","| nupdates           | 1000     |\n","| policy_entropy     | 20.8     |\n","| total_timesteps    | 20000    |\n","| value_loss         | 0.000109 |\n","---------------------------------\n","environment/nop_value 94626.64594584095\n","environment/total_reward -5373.354054159048\n","environment/total_reward_pct -5.373354054159049\n","environment/total_cost 0.0\n","environment/total_trades 8459\n","train/episode_reward -0.0006119899068260566\n","---------------------------------\n","| explained_variance | 0.0209   |\n","| fps                | 148      |\n","| nupdates           | 1100     |\n","| policy_entropy     | 20.9     |\n","| total_timesteps    | 22000    |\n","| value_loss         | 5.94e-06 |\n","---------------------------------\n","step: 2653, episode: 10\n","end_total_asset: 92809.39\n","total_reward: -7190.61\n","total_cost: 0.00\n","total_trades: 8566\n","=================================\n","environment/nop_value 92809.38670797033\n","environment/total_reward -7190.613292029666\n","environment/total_reward_pct -7.190613292029665\n","environment/total_cost 0.0\n","environment/total_trades 8566\n","train/episode_reward -0.0024018337565255934\n","---------------------------------\n","| explained_variance | -0.143   |\n","| fps                | 148      |\n","| nupdates           | 1200     |\n","| policy_entropy     | 21       |\n","| total_timesteps    | 24000    |\n","| value_loss         | 9.16e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -14.1    |\n","| fps                | 148      |\n","| nupdates           | 1300     |\n","| policy_entropy     | 21.1     |\n","| total_timesteps    | 26000    |\n","| value_loss         | 0.000672 |\n","---------------------------------\n","environment/nop_value 93146.71747624862\n","environment/total_reward -6853.282523751375\n","environment/total_reward_pct -6.853282523751375\n","environment/total_cost 0.0\n","environment/total_trades 8778\n","train/episode_reward -0.001365504948393209\n","---------------------------------\n","| explained_variance | 0.0274   |\n","| fps                | 148      |\n","| nupdates           | 1400     |\n","| policy_entropy     | 21.1     |\n","| total_timesteps    | 28000    |\n","| value_loss         | 2.76e-05 |\n","---------------------------------\n","environment/nop_value 93574.16017289861\n","environment/total_reward -6425.839827101387\n","environment/total_reward_pct -6.425839827101387\n","environment/total_cost 0.0\n","environment/total_trades 8357\n","train/episode_reward -0.00201594404077332\n","---------------------------------\n","| explained_variance | 0.00467  |\n","| fps                | 148      |\n","| nupdates           | 1500     |\n","| policy_entropy     | 21.2     |\n","| total_timesteps    | 30000    |\n","| value_loss         | 0.000583 |\n","---------------------------------\n","environment/nop_value 91955.59952098128\n","environment/total_reward -8044.400479018717\n","environment/total_reward_pct -8.044400479018718\n","environment/total_cost 0.0\n","environment/total_trades 8442\n","train/episode_reward -0.002587763246278337\n","---------------------------------\n","| explained_variance | -2.81    |\n","| fps                | 148      |\n","| nupdates           | 1600     |\n","| policy_entropy     | 21.3     |\n","| total_timesteps    | 32000    |\n","| value_loss         | 1.28e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0647  |\n","| fps                | 148      |\n","| nupdates           | 1700     |\n","| policy_entropy     | 21.4     |\n","| total_timesteps    | 34000    |\n","| value_loss         | 9.27e-05 |\n","---------------------------------\n","environment/nop_value 95053.3914897198\n","environment/total_reward -4946.608510280203\n","environment/total_reward_pct -4.946608510280202\n","environment/total_cost 0.0\n","environment/total_trades 8555\n","train/episode_reward -0.002360086604653043\n","---------------------------------\n","| explained_variance | -8.43    |\n","| fps                | 148      |\n","| nupdates           | 1800     |\n","| policy_entropy     | 21.6     |\n","| total_timesteps    | 36000    |\n","| value_loss         | 0.00189  |\n","---------------------------------\n","environment/nop_value 94031.88218525382\n","environment/total_reward -5968.117814746176\n","environment/total_reward_pct -5.968117814746176\n","environment/total_cost 0.0\n","environment/total_trades 8504\n","train/episode_reward -0.0017534500488007325\n","---------------------------------\n","| explained_variance | -4.94    |\n","| fps                | 148      |\n","| nupdates           | 1900     |\n","| policy_entropy     | 21.7     |\n","| total_timesteps    | 38000    |\n","| value_loss         | 9.69e-05 |\n","---------------------------------\n","environment/nop_value 93623.49948671657\n","environment/total_reward -6376.500513283434\n","environment/total_reward_pct -6.376500513283434\n","environment/total_cost 0.0\n","environment/total_trades 8451\n","train/episode_reward -0.0031972940007326542\n","---------------------------------\n","| explained_variance | -0.0375  |\n","| fps                | 148      |\n","| nupdates           | 2000     |\n","| policy_entropy     | 21.8     |\n","| total_timesteps    | 40000    |\n","| value_loss         | 4.81e-06 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.945   |\n","| fps                | 148      |\n","| nupdates           | 2100     |\n","| policy_entropy     | 21.9     |\n","| total_timesteps    | 42000    |\n","| value_loss         | 9.96e-05 |\n","---------------------------------\n","environment/nop_value 90281.76108176672\n","environment/total_reward -9718.238918233284\n","environment/total_reward_pct -9.718238918233284\n","environment/total_cost 0.0\n","environment/total_trades 8534\n","train/episode_reward -0.002977252778943512\n","---------------------------------\n","| explained_variance | -0.124   |\n","| fps                | 148      |\n","| nupdates           | 2200     |\n","| policy_entropy     | 21.9     |\n","| total_timesteps    | 44000    |\n","| value_loss         | 3.51e-05 |\n","---------------------------------\n","environment/nop_value 92501.18272155021\n","environment/total_reward -7498.817278449787\n","environment/total_reward_pct -7.4988172784497875\n","environment/total_cost 0.0\n","environment/total_trades 8574\n","train/episode_reward -0.00268365645371523\n","---------------------------------\n","| explained_variance | -1.3     |\n","| fps                | 148      |\n","| nupdates           | 2300     |\n","| policy_entropy     | 22       |\n","| total_timesteps    | 46000    |\n","| value_loss         | 7.88e-05 |\n","---------------------------------\n","environment/nop_value 94016.65505423117\n","environment/total_reward -5983.344945768826\n","environment/total_reward_pct -5.983344945768826\n","environment/total_cost 0.0\n","environment/total_trades 8366\n","train/episode_reward -0.0019051408661849565\n","---------------------------------\n","| explained_variance | -0.0521  |\n","| fps                | 148      |\n","| nupdates           | 2400     |\n","| policy_entropy     | 22.1     |\n","| total_timesteps    | 48000    |\n","| value_loss         | 3.32e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.116    |\n","| fps                | 148      |\n","| nupdates           | 2500     |\n","| policy_entropy     | 22.2     |\n","| total_timesteps    | 50000    |\n","| value_loss         | 8.63e-05 |\n","---------------------------------\n","step: 2653, episode: 20\n","end_total_asset: 92400.88\n","total_reward: -7599.12\n","total_cost: 0.00\n","total_trades: 8836\n","=================================\n","environment/nop_value 92400.88266032553\n","environment/total_reward -7599.117339674471\n","environment/total_reward_pct -7.5991173396744705\n","environment/total_cost 0.0\n","environment/total_trades 8836\n","train/episode_reward -0.001147213240718702\n","---------------------------------\n","| explained_variance | 0.0828   |\n","| fps                | 148      |\n","| nupdates           | 2600     |\n","| policy_entropy     | 22.3     |\n","| total_timesteps    | 52000    |\n","| value_loss         | 0.000184 |\n","---------------------------------\n","environment/nop_value 92834.74870704311\n","environment/total_reward -7165.251292956891\n","environment/total_reward_pct -7.165251292956891\n","environment/total_cost 0.0\n","environment/total_trades 8712\n","train/episode_reward -0.0022470487764818248\n","---------------------------------\n","| explained_variance | -0.0386  |\n","| fps                | 148      |\n","| nupdates           | 2700     |\n","| policy_entropy     | 22.4     |\n","| total_timesteps    | 54000    |\n","| value_loss         | 0.000979 |\n","---------------------------------\n","environment/nop_value 93889.449854489\n","environment/total_reward -6110.550145511006\n","environment/total_reward_pct -6.110550145511006\n","environment/total_cost 0.0\n","environment/total_trades 8557\n","train/episode_reward -0.0030110261188732693\n","---------------------------------\n","| explained_variance | -0.316   |\n","| fps                | 148      |\n","| nupdates           | 2800     |\n","| policy_entropy     | 22.5     |\n","| total_timesteps    | 56000    |\n","| value_loss         | 6.21e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0763  |\n","| fps                | 148      |\n","| nupdates           | 2900     |\n","| policy_entropy     | 22.6     |\n","| total_timesteps    | 58000    |\n","| value_loss         | 6.96e-05 |\n","---------------------------------\n","environment/nop_value 93534.44852726396\n","environment/total_reward -6465.551472736042\n","environment/total_reward_pct -6.465551472736042\n","environment/total_cost 0.0\n","environment/total_trades 8662\n","train/episode_reward -0.002240579351944325\n","---------------------------------\n","| explained_variance | 0.322    |\n","| fps                | 148      |\n","| nupdates           | 3000     |\n","| policy_entropy     | 22.7     |\n","| total_timesteps    | 60000    |\n","| value_loss         | 2.58e-05 |\n","---------------------------------\n","environment/nop_value 91754.38282778155\n","environment/total_reward -8245.617172218452\n","environment/total_reward_pct -8.245617172218452\n","environment/total_cost 0.0\n","environment/total_trades 8740\n","train/episode_reward -0.0032767857985978484\n","---------------------------------\n","| explained_variance | -0.576   |\n","| fps                | 148      |\n","| nupdates           | 3100     |\n","| policy_entropy     | 22.8     |\n","| total_timesteps    | 62000    |\n","| value_loss         | 6.24e-05 |\n","---------------------------------\n","environment/nop_value 93148.31999815183\n","environment/total_reward -6851.680001848174\n","environment/total_reward_pct -6.851680001848173\n","environment/total_cost 0.0\n","environment/total_trades 8636\n","train/episode_reward -0.001495803601454827\n","---------------------------------\n","| explained_variance | -0.0638  |\n","| fps                | 148      |\n","| nupdates           | 3200     |\n","| policy_entropy     | 22.9     |\n","| total_timesteps    | 64000    |\n","| value_loss         | 0.000118 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -2.77    |\n","| fps                | 148      |\n","| nupdates           | 3300     |\n","| policy_entropy     | 23       |\n","| total_timesteps    | 66000    |\n","| value_loss         | 0.000195 |\n","---------------------------------\n","environment/nop_value 91328.88863704824\n","environment/total_reward -8671.111362951764\n","environment/total_reward_pct -8.671111362951764\n","environment/total_cost 0.0\n","environment/total_trades 8762\n","train/episode_reward -0.002745913248782745\n","---------------------------------\n","| explained_variance | -1.65    |\n","| fps                | 148      |\n","| nupdates           | 3400     |\n","| policy_entropy     | 23.1     |\n","| total_timesteps    | 68000    |\n","| value_loss         | 3.66e-05 |\n","---------------------------------\n","environment/nop_value 92158.27416980991\n","environment/total_reward -7841.725830190087\n","environment/total_reward_pct -7.841725830190087\n","environment/total_cost 0.0\n","environment/total_trades 8660\n","train/episode_reward -0.0028506851844576886\n","---------------------------------\n","| explained_variance | 0.00225  |\n","| fps                | 148      |\n","| nupdates           | 3500     |\n","| policy_entropy     | 23.2     |\n","| total_timesteps    | 70000    |\n","| value_loss         | 4.88e-05 |\n","---------------------------------\n","environment/nop_value 93084.90580229631\n","environment/total_reward -6915.0941977036855\n","environment/total_reward_pct -6.915094197703686\n","environment/total_cost 0.0\n","environment/total_trades 8803\n","train/episode_reward -0.001551688330997422\n","---------------------------------\n","| explained_variance | -1.64    |\n","| fps                | 148      |\n","| nupdates           | 3600     |\n","| policy_entropy     | 23.3     |\n","| total_timesteps    | 72000    |\n","| value_loss         | 3.39e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.126    |\n","| fps                | 148      |\n","| nupdates           | 3700     |\n","| policy_entropy     | 23.4     |\n","| total_timesteps    | 74000    |\n","| value_loss         | 0.000195 |\n","---------------------------------\n","environment/nop_value 93967.71866993517\n","environment/total_reward -6032.281330064827\n","environment/total_reward_pct -6.032281330064826\n","environment/total_cost 0.0\n","environment/total_trades 8657\n","train/episode_reward -0.0032090492751594866\n","---------------------------------\n","| explained_variance | 0.219    |\n","| fps                | 148      |\n","| nupdates           | 3800     |\n","| policy_entropy     | 23.5     |\n","| total_timesteps    | 76000    |\n","| value_loss         | 1.67e-05 |\n","---------------------------------\n","step: 2653, episode: 30\n","end_total_asset: 93944.90\n","total_reward: -6055.10\n","total_cost: 0.00\n","total_trades: 8749\n","=================================\n","environment/nop_value 93944.89555796699\n","environment/total_reward -6055.1044420330145\n","environment/total_reward_pct -6.055104442033015\n","environment/total_cost 0.0\n","environment/total_trades 8749\n","train/episode_reward -0.0011782148336002137\n","---------------------------------\n","| explained_variance | -1.3     |\n","| fps                | 148      |\n","| nupdates           | 3900     |\n","| policy_entropy     | 23.6     |\n","| total_timesteps    | 78000    |\n","| value_loss         | 3.68e-05 |\n","---------------------------------\n","environment/nop_value 93588.80195425334\n","environment/total_reward -6411.198045746656\n","environment/total_reward_pct -6.411198045746656\n","environment/total_cost 0.0\n","environment/total_trades 8560\n","train/episode_reward -0.0026740533887423226\n","---------------------------------\n","| explained_variance | -0.0536  |\n","| fps                | 148      |\n","| nupdates           | 4000     |\n","| policy_entropy     | 23.7     |\n","| total_timesteps    | 80000    |\n","| value_loss         | 0.000462 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -2.07    |\n","| fps                | 148      |\n","| nupdates           | 4100     |\n","| policy_entropy     | 23.8     |\n","| total_timesteps    | 82000    |\n","| value_loss         | 7.61e-05 |\n","---------------------------------\n","environment/nop_value 92416.56046003383\n","environment/total_reward -7583.4395399661735\n","environment/total_reward_pct -7.583439539966173\n","environment/total_cost 0.0\n","environment/total_trades 8915\n","train/episode_reward -0.003156076369152288\n","---------------------------------\n","| explained_variance | -0.51    |\n","| fps                | 148      |\n","| nupdates           | 4200     |\n","| policy_entropy     | 23.8     |\n","| total_timesteps    | 84000    |\n","| value_loss         | 0.000127 |\n","---------------------------------\n","environment/nop_value 92835.99019219373\n","environment/total_reward -7164.009807806273\n","environment/total_reward_pct -7.164009807806273\n","environment/total_cost 0.0\n","environment/total_trades 8908\n","train/episode_reward -0.0022178608922651622\n","---------------------------------\n","| explained_variance | -1.01    |\n","| fps                | 148      |\n","| nupdates           | 4300     |\n","| policy_entropy     | 23.9     |\n","| total_timesteps    | 86000    |\n","| value_loss         | 1.1e-05  |\n","---------------------------------\n","environment/nop_value 91800.04570218411\n","environment/total_reward -8199.954297815886\n","environment/total_reward_pct -8.199954297815886\n","environment/total_cost 0.0\n","environment/total_trades 8848\n","train/episode_reward -0.002854535590413434\n","---------------------------------\n","| explained_variance | -0.0602  |\n","| fps                | 148      |\n","| nupdates           | 4400     |\n","| policy_entropy     | 24       |\n","| total_timesteps    | 88000    |\n","| value_loss         | 0.000643 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.52    |\n","| fps                | 148      |\n","| nupdates           | 4500     |\n","| policy_entropy     | 24.1     |\n","| total_timesteps    | 90000    |\n","| value_loss         | 5.55e-05 |\n","---------------------------------\n","environment/nop_value 89765.37678489009\n","environment/total_reward -10234.62321510991\n","environment/total_reward_pct -10.23462321510991\n","environment/total_cost 0.0\n","environment/total_trades 8997\n","train/episode_reward -0.0013928020597508293\n","---------------------------------\n","| explained_variance | -0.403   |\n","| fps                | 148      |\n","| nupdates           | 4600     |\n","| policy_entropy     | 24.1     |\n","| total_timesteps    | 92000    |\n","| value_loss         | 7.48e-05 |\n","---------------------------------\n","environment/nop_value 93958.2892486611\n","environment/total_reward -6041.7107513389055\n","environment/total_reward_pct -6.041710751338906\n","environment/total_cost 0.0\n","environment/total_trades 8748\n","train/episode_reward -0.0034601244949750256\n","---------------------------------\n","| explained_variance | -0.0606  |\n","| fps                | 148      |\n","| nupdates           | 4700     |\n","| policy_entropy     | 24.3     |\n","| total_timesteps    | 94000    |\n","| value_loss         | 0.000127 |\n","---------------------------------\n","environment/nop_value 92124.68884037134\n","environment/total_reward -7875.311159628662\n","environment/total_reward_pct -7.875311159628662\n","environment/total_cost 0.0\n","environment/total_trades 8805\n","train/episode_reward -0.0011044338312916808\n","---------------------------------\n","| explained_variance | -0.0139  |\n","| fps                | 148      |\n","| nupdates           | 4800     |\n","| policy_entropy     | 24.3     |\n","| total_timesteps    | 96000    |\n","| value_loss         | 2.18e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.032    |\n","| fps                | 148      |\n","| nupdates           | 4900     |\n","| policy_entropy     | 24.4     |\n","| total_timesteps    | 98000    |\n","| value_loss         | 3.52e-05 |\n","---------------------------------\n","environment/nop_value 93705.98804975887\n","environment/total_reward -6294.011950241125\n","environment/total_reward_pct -6.294011950241125\n","environment/total_cost 0.0\n","environment/total_trades 8806\n","train/episode_reward -0.0035502448528204698\n","---------------------------------\n","| explained_variance | -0.223   |\n","| fps                | 148      |\n","| nupdates           | 5000     |\n","| policy_entropy     | 24.5     |\n","| total_timesteps    | 100000   |\n","| value_loss         | 1.35e-05 |\n","---------------------------------\n","environment/nop_value 91796.96850227598\n","environment/total_reward -8203.03149772402\n","environment/total_reward_pct -8.20303149772402\n","environment/total_cost 0.0\n","environment/total_trades 8697\n","train/episode_reward -0.00279583295792836\n","---------------------------------\n","| explained_variance | -1.57    |\n","| fps                | 148      |\n","| nupdates           | 5100     |\n","| policy_entropy     | 24.6     |\n","| total_timesteps    | 102000   |\n","| value_loss         | 0.000331 |\n","---------------------------------\n","step: 2653, episode: 40\n","end_total_asset: 91225.22\n","total_reward: -8774.78\n","total_cost: 0.00\n","total_trades: 8935\n","=================================\n","environment/nop_value 91225.21950037539\n","environment/total_reward -8774.780499624612\n","environment/total_reward_pct -8.774780499624612\n","environment/total_cost 0.0\n","environment/total_trades 8935\n","train/episode_reward -0.0011128573018679164\n","---------------------------------\n","| explained_variance | -4.59    |\n","| fps                | 148      |\n","| nupdates           | 5200     |\n","| policy_entropy     | 24.7     |\n","| total_timesteps    | 104000   |\n","| value_loss         | 1.39e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.278   |\n","| fps                | 148      |\n","| nupdates           | 5300     |\n","| policy_entropy     | 24.7     |\n","| total_timesteps    | 106000   |\n","| value_loss         | 1.55e-05 |\n","---------------------------------\n","environment/nop_value 91527.75211354726\n","environment/total_reward -8472.247886452737\n","environment/total_reward_pct -8.472247886452736\n","environment/total_cost 0.0\n","environment/total_trades 8784\n","train/episode_reward -0.0031855948356402223\n","---------------------------------\n","| explained_variance | 0.161    |\n","| fps                | 148      |\n","| nupdates           | 5400     |\n","| policy_entropy     | 24.9     |\n","| total_timesteps    | 108000   |\n","| value_loss         | 2e-05    |\n","---------------------------------\n","environment/nop_value 94634.69249103595\n","environment/total_reward -5365.307508964048\n","environment/total_reward_pct -5.365307508964047\n","environment/total_cost 0.0\n","environment/total_trades 8683\n","train/episode_reward -0.002034691564257082\n","---------------------------------\n","| explained_variance | 0.181    |\n","| fps                | 148      |\n","| nupdates           | 5500     |\n","| policy_entropy     | 25       |\n","| total_timesteps    | 110000   |\n","| value_loss         | 0.000126 |\n","---------------------------------\n","environment/nop_value 91892.55788831868\n","environment/total_reward -8107.442111681317\n","environment/total_reward_pct -8.107442111681317\n","environment/total_cost 0.0\n","environment/total_trades 8834\n","train/episode_reward -0.0025354175279280753\n","---------------------------------\n","| explained_variance | -60      |\n","| fps                | 148      |\n","| nupdates           | 5600     |\n","| policy_entropy     | 25       |\n","| total_timesteps    | 112000   |\n","| value_loss         | 0.000157 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -5.64    |\n","| fps                | 148      |\n","| nupdates           | 5700     |\n","| policy_entropy     | 25.1     |\n","| total_timesteps    | 114000   |\n","| value_loss         | 2.68e-05 |\n","---------------------------------\n","environment/nop_value 92518.07829982688\n","environment/total_reward -7481.921700173116\n","environment/total_reward_pct -7.481921700173117\n","environment/total_cost 0.0\n","environment/total_trades 8884\n","train/episode_reward -0.0014990326470404399\n","---------------------------------\n","| explained_variance | -2.76    |\n","| fps                | 148      |\n","| nupdates           | 5800     |\n","| policy_entropy     | 25.2     |\n","| total_timesteps    | 116000   |\n","| value_loss         | 0.000316 |\n","---------------------------------\n","environment/nop_value 93761.85244993454\n","environment/total_reward -6238.147550065463\n","environment/total_reward_pct -6.238147550065463\n","environment/total_cost 0.0\n","environment/total_trades 8999\n","train/episode_reward -0.0029944486887077803\n","---------------------------------\n","| explained_variance | -0.151   |\n","| fps                | 148      |\n","| nupdates           | 5900     |\n","| policy_entropy     | 25.3     |\n","| total_timesteps    | 118000   |\n","| value_loss         | 8.8e-05  |\n","---------------------------------\n","environment/nop_value 93880.16594439794\n","environment/total_reward -6119.834055602056\n","environment/total_reward_pct -6.119834055602056\n","environment/total_cost 0.0\n","environment/total_trades 8791\n","train/episode_reward -0.0006042353102369817\n","---------------------------------\n","| explained_variance | -4       |\n","| fps                | 148      |\n","| nupdates           | 6000     |\n","| policy_entropy     | 25.4     |\n","| total_timesteps    | 120000   |\n","| value_loss         | 5.53e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.366   |\n","| fps                | 148      |\n","| nupdates           | 6100     |\n","| policy_entropy     | 25.5     |\n","| total_timesteps    | 122000   |\n","| value_loss         | 9.86e-07 |\n","---------------------------------\n","environment/nop_value 94159.46580672987\n","environment/total_reward -5840.534193270127\n","environment/total_reward_pct -5.840534193270127\n","environment/total_cost 0.0\n","environment/total_trades 8951\n","train/episode_reward -0.0012620384645881133\n","---------------------------------\n","| explained_variance | -0.204   |\n","| fps                | 148      |\n","| nupdates           | 6200     |\n","| policy_entropy     | 25.5     |\n","| total_timesteps    | 124000   |\n","| value_loss         | 3.18e-05 |\n","---------------------------------\n","environment/nop_value 93048.54176975084\n","environment/total_reward -6951.458230249162\n","environment/total_reward_pct -6.951458230249162\n","environment/total_cost 0.0\n","environment/total_trades 8694\n","train/episode_reward -0.0021985470294326663\n","---------------------------------\n","| explained_variance | 0.0997   |\n","| fps                | 148      |\n","| nupdates           | 6300     |\n","| policy_entropy     | 25.6     |\n","| total_timesteps    | 126000   |\n","| value_loss         | 5.23e-05 |\n","---------------------------------\n","environment/nop_value 93935.83169547218\n","environment/total_reward -6064.168304527819\n","environment/total_reward_pct -6.0641683045278185\n","environment/total_cost 0.0\n","environment/total_trades 8851\n","train/episode_reward -0.00347081097374612\n","---------------------------------\n","| explained_variance | 0.035    |\n","| fps                | 148      |\n","| nupdates           | 6400     |\n","| policy_entropy     | 25.7     |\n","| total_timesteps    | 128000   |\n","| value_loss         | 2.35e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -109     |\n","| fps                | 148      |\n","| nupdates           | 6500     |\n","| policy_entropy     | 25.8     |\n","| total_timesteps    | 130000   |\n","| value_loss         | 1.94e-05 |\n","---------------------------------\n","step: 2653, episode: 50\n","end_total_asset: 92025.51\n","total_reward: -7974.49\n","total_cost: 0.00\n","total_trades: 8965\n","=================================\n","environment/nop_value 92025.51470319455\n","environment/total_reward -7974.485296805447\n","environment/total_reward_pct -7.974485296805447\n","environment/total_cost 0.0\n","environment/total_trades 8965\n","train/episode_reward -0.001233959808164218\n","---------------------------------\n","| explained_variance | -0.0383  |\n","| fps                | 148      |\n","| nupdates           | 6600     |\n","| policy_entropy     | 25.9     |\n","| total_timesteps    | 132000   |\n","| value_loss         | 8.88e-07 |\n","---------------------------------\n","environment/nop_value 92888.9717042468\n","environment/total_reward -7111.028295753204\n","environment/total_reward_pct -7.111028295753203\n","environment/total_cost 0.0\n","environment/total_trades 8910\n","train/episode_reward -0.0021001837010029703\n","---------------------------------\n","| explained_variance | -5.41    |\n","| fps                | 148      |\n","| nupdates           | 6700     |\n","| policy_entropy     | 26       |\n","| total_timesteps    | 134000   |\n","| value_loss         | 0.00014  |\n","---------------------------------\n","environment/nop_value 93346.06910621832\n","environment/total_reward -6653.930893781682\n","environment/total_reward_pct -6.6539308937816815\n","environment/total_cost 0.0\n","environment/total_trades 8828\n","train/episode_reward -0.0016925730016679155\n","---------------------------------\n","| explained_variance | 0.0335   |\n","| fps                | 148      |\n","| nupdates           | 6800     |\n","| policy_entropy     | 26.1     |\n","| total_timesteps    | 136000   |\n","| value_loss         | 5.06e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -4.24    |\n","| fps                | 148      |\n","| nupdates           | 6900     |\n","| policy_entropy     | 26.2     |\n","| total_timesteps    | 138000   |\n","| value_loss         | 2.3e-05  |\n","---------------------------------\n","environment/nop_value 91826.23538952055\n","environment/total_reward -8173.764610479455\n","environment/total_reward_pct -8.173764610479454\n","environment/total_cost 0.0\n","environment/total_trades 8966\n","train/episode_reward -0.0022278246269153896\n","---------------------------------\n","| explained_variance | -27.8    |\n","| fps                | 148      |\n","| nupdates           | 7000     |\n","| policy_entropy     | 26.3     |\n","| total_timesteps    | 140000   |\n","| value_loss         | 0.000394 |\n","---------------------------------\n","environment/nop_value 91467.0760378608\n","environment/total_reward -8532.923962139204\n","environment/total_reward_pct -8.532923962139204\n","environment/total_cost 0.0\n","environment/total_trades 8775\n","train/episode_reward -0.0013733990771434038\n","---------------------------------\n","| explained_variance | -1.06    |\n","| fps                | 148      |\n","| nupdates           | 7100     |\n","| policy_entropy     | 26.4     |\n","| total_timesteps    | 142000   |\n","| value_loss         | 7.71e-05 |\n","---------------------------------\n","environment/nop_value 93003.48415392486\n","environment/total_reward -6996.515846075141\n","environment/total_reward_pct -6.996515846075141\n","environment/total_cost 0.0\n","environment/total_trades 8942\n","train/episode_reward -0.0010703445013932652\n","---------------------------------\n","| explained_variance | -1.42    |\n","| fps                | 148      |\n","| nupdates           | 7200     |\n","| policy_entropy     | 26.5     |\n","| total_timesteps    | 144000   |\n","| value_loss         | 0.000141 |\n","---------------------------------\n","environment/nop_value 91693.8815667629\n","environment/total_reward -8306.118433237105\n","environment/total_reward_pct -8.306118433237105\n","environment/total_cost 0.0\n","environment/total_trades 8895\n","train/episode_reward -0.0021015215274805088\n","---------------------------------\n","| explained_variance | 0.0483   |\n","| fps                | 148      |\n","| nupdates           | 7300     |\n","| policy_entropy     | 26.6     |\n","| total_timesteps    | 146000   |\n","| value_loss         | 0.000552 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.131    |\n","| fps                | 148      |\n","| nupdates           | 7400     |\n","| policy_entropy     | 26.7     |\n","| total_timesteps    | 148000   |\n","| value_loss         | 7.48e-05 |\n","---------------------------------\n","environment/nop_value 92100.39659981648\n","environment/total_reward -7899.603400183521\n","environment/total_reward_pct -7.899603400183522\n","environment/total_cost 0.0\n","environment/total_trades 8958\n","train/episode_reward -0.0016381095665143222\n","---------------------------------\n","| explained_variance | -0.129   |\n","| fps                | 148      |\n","| nupdates           | 7500     |\n","| policy_entropy     | 26.9     |\n","| total_timesteps    | 150000   |\n","| value_loss         | 0.000116 |\n","---------------------------------\n","environment/nop_value 92869.96468013708\n","environment/total_reward -7130.035319862916\n","environment/total_reward_pct -7.130035319862917\n","environment/total_cost 0.0\n","environment/total_trades 9010\n","train/episode_reward -0.0026954563087419957\n","---------------------------------\n","| explained_variance | -0.0493  |\n","| fps                | 148      |\n","| nupdates           | 7600     |\n","| policy_entropy     | 27       |\n","| total_timesteps    | 152000   |\n","| value_loss         | 3.58e-05 |\n","---------------------------------\n","environment/nop_value 92133.29987816318\n","environment/total_reward -7866.700121836824\n","environment/total_reward_pct -7.866700121836824\n","environment/total_cost 0.0\n","environment/total_trades 8850\n","train/episode_reward -0.0024922799575535465\n","---------------------------------\n","| explained_variance | 0.00266  |\n","| fps                | 148      |\n","| nupdates           | 7700     |\n","| policy_entropy     | 27.1     |\n","| total_timesteps    | 154000   |\n","| value_loss         | 0.000162 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.24    |\n","| fps                | 148      |\n","| nupdates           | 7800     |\n","| policy_entropy     | 27.1     |\n","| total_timesteps    | 156000   |\n","| value_loss         | 0.000277 |\n","---------------------------------\n","step: 2653, episode: 60\n","end_total_asset: 91845.80\n","total_reward: -8154.20\n","total_cost: 0.00\n","total_trades: 8816\n","=================================\n","environment/nop_value 91845.79951977827\n","environment/total_reward -8154.200480221727\n","environment/total_reward_pct -8.154200480221727\n","environment/total_cost 0.0\n","environment/total_trades 8816\n","train/episode_reward -0.002566934208542807\n","---------------------------------\n","| explained_variance | 0.0639   |\n","| fps                | 148      |\n","| nupdates           | 7900     |\n","| policy_entropy     | 27.2     |\n","| total_timesteps    | 158000   |\n","| value_loss         | 0.000188 |\n","---------------------------------\n","environment/nop_value 93096.67965799826\n","environment/total_reward -6903.320342001738\n","environment/total_reward_pct -6.903320342001738\n","environment/total_cost 0.0\n","environment/total_trades 8920\n","train/episode_reward -0.0033038018021456085\n","---------------------------------\n","| explained_variance | 0.403    |\n","| fps                | 148      |\n","| nupdates           | 8000     |\n","| policy_entropy     | 27.3     |\n","| total_timesteps    | 160000   |\n","| value_loss         | 9.54e-06 |\n","---------------------------------\n","environment/nop_value 93077.65117086718\n","environment/total_reward -6922.348829132825\n","environment/total_reward_pct -6.922348829132825\n","environment/total_cost 0.0\n","environment/total_trades 8807\n","train/episode_reward -0.0018746852225638578\n","---------------------------------\n","| explained_variance | 0.172    |\n","| fps                | 148      |\n","| nupdates           | 8100     |\n","| policy_entropy     | 27.4     |\n","| total_timesteps    | 162000   |\n","| value_loss         | 0.000149 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0773  |\n","| fps                | 148      |\n","| nupdates           | 8200     |\n","| policy_entropy     | 27.5     |\n","| total_timesteps    | 164000   |\n","| value_loss         | 5.33e-05 |\n","---------------------------------\n","environment/nop_value 94323.00024563447\n","environment/total_reward -5676.999754365534\n","environment/total_reward_pct -5.676999754365534\n","environment/total_cost 0.0\n","environment/total_trades 8858\n","train/episode_reward -0.002201209216276766\n","---------------------------------\n","| explained_variance | 0.109    |\n","| fps                | 148      |\n","| nupdates           | 8300     |\n","| policy_entropy     | 27.6     |\n","| total_timesteps    | 166000   |\n","| value_loss         | 0.00396  |\n","---------------------------------\n","environment/nop_value 94128.61526329925\n","environment/total_reward -5871.384736700755\n","environment/total_reward_pct -5.871384736700755\n","environment/total_cost 0.0\n","environment/total_trades 8717\n","train/episode_reward -0.0029386147278768478\n","---------------------------------\n","| explained_variance | 0.112    |\n","| fps                | 148      |\n","| nupdates           | 8400     |\n","| policy_entropy     | 27.7     |\n","| total_timesteps    | 168000   |\n","| value_loss         | 0.00154  |\n","---------------------------------\n","environment/nop_value 92886.79265702576\n","environment/total_reward -7113.207342974245\n","environment/total_reward_pct -7.1132073429742455\n","environment/total_cost 0.0\n","environment/total_trades 8908\n","train/episode_reward -0.0031119243689929138\n","---------------------------------\n","| explained_variance | -0.339   |\n","| fps                | 148      |\n","| nupdates           | 8500     |\n","| policy_entropy     | 27.8     |\n","| total_timesteps    | 170000   |\n","| value_loss         | 3.8e-05  |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0164  |\n","| fps                | 148      |\n","| nupdates           | 8600     |\n","| policy_entropy     | 27.8     |\n","| total_timesteps    | 172000   |\n","| value_loss         | 0.000345 |\n","---------------------------------\n","environment/nop_value 90552.47521155122\n","environment/total_reward -9447.524788448776\n","environment/total_reward_pct -9.447524788448776\n","environment/total_cost 0.0\n","environment/total_trades 8770\n","train/episode_reward -0.0028087563748107644\n","---------------------------------\n","| explained_variance | -1.33    |\n","| fps                | 148      |\n","| nupdates           | 8700     |\n","| policy_entropy     | 28       |\n","| total_timesteps    | 174000   |\n","| value_loss         | 0.000203 |\n","---------------------------------\n","environment/nop_value 92665.58911536446\n","environment/total_reward -7334.4108846355375\n","environment/total_reward_pct -7.334410884635538\n","environment/total_cost 0.0\n","environment/total_trades 9041\n","train/episode_reward -0.001636629605475173\n","---------------------------------\n","| explained_variance | -4.05    |\n","| fps                | 148      |\n","| nupdates           | 8800     |\n","| policy_entropy     | 28.1     |\n","| total_timesteps    | 176000   |\n","| value_loss         | 0.000206 |\n","---------------------------------\n","environment/nop_value 92406.79001530726\n","environment/total_reward -7593.209984692745\n","environment/total_reward_pct -7.593209984692745\n","environment/total_cost 0.0\n","environment/total_trades 8777\n","train/episode_reward -0.0034247217962649302\n","---------------------------------\n","| explained_variance | -1.92    |\n","| fps                | 148      |\n","| nupdates           | 8900     |\n","| policy_entropy     | 28.2     |\n","| total_timesteps    | 178000   |\n","| value_loss         | 6.68e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -4.26    |\n","| fps                | 148      |\n","| nupdates           | 9000     |\n","| policy_entropy     | 28.2     |\n","| total_timesteps    | 180000   |\n","| value_loss         | 3.68e-05 |\n","---------------------------------\n","environment/nop_value 92949.56506030334\n","environment/total_reward -7050.434939696657\n","environment/total_reward_pct -7.0504349396966575\n","environment/total_cost 0.0\n","environment/total_trades 8760\n","train/episode_reward -0.0016150022722446011\n","---------------------------------\n","| explained_variance | 0.0171   |\n","| fps                | 148      |\n","| nupdates           | 9100     |\n","| policy_entropy     | 28.3     |\n","| total_timesteps    | 182000   |\n","| value_loss         | 0.000137 |\n","---------------------------------\n","step: 2653, episode: 70\n","end_total_asset: 91503.76\n","total_reward: -8496.24\n","total_cost: 0.00\n","total_trades: 8796\n","=================================\n","environment/nop_value 91503.75992950962\n","environment/total_reward -8496.240070490385\n","environment/total_reward_pct -8.496240070490385\n","environment/total_cost 0.0\n","environment/total_trades 8796\n","train/episode_reward -0.0026716389310153317\n","---------------------------------\n","| explained_variance | 0.0162   |\n","| fps                | 148      |\n","| nupdates           | 9200     |\n","| policy_entropy     | 28.4     |\n","| total_timesteps    | 184000   |\n","| value_loss         | 4.25e-05 |\n","---------------------------------\n","environment/nop_value 91816.2976299695\n","environment/total_reward -8183.7023700305\n","environment/total_reward_pct -8.1837023700305\n","environment/total_cost 0.0\n","environment/total_trades 8883\n","train/episode_reward -0.002839006497534865\n","---------------------------------\n","| explained_variance | -0.507   |\n","| fps                | 148      |\n","| nupdates           | 9300     |\n","| policy_entropy     | 28.5     |\n","| total_timesteps    | 186000   |\n","| value_loss         | 0.000199 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.42    |\n","| fps                | 148      |\n","| nupdates           | 9400     |\n","| policy_entropy     | 28.6     |\n","| total_timesteps    | 188000   |\n","| value_loss         | 5.31e-05 |\n","---------------------------------\n","environment/nop_value 91860.04966449417\n","environment/total_reward -8139.950335505826\n","environment/total_reward_pct -8.139950335505826\n","environment/total_cost 0.0\n","environment/total_trades 8961\n","train/episode_reward -0.0011860338599581155\n","---------------------------------\n","| explained_variance | 0.278    |\n","| fps                | 148      |\n","| nupdates           | 9500     |\n","| policy_entropy     | 28.6     |\n","| total_timesteps    | 190000   |\n","| value_loss         | 6.02e-05 |\n","---------------------------------\n","environment/nop_value 92381.42764883464\n","environment/total_reward -7618.572351165363\n","environment/total_reward_pct -7.618572351165363\n","environment/total_cost 0.0\n","environment/total_trades 8974\n","train/episode_reward -0.003806334644847084\n","---------------------------------\n","| explained_variance | 0.237    |\n","| fps                | 148      |\n","| nupdates           | 9600     |\n","| policy_entropy     | 28.7     |\n","| total_timesteps    | 192000   |\n","| value_loss         | 0.000432 |\n","---------------------------------\n","environment/nop_value 91832.41691824645\n","environment/total_reward -8167.583081753546\n","environment/total_reward_pct -8.167583081753547\n","environment/total_cost 0.0\n","environment/total_trades 8963\n","train/episode_reward -0.0024667720030163765\n","---------------------------------\n","| explained_variance | 0.0857   |\n","| fps                | 148      |\n","| nupdates           | 9700     |\n","| policy_entropy     | 28.9     |\n","| total_timesteps    | 194000   |\n","| value_loss         | 3.46e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.247   |\n","| fps                | 148      |\n","| nupdates           | 9800     |\n","| policy_entropy     | 29       |\n","| total_timesteps    | 196000   |\n","| value_loss         | 0.000982 |\n","---------------------------------\n","environment/nop_value 92010.915043452\n","environment/total_reward -7989.084956548002\n","environment/total_reward_pct -7.989084956548003\n","environment/total_cost 0.0\n","environment/total_trades 8842\n","train/episode_reward -0.0018221285817562603\n","---------------------------------\n","| explained_variance | 0.158    |\n","| fps                | 148      |\n","| nupdates           | 9900     |\n","| policy_entropy     | 29.1     |\n","| total_timesteps    | 198000   |\n","| value_loss         | 4.22e-06 |\n","---------------------------------\n","environment/nop_value 92308.50520092822\n","environment/total_reward -7691.494799071777\n","environment/total_reward_pct -7.691494799071777\n","environment/total_cost 0.0\n","environment/total_trades 8977\n","train/episode_reward -0.0015623061097445317\n","---------------------------------\n","| explained_variance | -0.777   |\n","| fps                | 148      |\n","| nupdates           | 10000    |\n","| policy_entropy     | 29.1     |\n","| total_timesteps    | 200000   |\n","| value_loss         | 0.000314 |\n","---------------------------------\n","environment/nop_value 92004.02707131812\n","environment/total_reward -7995.9729286818765\n","environment/total_reward_pct -7.995972928681877\n","environment/total_cost 0.0\n","environment/total_trades 9116\n","train/episode_reward -0.002738283875808702\n","---------------------------------\n","| explained_variance | -1.07    |\n","| fps                | 148      |\n","| nupdates           | 10100    |\n","| policy_entropy     | 29.2     |\n","| total_timesteps    | 202000   |\n","| value_loss         | 0.000104 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -4.58    |\n","| fps                | 148      |\n","| nupdates           | 10200    |\n","| policy_entropy     | 29.3     |\n","| total_timesteps    | 204000   |\n","| value_loss         | 0.000414 |\n","---------------------------------\n","environment/nop_value 92986.41767614358\n","environment/total_reward -7013.582323856419\n","environment/total_reward_pct -7.013582323856419\n","environment/total_cost 0.0\n","environment/total_trades 9064\n","train/episode_reward -0.00316728417405393\n","---------------------------------\n","| explained_variance | 0.143    |\n","| fps                | 148      |\n","| nupdates           | 10300    |\n","| policy_entropy     | 29.4     |\n","| total_timesteps    | 206000   |\n","| value_loss         | 6.55e-05 |\n","---------------------------------\n","environment/nop_value 92892.02521343812\n","environment/total_reward -7107.974786561885\n","environment/total_reward_pct -7.107974786561885\n","environment/total_cost 0.0\n","environment/total_trades 8860\n","train/episode_reward -0.0029840281534532554\n","---------------------------------\n","| explained_variance | -0.0358  |\n","| fps                | 148      |\n","| nupdates           | 10400    |\n","| policy_entropy     | 29.5     |\n","| total_timesteps    | 208000   |\n","| value_loss         | 7.21e-05 |\n","---------------------------------\n","step: 2653, episode: 80\n","end_total_asset: 91281.11\n","total_reward: -8718.89\n","total_cost: 0.00\n","total_trades: 8909\n","=================================\n","environment/nop_value 91281.10621253081\n","environment/total_reward -8718.893787469191\n","environment/total_reward_pct -8.718893787469192\n","environment/total_cost 0.0\n","environment/total_trades 8909\n","train/episode_reward -0.00031381139616132715\n","---------------------------------\n","| explained_variance | 0.0688   |\n","| fps                | 148      |\n","| nupdates           | 10500    |\n","| policy_entropy     | 29.6     |\n","| total_timesteps    | 210000   |\n","| value_loss         | 9.97e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.517   |\n","| fps                | 148      |\n","| nupdates           | 10600    |\n","| policy_entropy     | 29.7     |\n","| total_timesteps    | 212000   |\n","| value_loss         | 0.000315 |\n","---------------------------------\n","environment/nop_value 92111.69957207164\n","environment/total_reward -7888.300427928363\n","environment/total_reward_pct -7.888300427928363\n","environment/total_cost 0.0\n","environment/total_trades 8886\n","train/episode_reward -0.0024857626971730496\n","---------------------------------\n","| explained_variance | -0.142   |\n","| fps                | 148      |\n","| nupdates           | 10700    |\n","| policy_entropy     | 29.8     |\n","| total_timesteps    | 214000   |\n","| value_loss         | 3.5e-05  |\n","---------------------------------\n","environment/nop_value 94085.00471513334\n","environment/total_reward -5914.995284866658\n","environment/total_reward_pct -5.914995284866658\n","environment/total_cost 0.0\n","environment/total_trades 8864\n","train/episode_reward -0.00241919165396248\n","---------------------------------\n","| explained_variance | -0.229   |\n","| fps                | 148      |\n","| nupdates           | 10800    |\n","| policy_entropy     | 29.9     |\n","| total_timesteps    | 216000   |\n","| value_loss         | 3.55e-05 |\n","---------------------------------\n","environment/nop_value 93531.57967428661\n","environment/total_reward -6468.420325713392\n","environment/total_reward_pct -6.468420325713392\n","environment/total_cost 0.0\n","environment/total_trades 8758\n","train/episode_reward -0.0014450528665460299\n","---------------------------------\n","| explained_variance | -0.0796  |\n","| fps                | 148      |\n","| nupdates           | 10900    |\n","| policy_entropy     | 30.1     |\n","| total_timesteps    | 218000   |\n","| value_loss         | 4.88e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.27    |\n","| fps                | 148      |\n","| nupdates           | 11000    |\n","| policy_entropy     | 30.2     |\n","| total_timesteps    | 220000   |\n","| value_loss         | 1.58e-05 |\n","---------------------------------\n","environment/nop_value 92516.79194470897\n","environment/total_reward -7483.208055291034\n","environment/total_reward_pct -7.483208055291033\n","environment/total_cost 0.0\n","environment/total_trades 9019\n","train/episode_reward -0.002945759582248866\n","---------------------------------\n","| explained_variance | -1.02    |\n","| fps                | 148      |\n","| nupdates           | 11100    |\n","| policy_entropy     | 30.2     |\n","| total_timesteps    | 222000   |\n","| value_loss         | 0.000193 |\n","---------------------------------\n","environment/nop_value 93521.70015206638\n","environment/total_reward -6478.299847933624\n","environment/total_reward_pct -6.478299847933624\n","environment/total_cost 0.0\n","environment/total_trades 8915\n","train/episode_reward -0.0035814383804012324\n","---------------------------------\n","| explained_variance | -0.0319  |\n","| fps                | 148      |\n","| nupdates           | 11200    |\n","| policy_entropy     | 30.3     |\n","| total_timesteps    | 224000   |\n","| value_loss         | 6.5e-06  |\n","---------------------------------\n","environment/nop_value 93469.51878489405\n","environment/total_reward -6530.481215105945\n","environment/total_reward_pct -6.530481215105945\n","environment/total_cost 0.0\n","environment/total_trades 9080\n","train/episode_reward -0.0017338879061091575\n","---------------------------------\n","| explained_variance | 0.0565   |\n","| fps                | 148      |\n","| nupdates           | 11300    |\n","| policy_entropy     | 30.4     |\n","| total_timesteps    | 226000   |\n","| value_loss         | 6.66e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.463   |\n","| fps                | 148      |\n","| nupdates           | 11400    |\n","| policy_entropy     | 30.5     |\n","| total_timesteps    | 228000   |\n","| value_loss         | 8.08e-05 |\n","---------------------------------\n","environment/nop_value 91770.82275219519\n","environment/total_reward -8229.177247804808\n","environment/total_reward_pct -8.229177247804808\n","environment/total_cost 0.0\n","environment/total_trades 9125\n","train/episode_reward -0.002177649154471874\n","---------------------------------\n","| explained_variance | -1.26    |\n","| fps                | 148      |\n","| nupdates           | 11500    |\n","| policy_entropy     | 30.6     |\n","| total_timesteps    | 230000   |\n","| value_loss         | 1.78e-05 |\n","---------------------------------\n","environment/nop_value 91486.83272065938\n","environment/total_reward -8513.167279340618\n","environment/total_reward_pct -8.513167279340617\n","environment/total_cost 0.0\n","environment/total_trades 8877\n","train/episode_reward -0.002766645764581335\n","---------------------------------\n","| explained_variance | -1.82    |\n","| fps                | 148      |\n","| nupdates           | 11600    |\n","| policy_entropy     | 30.7     |\n","| total_timesteps    | 232000   |\n","| value_loss         | 7.89e-05 |\n","---------------------------------\n","environment/nop_value 92553.74443047527\n","environment/total_reward -7446.255569524728\n","environment/total_reward_pct -7.446255569524729\n","environment/total_cost 0.0\n","environment/total_trades 9159\n","train/episode_reward -0.0027425235927803445\n","---------------------------------\n","| explained_variance | -1.24    |\n","| fps                | 148      |\n","| nupdates           | 11700    |\n","| policy_entropy     | 30.8     |\n","| total_timesteps    | 234000   |\n","| value_loss         | 1.1e-05  |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -2.3     |\n","| fps                | 148      |\n","| nupdates           | 11800    |\n","| policy_entropy     | 30.9     |\n","| total_timesteps    | 236000   |\n","| value_loss         | 5.13e-05 |\n","---------------------------------\n","step: 2653, episode: 90\n","end_total_asset: 93918.67\n","total_reward: -6081.33\n","total_cost: 0.00\n","total_trades: 9055\n","=================================\n","environment/nop_value 93918.66919072147\n","environment/total_reward -6081.33080927853\n","environment/total_reward_pct -6.081330809278531\n","environment/total_cost 0.0\n","environment/total_trades 9055\n","train/episode_reward -0.0033996489283628765\n","---------------------------------\n","| explained_variance | -0.257   |\n","| fps                | 148      |\n","| nupdates           | 11900    |\n","| policy_entropy     | 30.9     |\n","| total_timesteps    | 238000   |\n","| value_loss         | 4.34e-05 |\n","---------------------------------\n","environment/nop_value 93151.52054527067\n","environment/total_reward -6848.479454729328\n","environment/total_reward_pct -6.848479454729328\n","environment/total_cost 0.0\n","environment/total_trades 8932\n","train/episode_reward -8.02203167200787e-05\n","---------------------------------\n","| explained_variance | -0.196   |\n","| fps                | 148      |\n","| nupdates           | 12000    |\n","| policy_entropy     | 31.1     |\n","| total_timesteps    | 240000   |\n","| value_loss         | 0.000214 |\n","---------------------------------\n","environment/nop_value 91640.53545064607\n","environment/total_reward -8359.464549353928\n","environment/total_reward_pct -8.359464549353929\n","environment/total_cost 0.0\n","environment/total_trades 9031\n","train/episode_reward -0.003379110823858355\n","---------------------------------\n","| explained_variance | -20.1    |\n","| fps                | 148      |\n","| nupdates           | 12100    |\n","| policy_entropy     | 31.1     |\n","| total_timesteps    | 242000   |\n","| value_loss         | 3.83e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.08    |\n","| fps                | 148      |\n","| nupdates           | 12200    |\n","| policy_entropy     | 31.2     |\n","| total_timesteps    | 244000   |\n","| value_loss         | 2.99e-05 |\n","---------------------------------\n","environment/nop_value 93509.96776150112\n","environment/total_reward -6490.032238498883\n","environment/total_reward_pct -6.490032238498883\n","environment/total_cost 0.0\n","environment/total_trades 9019\n","train/episode_reward -0.0024516496617274243\n","---------------------------------\n","| explained_variance | 0.0809   |\n","| fps                | 148      |\n","| nupdates           | 12300    |\n","| policy_entropy     | 31.3     |\n","| total_timesteps    | 246000   |\n","| value_loss         | 7.22e-05 |\n","---------------------------------\n","environment/nop_value 92473.2133294244\n","environment/total_reward -7526.786670575602\n","environment/total_reward_pct -7.526786670575603\n","environment/total_cost 0.0\n","environment/total_trades 8998\n","train/episode_reward -0.0037471089955055507\n","---------------------------------\n","| explained_variance | 0.327    |\n","| fps                | 148      |\n","| nupdates           | 12400    |\n","| policy_entropy     | 31.4     |\n","| total_timesteps    | 248000   |\n","| value_loss         | 6.12e-06 |\n","---------------------------------\n","environment/nop_value 91329.74001801776\n","environment/total_reward -8670.259981982235\n","environment/total_reward_pct -8.670259981982236\n","environment/total_cost 0.0\n","environment/total_trades 9023\n","train/episode_reward -0.0006615408972094883\n","---------------------------------\n","| explained_variance | 0.288    |\n","| fps                | 148      |\n","| nupdates           | 12500    |\n","| policy_entropy     | 31.5     |\n","| total_timesteps    | 250000   |\n","| value_loss         | 3.91e-06 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -4.55    |\n","| fps                | 148      |\n","| nupdates           | 12600    |\n","| policy_entropy     | 31.7     |\n","| total_timesteps    | 252000   |\n","| value_loss         | 3.49e-06 |\n","---------------------------------\n","environment/nop_value 92881.61387540326\n","environment/total_reward -7118.386124596742\n","environment/total_reward_pct -7.118386124596741\n","environment/total_cost 0.0\n","environment/total_trades 8859\n","train/episode_reward -0.0032148512325875346\n","---------------------------------\n","| explained_variance | -0.726   |\n","| fps                | 148      |\n","| nupdates           | 12700    |\n","| policy_entropy     | 31.8     |\n","| total_timesteps    | 254000   |\n","| value_loss         | 0.000188 |\n","---------------------------------\n","environment/nop_value 91908.34104003149\n","environment/total_reward -8091.65895996851\n","environment/total_reward_pct -8.09165895996851\n","environment/total_cost 0.0\n","environment/total_trades 9034\n","train/episode_reward -0.00028925002563046293\n","---------------------------------\n","| explained_variance | -0.394   |\n","| fps                | 148      |\n","| nupdates           | 12800    |\n","| policy_entropy     | 31.9     |\n","| total_timesteps    | 256000   |\n","| value_loss         | 0.000485 |\n","---------------------------------\n","environment/nop_value 91808.02333104803\n","environment/total_reward -8191.976668951975\n","environment/total_reward_pct -8.191976668951975\n","environment/total_cost 0.0\n","environment/total_trades 8967\n","train/episode_reward -0.0027249982207009455\n","---------------------------------\n","| explained_variance | -4.6     |\n","| fps                | 148      |\n","| nupdates           | 12900    |\n","| policy_entropy     | 32       |\n","| total_timesteps    | 258000   |\n","| value_loss         | 1.86e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -3.45    |\n","| fps                | 148      |\n","| nupdates           | 13000    |\n","| policy_entropy     | 32.1     |\n","| total_timesteps    | 260000   |\n","| value_loss         | 1.68e-05 |\n","---------------------------------\n","environment/nop_value 93212.05170822589\n","environment/total_reward -6787.948291774112\n","environment/total_reward_pct -6.787948291774111\n","environment/total_cost 0.0\n","environment/total_trades 9078\n","train/episode_reward -0.002591549381903315\n","---------------------------------\n","| explained_variance | -0.493   |\n","| fps                | 148      |\n","| nupdates           | 13100    |\n","| policy_entropy     | 32.2     |\n","| total_timesteps    | 262000   |\n","| value_loss         | 5.21e-06 |\n","---------------------------------\n","step: 2653, episode: 100\n","end_total_asset: 92210.10\n","total_reward: -7789.90\n","total_cost: 0.00\n","total_trades: 8847\n","=================================\n","environment/nop_value 92210.09968846638\n","environment/total_reward -7789.900311533624\n","environment/total_reward_pct -7.789900311533623\n","environment/total_cost 0.0\n","environment/total_trades 8847\n","train/episode_reward -0.003064708831853932\n","---------------------------------\n","| explained_variance | -1.34    |\n","| fps                | 148      |\n","| nupdates           | 13200    |\n","| policy_entropy     | 32.2     |\n","| total_timesteps    | 264000   |\n","| value_loss         | 3.93e-05 |\n","---------------------------------\n","environment/nop_value 91386.54702402918\n","environment/total_reward -8613.452975970824\n","environment/total_reward_pct -8.613452975970825\n","environment/total_cost 0.0\n","environment/total_trades 8778\n","train/episode_reward -0.0028331285833221045\n","---------------------------------\n","| explained_variance | -292     |\n","| fps                | 148      |\n","| nupdates           | 13300    |\n","| policy_entropy     | 32.3     |\n","| total_timesteps    | 266000   |\n","| value_loss         | 8.53e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -5.18    |\n","| fps                | 148      |\n","| nupdates           | 13400    |\n","| policy_entropy     | 32.4     |\n","| total_timesteps    | 268000   |\n","| value_loss         | 3.07e-05 |\n","---------------------------------\n","environment/nop_value 93213.61747142431\n","environment/total_reward -6786.38252857569\n","environment/total_reward_pct -6.7863825285756905\n","environment/total_cost 0.0\n","environment/total_trades 8887\n","train/episode_reward -0.0003862777673755773\n","---------------------------------\n","| explained_variance | 0.732    |\n","| fps                | 148      |\n","| nupdates           | 13500    |\n","| policy_entropy     | 32.5     |\n","| total_timesteps    | 270000   |\n","| value_loss         | 2.18e-05 |\n","---------------------------------\n","environment/nop_value 95020.83562904595\n","environment/total_reward -4979.164370954051\n","environment/total_reward_pct -4.979164370954051\n","environment/total_cost 0.0\n","environment/total_trades 8910\n","train/episode_reward -0.001348686932171404\n","---------------------------------\n","| explained_variance | -1.12    |\n","| fps                | 148      |\n","| nupdates           | 13600    |\n","| policy_entropy     | 32.6     |\n","| total_timesteps    | 272000   |\n","| value_loss         | 8.41e-05 |\n","---------------------------------\n","environment/nop_value 92719.79850589106\n","environment/total_reward -7280.201494108944\n","environment/total_reward_pct -7.280201494108944\n","environment/total_cost 0.0\n","environment/total_trades 9077\n","train/episode_reward -0.0017418751277786214\n","---------------------------------\n","| explained_variance | -0.718   |\n","| fps                | 148      |\n","| nupdates           | 13700    |\n","| policy_entropy     | 32.7     |\n","| total_timesteps    | 274000   |\n","| value_loss         | 1.15e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -20.2    |\n","| fps                | 148      |\n","| nupdates           | 13800    |\n","| policy_entropy     | 32.8     |\n","| total_timesteps    | 276000   |\n","| value_loss         | 1.87e-05 |\n","---------------------------------\n","environment/nop_value 93787.70722014918\n","environment/total_reward -6212.292779850817\n","environment/total_reward_pct -6.212292779850817\n","environment/total_cost 0.0\n","environment/total_trades 9030\n","train/episode_reward -0.002193224587592704\n","---------------------------------\n","| explained_variance | -0.0165  |\n","| fps                | 148      |\n","| nupdates           | 13900    |\n","| policy_entropy     | 32.9     |\n","| total_timesteps    | 278000   |\n","| value_loss         | 0.000475 |\n","---------------------------------\n","environment/nop_value 92994.39067649879\n","environment/total_reward -7005.609323501209\n","environment/total_reward_pct -7.005609323501208\n","environment/total_cost 0.0\n","environment/total_trades 9012\n","train/episode_reward -0.0014922117385387538\n","---------------------------------\n","| explained_variance | -1.47    |\n","| fps                | 148      |\n","| nupdates           | 14000    |\n","| policy_entropy     | 33       |\n","| total_timesteps    | 280000   |\n","| value_loss         | 0.000198 |\n","---------------------------------\n","environment/nop_value 92759.53171956367\n","environment/total_reward -7240.468280436326\n","environment/total_reward_pct -7.240468280436326\n","environment/total_cost 0.0\n","environment/total_trades 8859\n","train/episode_reward -0.0025355181895749413\n","---------------------------------\n","| explained_variance | 0.164    |\n","| fps                | 148      |\n","| nupdates           | 14100    |\n","| policy_entropy     | 33.1     |\n","| total_timesteps    | 282000   |\n","| value_loss         | 9.19e-05 |\n","---------------------------------\n","environment/nop_value 92047.29603967235\n","environment/total_reward -7952.70396032765\n","environment/total_reward_pct -7.952703960327649\n","environment/total_cost 0.0\n","environment/total_trades 9122\n","train/episode_reward -0.0010810623005861998\n","---------------------------------\n","| explained_variance | -0.314   |\n","| fps                | 148      |\n","| nupdates           | 14200    |\n","| policy_entropy     | 33.2     |\n","| total_timesteps    | 284000   |\n","| value_loss         | 0.000221 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.00252  |\n","| fps                | 148      |\n","| nupdates           | 14300    |\n","| policy_entropy     | 33.3     |\n","| total_timesteps    | 286000   |\n","| value_loss         | 6.62e-05 |\n","---------------------------------\n","environment/nop_value 91238.62711652588\n","environment/total_reward -8761.37288347412\n","environment/total_reward_pct -8.76137288347412\n","environment/total_cost 0.0\n","environment/total_trades 8719\n","train/episode_reward -0.0026510192667410595\n","---------------------------------\n","| explained_variance | -1.82    |\n","| fps                | 148      |\n","| nupdates           | 14400    |\n","| policy_entropy     | 33.4     |\n","| total_timesteps    | 288000   |\n","| value_loss         | 5.21e-05 |\n","---------------------------------\n","step: 2653, episode: 110\n","end_total_asset: 92078.99\n","total_reward: -7921.01\n","total_cost: 0.00\n","total_trades: 8894\n","=================================\n","environment/nop_value 92078.99435428536\n","environment/total_reward -7921.005645714642\n","environment/total_reward_pct -7.921005645714642\n","environment/total_cost 0.0\n","environment/total_trades 8894\n","train/episode_reward -0.0024153058877549485\n","---------------------------------\n","| explained_variance | -0.0636  |\n","| fps                | 148      |\n","| nupdates           | 14500    |\n","| policy_entropy     | 33.5     |\n","| total_timesteps    | 290000   |\n","| value_loss         | 6.05e-05 |\n","---------------------------------\n","environment/nop_value 92384.60107733229\n","environment/total_reward -7615.398922667708\n","environment/total_reward_pct -7.6153989226677075\n","environment/total_cost 0.0\n","environment/total_trades 8525\n","train/episode_reward -0.002971510541121825\n","---------------------------------\n","| explained_variance | -13.4    |\n","| fps                | 148      |\n","| nupdates           | 14600    |\n","| policy_entropy     | 33.6     |\n","| total_timesteps    | 292000   |\n","| value_loss         | 0.000118 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.0972   |\n","| fps                | 148      |\n","| nupdates           | 14700    |\n","| policy_entropy     | 33.7     |\n","| total_timesteps    | 294000   |\n","| value_loss         | 5.82e-05 |\n","---------------------------------\n","environment/nop_value 92069.44382131522\n","environment/total_reward -7930.556178684783\n","environment/total_reward_pct -7.930556178684784\n","environment/total_cost 0.0\n","environment/total_trades 8895\n","train/episode_reward -0.0011981495190426358\n","---------------------------------\n","| explained_variance | -0.537   |\n","| fps                | 148      |\n","| nupdates           | 14800    |\n","| policy_entropy     | 33.8     |\n","| total_timesteps    | 296000   |\n","| value_loss         | 1.58e-05 |\n","---------------------------------\n","environment/nop_value 91705.62912818984\n","environment/total_reward -8294.370871810155\n","environment/total_reward_pct -8.294370871810155\n","environment/total_cost 0.0\n","environment/total_trades 9005\n","train/episode_reward -0.0017612361516570673\n","---------------------------------\n","| explained_variance | -0.0805  |\n","| fps                | 148      |\n","| nupdates           | 14900    |\n","| policy_entropy     | 33.9     |\n","| total_timesteps    | 298000   |\n","| value_loss         | 4.82e-05 |\n","---------------------------------\n","environment/nop_value 92567.05449678587\n","environment/total_reward -7432.945503214127\n","environment/total_reward_pct -7.4329455032141265\n","environment/total_cost 0.0\n","environment/total_trades 8921\n","train/episode_reward -0.0021263688963954336\n","---------------------------------\n","| explained_variance | 0.267    |\n","| fps                | 148      |\n","| nupdates           | 15000    |\n","| policy_entropy     | 34       |\n","| total_timesteps    | 300000   |\n","| value_loss         | 3.02e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -3.87    |\n","| fps                | 148      |\n","| nupdates           | 15100    |\n","| policy_entropy     | 34.1     |\n","| total_timesteps    | 302000   |\n","| value_loss         | 4.98e-05 |\n","---------------------------------\n","environment/nop_value 92961.11076902554\n","environment/total_reward -7038.889230974455\n","environment/total_reward_pct -7.038889230974456\n","environment/total_cost 0.0\n","environment/total_trades 8929\n","train/episode_reward -0.003412024992253282\n","---------------------------------\n","| explained_variance | 0.0523   |\n","| fps                | 148      |\n","| nupdates           | 15200    |\n","| policy_entropy     | 34.2     |\n","| total_timesteps    | 304000   |\n","| value_loss         | 0.000395 |\n","---------------------------------\n","environment/nop_value 92177.61415532511\n","environment/total_reward -7822.385844674893\n","environment/total_reward_pct -7.822385844674892\n","environment/total_cost 0.0\n","environment/total_trades 8874\n","train/episode_reward -0.002851345655602927\n","---------------------------------\n","| explained_variance | 0.526    |\n","| fps                | 148      |\n","| nupdates           | 15300    |\n","| policy_entropy     | 34.3     |\n","| total_timesteps    | 306000   |\n","| value_loss         | 4.57e-05 |\n","---------------------------------\n","environment/nop_value 92490.28929456085\n","environment/total_reward -7509.710705439153\n","environment/total_reward_pct -7.5097107054391525\n","environment/total_cost 0.0\n","environment/total_trades 8929\n","train/episode_reward -0.0011737954587093555\n","---------------------------------\n","| explained_variance | -0.986   |\n","| fps                | 148      |\n","| nupdates           | 15400    |\n","| policy_entropy     | 34.5     |\n","| total_timesteps    | 308000   |\n","| value_loss         | 4.89e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.538   |\n","| fps                | 148      |\n","| nupdates           | 15500    |\n","| policy_entropy     | 34.6     |\n","| total_timesteps    | 310000   |\n","| value_loss         | 3.96e-05 |\n","---------------------------------\n","environment/nop_value 91808.09118263405\n","environment/total_reward -8191.908817365955\n","environment/total_reward_pct -8.191908817365954\n","environment/total_cost 0.0\n","environment/total_trades 9016\n","train/episode_reward -0.003556425228698936\n","---------------------------------\n","| explained_variance | -0.00772 |\n","| fps                | 148      |\n","| nupdates           | 15600    |\n","| policy_entropy     | 34.6     |\n","| total_timesteps    | 312000   |\n","| value_loss         | 0.00177  |\n","---------------------------------\n","environment/nop_value 93012.0904293275\n","environment/total_reward -6987.909570672506\n","environment/total_reward_pct -6.987909570672506\n","environment/total_cost 0.0\n","environment/total_trades 8970\n","train/episode_reward -0.002988128446611518\n","---------------------------------\n","| explained_variance | -0.713   |\n","| fps                | 148      |\n","| nupdates           | 15700    |\n","| policy_entropy     | 34.7     |\n","| total_timesteps    | 314000   |\n","| value_loss         | 1.68e-05 |\n","---------------------------------\n","step: 2653, episode: 120\n","end_total_asset: 93145.00\n","total_reward: -6855.00\n","total_cost: 0.00\n","total_trades: 9035\n","=================================\n","environment/nop_value 93145.00001167144\n","environment/total_reward -6854.999988328564\n","environment/total_reward_pct -6.854999988328564\n","environment/total_cost 0.0\n","environment/total_trades 9035\n","train/episode_reward -0.0009242334451992065\n","---------------------------------\n","| explained_variance | -0.0547  |\n","| fps                | 148      |\n","| nupdates           | 15800    |\n","| policy_entropy     | 34.8     |\n","| total_timesteps    | 316000   |\n","| value_loss         | 7.64e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -4.84    |\n","| fps                | 148      |\n","| nupdates           | 15900    |\n","| policy_entropy     | 34.9     |\n","| total_timesteps    | 318000   |\n","| value_loss         | 0.000156 |\n","---------------------------------\n","environment/nop_value 91946.20141821072\n","environment/total_reward -8053.798581789277\n","environment/total_reward_pct -8.053798581789277\n","environment/total_cost 0.0\n","environment/total_trades 8958\n","train/episode_reward -0.0010722617756779072\n","---------------------------------\n","| explained_variance | -0.0958  |\n","| fps                | 148      |\n","| nupdates           | 16000    |\n","| policy_entropy     | 35       |\n","| total_timesteps    | 320000   |\n","| value_loss         | 1.89e-05 |\n","---------------------------------\n","environment/nop_value 93688.17258138437\n","environment/total_reward -6311.827418615634\n","environment/total_reward_pct -6.311827418615634\n","environment/total_cost 0.0\n","environment/total_trades 8854\n","train/episode_reward -0.003199502622486034\n","---------------------------------\n","| explained_variance | 0.128    |\n","| fps                | 148      |\n","| nupdates           | 16100    |\n","| policy_entropy     | 35.1     |\n","| total_timesteps    | 322000   |\n","| value_loss         | 3.72e-05 |\n","---------------------------------\n","environment/nop_value 91538.18112497998\n","environment/total_reward -8461.81887502002\n","environment/total_reward_pct -8.46181887502002\n","environment/total_cost 0.0\n","environment/total_trades 8884\n","train/episode_reward -0.0022812272666895297\n","---------------------------------\n","| explained_variance | 0.0229   |\n","| fps                | 148      |\n","| nupdates           | 16200    |\n","| policy_entropy     | 35.2     |\n","| total_timesteps    | 324000   |\n","| value_loss         | 0.000219 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -2.69    |\n","| fps                | 148      |\n","| nupdates           | 16300    |\n","| policy_entropy     | 35.3     |\n","| total_timesteps    | 326000   |\n","| value_loss         | 1.43e-05 |\n","---------------------------------\n","environment/nop_value 92907.458545061\n","environment/total_reward -7092.541454938997\n","environment/total_reward_pct -7.092541454938997\n","environment/total_cost 0.0\n","environment/total_trades 8821\n","train/episode_reward -0.003232397009266424\n","---------------------------------\n","| explained_variance | 0.427    |\n","| fps                | 148      |\n","| nupdates           | 16400    |\n","| policy_entropy     | 35.4     |\n","| total_timesteps    | 328000   |\n","| value_loss         | 9.75e-05 |\n","---------------------------------\n","environment/nop_value 92134.9069046367\n","environment/total_reward -7865.093095363307\n","environment/total_reward_pct -7.8650930953633065\n","environment/total_cost 0.0\n","environment/total_trades 8941\n","train/episode_reward -0.001097364871679747\n","---------------------------------\n","| explained_variance | 0.0687   |\n","| fps                | 148      |\n","| nupdates           | 16500    |\n","| policy_entropy     | 35.5     |\n","| total_timesteps    | 330000   |\n","| value_loss         | 9.82e-05 |\n","---------------------------------\n","environment/nop_value 92903.8208567704\n","environment/total_reward -7096.179143229601\n","environment/total_reward_pct -7.096179143229602\n","environment/total_cost 0.0\n","environment/total_trades 8827\n","train/episode_reward -0.0006408670790842735\n","---------------------------------\n","| explained_variance | -0.0343  |\n","| fps                | 148      |\n","| nupdates           | 16600    |\n","| policy_entropy     | 35.6     |\n","| total_timesteps    | 332000   |\n","| value_loss         | 0.000195 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.284   |\n","| fps                | 148      |\n","| nupdates           | 16700    |\n","| policy_entropy     | 35.7     |\n","| total_timesteps    | 334000   |\n","| value_loss         | 0.000179 |\n","---------------------------------\n","environment/nop_value 91708.40262956051\n","environment/total_reward -8291.597370439486\n","environment/total_reward_pct -8.291597370439485\n","environment/total_cost 0.0\n","environment/total_trades 8861\n","train/episode_reward -0.0025447818017317334\n","---------------------------------\n","| explained_variance | -0.146   |\n","| fps                | 148      |\n","| nupdates           | 16800    |\n","| policy_entropy     | 35.8     |\n","| total_timesteps    | 336000   |\n","| value_loss         | 1.46e-05 |\n","---------------------------------\n","environment/nop_value 92973.08511629576\n","environment/total_reward -7026.914883704245\n","environment/total_reward_pct -7.026914883704245\n","environment/total_cost 0.0\n","environment/total_trades 9092\n","train/episode_reward -0.001135121693740075\n","---------------------------------\n","| explained_variance | -0.225   |\n","| fps                | 148      |\n","| nupdates           | 16900    |\n","| policy_entropy     | 35.9     |\n","| total_timesteps    | 338000   |\n","| value_loss         | 7.21e-05 |\n","---------------------------------\n","environment/nop_value 91549.53524829389\n","environment/total_reward -8450.46475170611\n","environment/total_reward_pct -8.45046475170611\n","environment/total_cost 0.0\n","environment/total_trades 8850\n","train/episode_reward -0.003182944082460017\n","---------------------------------\n","| explained_variance | -2.73    |\n","| fps                | 148      |\n","| nupdates           | 17000    |\n","| policy_entropy     | 36       |\n","| total_timesteps    | 340000   |\n","| value_loss         | 0.000131 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.55     |\n","| fps                | 148      |\n","| nupdates           | 17100    |\n","| policy_entropy     | 36.1     |\n","| total_timesteps    | 342000   |\n","| value_loss         | 1.34e-05 |\n","---------------------------------\n","step: 2653, episode: 130\n","end_total_asset: 91841.65\n","total_reward: -8158.35\n","total_cost: 0.00\n","total_trades: 8974\n","=================================\n","environment/nop_value 91841.65324379779\n","environment/total_reward -8158.346756202212\n","environment/total_reward_pct -8.158346756202214\n","environment/total_cost 0.0\n","environment/total_trades 8974\n","train/episode_reward -0.002604046535394446\n","---------------------------------\n","| explained_variance | 0.0273   |\n","| fps                | 148      |\n","| nupdates           | 17200    |\n","| policy_entropy     | 36.2     |\n","| total_timesteps    | 344000   |\n","| value_loss         | 6.38e-05 |\n","---------------------------------\n","environment/nop_value 93672.36561930653\n","environment/total_reward -6327.634380693475\n","environment/total_reward_pct -6.327634380693474\n","environment/total_cost 0.0\n","environment/total_trades 8840\n","train/episode_reward -0.0010758896102648578\n","---------------------------------\n","| explained_variance | -3.23    |\n","| fps                | 148      |\n","| nupdates           | 17300    |\n","| policy_entropy     | 36.2     |\n","| total_timesteps    | 346000   |\n","| value_loss         | 0.000211 |\n","---------------------------------\n","environment/nop_value 93054.35044948674\n","environment/total_reward -6945.6495505132625\n","environment/total_reward_pct -6.945649550513262\n","environment/total_cost 0.0\n","environment/total_trades 8714\n","train/episode_reward -0.001846071681304602\n","---------------------------------\n","| explained_variance | -3.33    |\n","| fps                | 148      |\n","| nupdates           | 17400    |\n","| policy_entropy     | 36.3     |\n","| total_timesteps    | 348000   |\n","| value_loss         | 6.51e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.9     |\n","| fps                | 148      |\n","| nupdates           | 17500    |\n","| policy_entropy     | 36.5     |\n","| total_timesteps    | 350000   |\n","| value_loss         | 0.000157 |\n","---------------------------------\n","environment/nop_value 93020.40815644621\n","environment/total_reward -6979.59184355379\n","environment/total_reward_pct -6.97959184355379\n","environment/total_cost 0.0\n","environment/total_trades 9052\n","train/episode_reward -0.0009143655541964109\n","---------------------------------\n","| explained_variance | 0.468    |\n","| fps                | 148      |\n","| nupdates           | 17600    |\n","| policy_entropy     | 36.5     |\n","| total_timesteps    | 352000   |\n","| value_loss         | 2.69e-05 |\n","---------------------------------\n","environment/nop_value 92688.6065503369\n","environment/total_reward -7311.393449663097\n","environment/total_reward_pct -7.311393449663098\n","environment/total_cost 0.0\n","environment/total_trades 8987\n","train/episode_reward -0.0035206677752823456\n","---------------------------------\n","| explained_variance | -0.772   |\n","| fps                | 148      |\n","| nupdates           | 17700    |\n","| policy_entropy     | 36.6     |\n","| total_timesteps    | 354000   |\n","| value_loss         | 3.18e-05 |\n","---------------------------------\n","environment/nop_value 91774.37147256933\n","environment/total_reward -8225.628527430672\n","environment/total_reward_pct -8.225628527430672\n","environment/total_cost 0.0\n","environment/total_trades 8863\n","train/episode_reward -0.0022716691067616924\n","---------------------------------\n","| explained_variance | -0.542   |\n","| fps                | 148      |\n","| nupdates           | 17800    |\n","| policy_entropy     | 36.7     |\n","| total_timesteps    | 356000   |\n","| value_loss         | 0.000129 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -3.44    |\n","| fps                | 148      |\n","| nupdates           | 17900    |\n","| policy_entropy     | 36.8     |\n","| total_timesteps    | 358000   |\n","| value_loss         | 1.06e-05 |\n","---------------------------------\n","environment/nop_value 92727.38757239108\n","environment/total_reward -7272.612427608925\n","environment/total_reward_pct -7.272612427608925\n","environment/total_cost 0.0\n","environment/total_trades 8935\n","train/episode_reward -0.001857799828844145\n","---------------------------------\n","| explained_variance | 0.0665   |\n","| fps                | 148      |\n","| nupdates           | 18000    |\n","| policy_entropy     | 36.9     |\n","| total_timesteps    | 360000   |\n","| value_loss         | 1e-05    |\n","---------------------------------\n","environment/nop_value 92771.55601060795\n","environment/total_reward -7228.44398939205\n","environment/total_reward_pct -7.22844398939205\n","environment/total_cost 0.0\n","environment/total_trades 8893\n","train/episode_reward -0.0022285057592220255\n","---------------------------------\n","| explained_variance | -0.0499  |\n","| fps                | 148      |\n","| nupdates           | 18100    |\n","| policy_entropy     | 37       |\n","| total_timesteps    | 362000   |\n","| value_loss         | 0.00011  |\n","---------------------------------\n","environment/nop_value 91869.07438405833\n","environment/total_reward -8130.925615941669\n","environment/total_reward_pct -8.130925615941669\n","environment/total_cost 0.0\n","environment/total_trades 9038\n","train/episode_reward -0.0027880921482807026\n","---------------------------------\n","| explained_variance | 0.0111   |\n","| fps                | 148      |\n","| nupdates           | 18200    |\n","| policy_entropy     | 37.1     |\n","| total_timesteps    | 364000   |\n","| value_loss         | 0.000272 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.88    |\n","| fps                | 148      |\n","| nupdates           | 18300    |\n","| policy_entropy     | 37.2     |\n","| total_timesteps    | 366000   |\n","| value_loss         | 0.000166 |\n","---------------------------------\n","environment/nop_value 91617.33490494979\n","environment/total_reward -8382.665095050208\n","environment/total_reward_pct -8.382665095050209\n","environment/total_cost 0.0\n","environment/total_trades 9042\n","train/episode_reward -0.0018995341070607537\n","---------------------------------\n","| explained_variance | -0.576   |\n","| fps                | 148      |\n","| nupdates           | 18400    |\n","| policy_entropy     | 37.3     |\n","| total_timesteps    | 368000   |\n","| value_loss         | 9.8e-06  |\n","---------------------------------\n","step: 2653, episode: 140\n","end_total_asset: 92310.96\n","total_reward: -7689.04\n","total_cost: 0.00\n","total_trades: 8942\n","=================================\n","environment/nop_value 92310.96443793457\n","environment/total_reward -7689.03556206543\n","environment/total_reward_pct -7.68903556206543\n","environment/total_cost 0.0\n","environment/total_trades 8942\n","train/episode_reward -0.0022228741972649007\n","---------------------------------\n","| explained_variance | -11.6    |\n","| fps                | 148      |\n","| nupdates           | 18500    |\n","| policy_entropy     | 37.4     |\n","| total_timesteps    | 370000   |\n","| value_loss         | 0.000392 |\n","---------------------------------\n","environment/nop_value 93342.261469365\n","environment/total_reward -6657.738530635004\n","environment/total_reward_pct -6.6577385306350045\n","environment/total_cost 0.0\n","environment/total_trades 8945\n","train/episode_reward -0.0009850435222135275\n","---------------------------------\n","| explained_variance | -0.374   |\n","| fps                | 148      |\n","| nupdates           | 18600    |\n","| policy_entropy     | 37.5     |\n","| total_timesteps    | 372000   |\n","| value_loss         | 7.12e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.0544   |\n","| fps                | 148      |\n","| nupdates           | 18700    |\n","| policy_entropy     | 37.6     |\n","| total_timesteps    | 374000   |\n","| value_loss         | 3.18e-05 |\n","---------------------------------\n","environment/nop_value 92129.32630053378\n","environment/total_reward -7870.673699466221\n","environment/total_reward_pct -7.87067369946622\n","environment/total_cost 0.0\n","environment/total_trades 8939\n","train/episode_reward -0.0025200125182789634\n","---------------------------------\n","| explained_variance | 0.12     |\n","| fps                | 148      |\n","| nupdates           | 18800    |\n","| policy_entropy     | 37.7     |\n","| total_timesteps    | 376000   |\n","| value_loss         | 1.97e-05 |\n","---------------------------------\n","environment/nop_value 93206.88637853235\n","environment/total_reward -6793.113621467652\n","environment/total_reward_pct -6.7931136214676515\n","environment/total_cost 0.0\n","environment/total_trades 8950\n","train/episode_reward -0.0010278276503726375\n","---------------------------------\n","| explained_variance | -0.567   |\n","| fps                | 148      |\n","| nupdates           | 18900    |\n","| policy_entropy     | 37.8     |\n","| total_timesteps    | 378000   |\n","| value_loss         | 0.000224 |\n","---------------------------------\n","environment/nop_value 92453.35811889487\n","environment/total_reward -7546.641881105126\n","environment/total_reward_pct -7.546641881105126\n","environment/total_cost 0.0\n","environment/total_trades 9046\n","train/episode_reward -0.0023131627080656475\n","---------------------------------\n","| explained_variance | -0.546   |\n","| fps                | 148      |\n","| nupdates           | 19000    |\n","| policy_entropy     | 37.9     |\n","| total_timesteps    | 380000   |\n","| value_loss         | 8.24e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | 0.249    |\n","| fps                | 148      |\n","| nupdates           | 19100    |\n","| policy_entropy     | 38       |\n","| total_timesteps    | 382000   |\n","| value_loss         | 2.57e-06 |\n","---------------------------------\n","environment/nop_value 92885.46474798294\n","environment/total_reward -7114.535252017056\n","environment/total_reward_pct -7.114535252017057\n","environment/total_cost 0.0\n","environment/total_trades 9084\n","train/episode_reward -0.002530759058491094\n","---------------------------------\n","| explained_variance | -0.0573  |\n","| fps                | 148      |\n","| nupdates           | 19200    |\n","| policy_entropy     | 38.1     |\n","| total_timesteps    | 384000   |\n","| value_loss         | 0.00018  |\n","---------------------------------\n","environment/nop_value 92245.73655322638\n","environment/total_reward -7754.263446773621\n","environment/total_reward_pct -7.754263446773621\n","environment/total_cost 0.0\n","environment/total_trades 8968\n","train/episode_reward -0.0022009239492414056\n","---------------------------------\n","| explained_variance | 0.258    |\n","| fps                | 148      |\n","| nupdates           | 19300    |\n","| policy_entropy     | 38.2     |\n","| total_timesteps    | 386000   |\n","| value_loss         | 6.15e-05 |\n","---------------------------------\n","environment/nop_value 92589.99583087538\n","environment/total_reward -7410.004169124615\n","environment/total_reward_pct -7.410004169124615\n","environment/total_cost 0.0\n","environment/total_trades 9002\n","train/episode_reward -0.0007550660446606344\n","---------------------------------\n","| explained_variance | -0.494   |\n","| fps                | 148      |\n","| nupdates           | 19400    |\n","| policy_entropy     | 38.3     |\n","| total_timesteps    | 388000   |\n","| value_loss         | 6.49e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.115   |\n","| fps                | 148      |\n","| nupdates           | 19500    |\n","| policy_entropy     | 38.4     |\n","| total_timesteps    | 390000   |\n","| value_loss         | 2.6e-06  |\n","---------------------------------\n","environment/nop_value 92029.67633683828\n","environment/total_reward -7970.323663161718\n","environment/total_reward_pct -7.970323663161719\n","environment/total_cost 0.0\n","environment/total_trades 8817\n","train/episode_reward -0.0017568761419213842\n","---------------------------------\n","| explained_variance | 0.0238   |\n","| fps                | 148      |\n","| nupdates           | 19600    |\n","| policy_entropy     | 38.5     |\n","| total_timesteps    | 392000   |\n","| value_loss         | 6.83e-05 |\n","---------------------------------\n","environment/nop_value 92468.76924822708\n","environment/total_reward -7531.2307517729205\n","environment/total_reward_pct -7.53123075177292\n","environment/total_cost 0.0\n","environment/total_trades 9160\n","train/episode_reward -0.0020069276892958443\n","---------------------------------\n","| explained_variance | -2.91    |\n","| fps                | 148      |\n","| nupdates           | 19700    |\n","| policy_entropy     | 38.6     |\n","| total_timesteps    | 394000   |\n","| value_loss         | 0.000214 |\n","---------------------------------\n","step: 2653, episode: 150\n","end_total_asset: 93825.00\n","total_reward: -6175.00\n","total_cost: 0.00\n","total_trades: 9012\n","=================================\n","environment/nop_value 93825.00477782598\n","environment/total_reward -6174.995222174024\n","environment/total_reward_pct -6.174995222174024\n","environment/total_cost 0.0\n","environment/total_trades 9012\n","train/episode_reward -0.0022522999488981442\n","---------------------------------\n","| explained_variance | -6.27    |\n","| fps                | 148      |\n","| nupdates           | 19800    |\n","| policy_entropy     | 38.7     |\n","| total_timesteps    | 396000   |\n","| value_loss         | 2.55e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.33    |\n","| fps                | 148      |\n","| nupdates           | 19900    |\n","| policy_entropy     | 38.8     |\n","| total_timesteps    | 398000   |\n","| value_loss         | 6.37e-06 |\n","---------------------------------\n","environment/nop_value 92308.17049690665\n","environment/total_reward -7691.829503093351\n","environment/total_reward_pct -7.691829503093352\n","environment/total_cost 0.0\n","environment/total_trades 9021\n","train/episode_reward -0.002583286673721159\n","---------------------------------\n","| explained_variance | 0.136    |\n","| fps                | 148      |\n","| nupdates           | 20000    |\n","| policy_entropy     | 38.8     |\n","| total_timesteps    | 400000   |\n","| value_loss         | 4.56e-05 |\n","---------------------------------\n","environment/nop_value 92327.38008411357\n","environment/total_reward -7672.619915886433\n","environment/total_reward_pct -7.672619915886433\n","environment/total_cost 0.0\n","environment/total_trades 9011\n","train/episode_reward -0.000745994841324864\n","---------------------------------\n","| explained_variance | -0.848   |\n","| fps                | 148      |\n","| nupdates           | 20100    |\n","| policy_entropy     | 38.9     |\n","| total_timesteps    | 402000   |\n","| value_loss         | 0.000162 |\n","---------------------------------\n","environment/nop_value 93055.26510159865\n","environment/total_reward -6944.7348984013515\n","environment/total_reward_pct -6.944734898401352\n","environment/total_cost 0.0\n","environment/total_trades 8902\n","train/episode_reward -0.0022822251440622497\n","---------------------------------\n","| explained_variance | 0.402    |\n","| fps                | 148      |\n","| nupdates           | 20200    |\n","| policy_entropy     | 39       |\n","| total_timesteps    | 404000   |\n","| value_loss         | 2.31e-06 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -1.85    |\n","| fps                | 148      |\n","| nupdates           | 20300    |\n","| policy_entropy     | 39.1     |\n","| total_timesteps    | 406000   |\n","| value_loss         | 1.37e-06 |\n","---------------------------------\n","environment/nop_value 92674.23148448895\n","environment/total_reward -7325.768515511052\n","environment/total_reward_pct -7.325768515511053\n","environment/total_cost 0.0\n","environment/total_trades 8903\n","train/episode_reward -0.001579579585530155\n","---------------------------------\n","| explained_variance | -0.314   |\n","| fps                | 148      |\n","| nupdates           | 20400    |\n","| policy_entropy     | 39.2     |\n","| total_timesteps    | 408000   |\n","| value_loss         | 2.15e-06 |\n","---------------------------------\n","environment/nop_value 92319.61977823889\n","environment/total_reward -7680.380221761108\n","environment/total_reward_pct -7.680380221761109\n","environment/total_cost 0.0\n","environment/total_trades 9018\n","train/episode_reward -0.0033640903345061816\n","---------------------------------\n","| explained_variance | -2.16    |\n","| fps                | 148      |\n","| nupdates           | 20500    |\n","| policy_entropy     | 39.3     |\n","| total_timesteps    | 410000   |\n","| value_loss         | 0.000371 |\n","---------------------------------\n","environment/nop_value 94044.77175906388\n","environment/total_reward -5955.228240936121\n","environment/total_reward_pct -5.955228240936122\n","environment/total_cost 0.0\n","environment/total_trades 8947\n","train/episode_reward -0.002574716760464071\n","---------------------------------\n","| explained_variance | -3.98    |\n","| fps                | 148      |\n","| nupdates           | 20600    |\n","| policy_entropy     | 39.4     |\n","| total_timesteps    | 412000   |\n","| value_loss         | 5.45e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.211   |\n","| fps                | 148      |\n","| nupdates           | 20700    |\n","| policy_entropy     | 39.5     |\n","| total_timesteps    | 414000   |\n","| value_loss         | 2.74e-06 |\n","---------------------------------\n","environment/nop_value 92072.56121965572\n","environment/total_reward -7927.4387803442805\n","environment/total_reward_pct -7.92743878034428\n","environment/total_cost 0.0\n","environment/total_trades 9004\n","train/episode_reward -0.0029350200193803177\n","---------------------------------\n","| explained_variance | -0.143   |\n","| fps                | 148      |\n","| nupdates           | 20800    |\n","| policy_entropy     | 39.6     |\n","| total_timesteps    | 416000   |\n","| value_loss         | 0.000433 |\n","---------------------------------\n","environment/nop_value 90923.16216626432\n","environment/total_reward -9076.837833735684\n","environment/total_reward_pct -9.076837833735684\n","environment/total_cost 0.0\n","environment/total_trades 8972\n","train/episode_reward -0.0014517355842064718\n","---------------------------------\n","| explained_variance | 0.134    |\n","| fps                | 148      |\n","| nupdates           | 20900    |\n","| policy_entropy     | 39.7     |\n","| total_timesteps    | 418000   |\n","| value_loss         | 0.00037  |\n","---------------------------------\n","environment/nop_value 92704.76718099898\n","environment/total_reward -7295.232819001016\n","environment/total_reward_pct -7.295232819001016\n","environment/total_cost 0.0\n","environment/total_trades 8838\n","train/episode_reward -0.001194215362748946\n","---------------------------------\n","| explained_variance | -1.09    |\n","| fps                | 148      |\n","| nupdates           | 21000    |\n","| policy_entropy     | 39.8     |\n","| total_timesteps    | 420000   |\n","| value_loss         | 6.07e-05 |\n","---------------------------------\n","step: 2653, episode: 160\n","end_total_asset: 92505.87\n","total_reward: -7494.13\n","total_cost: 0.00\n","total_trades: 8879\n","=================================\n","environment/nop_value 92505.87358978027\n","environment/total_reward -7494.126410219731\n","environment/total_reward_pct -7.494126410219732\n","environment/total_cost 0.0\n","environment/total_trades 8879\n","train/episode_reward -0.0034846731902856845\n","---------------------------------\n","| explained_variance | -0.0779  |\n","| fps                | 148      |\n","| nupdates           | 21100    |\n","| policy_entropy     | 39.9     |\n","| total_timesteps    | 422000   |\n","| value_loss         | 0.000386 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.0426  |\n","| fps                | 148      |\n","| nupdates           | 21200    |\n","| policy_entropy     | 39.9     |\n","| total_timesteps    | 424000   |\n","| value_loss         | 0.000512 |\n","---------------------------------\n","environment/nop_value 93782.06567863113\n","environment/total_reward -6217.93432136887\n","environment/total_reward_pct -6.21793432136887\n","environment/total_cost 0.0\n","environment/total_trades 8928\n","train/episode_reward -0.0029471818814155995\n","---------------------------------\n","| explained_variance | -0.0825  |\n","| fps                | 148      |\n","| nupdates           | 21300    |\n","| policy_entropy     | 40       |\n","| total_timesteps    | 426000   |\n","| value_loss         | 0.00011  |\n","---------------------------------\n","environment/nop_value 92674.9674803567\n","environment/total_reward -7325.032519643297\n","environment/total_reward_pct -7.3250325196432975\n","environment/total_cost 0.0\n","environment/total_trades 8950\n","train/episode_reward -0.002004965557421383\n","---------------------------------\n","| explained_variance | -0.0846  |\n","| fps                | 148      |\n","| nupdates           | 21400    |\n","| policy_entropy     | 40.1     |\n","| total_timesteps    | 428000   |\n","| value_loss         | 0.000184 |\n","---------------------------------\n","environment/nop_value 92574.63490142628\n","environment/total_reward -7425.365098573719\n","environment/total_reward_pct -7.425365098573719\n","environment/total_cost 0.0\n","environment/total_trades 9028\n","train/episode_reward -0.00021703275353793288\n","---------------------------------\n","| explained_variance | 0.0283   |\n","| fps                | 148      |\n","| nupdates           | 21500    |\n","| policy_entropy     | 40.2     |\n","| total_timesteps    | 430000   |\n","| value_loss         | 6.83e-05 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.864   |\n","| fps                | 148      |\n","| nupdates           | 21600    |\n","| policy_entropy     | 40.4     |\n","| total_timesteps    | 432000   |\n","| value_loss         | 0.00052  |\n","---------------------------------\n","environment/nop_value 92517.83753481288\n","environment/total_reward -7482.162465187124\n","environment/total_reward_pct -7.482162465187124\n","environment/total_cost 0.0\n","environment/total_trades 9057\n","train/episode_reward -0.0027191127769096058\n","---------------------------------\n","| explained_variance | -0.0319  |\n","| fps                | 148      |\n","| nupdates           | 21700    |\n","| policy_entropy     | 40.5     |\n","| total_timesteps    | 434000   |\n","| value_loss         | 9.65e-05 |\n","---------------------------------\n","environment/nop_value 91626.32918223497\n","environment/total_reward -8373.670817765029\n","environment/total_reward_pct -8.37367081776503\n","environment/total_cost 0.0\n","environment/total_trades 9014\n","train/episode_reward -0.0018816137649395387\n","---------------------------------\n","| explained_variance | 0.136    |\n","| fps                | 148      |\n","| nupdates           | 21800    |\n","| policy_entropy     | 40.6     |\n","| total_timesteps    | 436000   |\n","| value_loss         | 6.39e-05 |\n","---------------------------------\n","environment/nop_value 92242.51828270967\n","environment/total_reward -7757.481717290328\n","environment/total_reward_pct -7.757481717290328\n","environment/total_cost 0.0\n","environment/total_trades 9007\n","train/episode_reward -0.0020731444321150775\n","---------------------------------\n","| explained_variance | 0.083    |\n","| fps                | 148      |\n","| nupdates           | 21900    |\n","| policy_entropy     | 40.7     |\n","| total_timesteps    | 438000   |\n","| value_loss         | 0.000329 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -7.99    |\n","| fps                | 148      |\n","| nupdates           | 22000    |\n","| policy_entropy     | 40.8     |\n","| total_timesteps    | 440000   |\n","| value_loss         | 9.88e-05 |\n","---------------------------------\n","environment/nop_value 93291.34722955717\n","environment/total_reward -6708.65277044283\n","environment/total_reward_pct -6.70865277044283\n","environment/total_cost 0.0\n","environment/total_trades 8864\n","train/episode_reward -0.0032588744064996717\n","---------------------------------\n","| explained_variance | -0.731   |\n","| fps                | 148      |\n","| nupdates           | 22100    |\n","| policy_entropy     | 40.9     |\n","| total_timesteps    | 442000   |\n","| value_loss         | 0.000134 |\n","---------------------------------\n","environment/nop_value 91962.22295899695\n","environment/total_reward -8037.77704100305\n","environment/total_reward_pct -8.03777704100305\n","environment/total_cost 0.0\n","environment/total_trades 8930\n","train/episode_reward -0.00038208182491653134\n","---------------------------------\n","| explained_variance | -0.0318  |\n","| fps                | 148      |\n","| nupdates           | 22200    |\n","| policy_entropy     | 41       |\n","| total_timesteps    | 444000   |\n","| value_loss         | 6.61e-05 |\n","---------------------------------\n","environment/nop_value 91649.08640766659\n","environment/total_reward -8350.91359233341\n","environment/total_reward_pct -8.350913592333411\n","environment/total_cost 0.0\n","environment/total_trades 9003\n","train/episode_reward -0.003012150112401287\n","---------------------------------\n","| explained_variance | -0.65    |\n","| fps                | 148      |\n","| nupdates           | 22300    |\n","| policy_entropy     | 41       |\n","| total_timesteps    | 446000   |\n","| value_loss         | 0.000124 |\n","---------------------------------\n","---------------------------------\n","| explained_variance | -0.258   |\n","| fps                | 148      |\n","| nupdates           | 22400    |\n","| policy_entropy     | 41.2     |\n","| total_timesteps    | 448000   |\n","| value_loss         | 1.2e-05  |\n","---------------------------------\n","step: 2653, episode: 170\n","end_total_asset: 91727.54\n","total_reward: -8272.46\n","total_cost: 0.00\n","total_trades: 8884\n","=================================\n","environment/nop_value 91727.53720728935\n","environment/total_reward -8272.462792710649\n","environment/total_reward_pct -8.272462792710648\n","environment/total_cost 0.0\n","environment/total_trades 8884\n","train/episode_reward -0.0024236351851839575\n","---------------------------------\n","| explained_variance | -0.164   |\n","| fps                | 148      |\n","| nupdates           | 22500    |\n","| policy_entropy     | 41.3     |\n","| total_timesteps    | 450000   |\n","| value_loss         | 0.000115 |\n","---------------------------------\n","environment/nop_value 93698.84394074013\n","environment/total_reward -6301.156059259869\n","environment/total_reward_pct -6.301156059259869\n","environment/total_cost 0.0\n","environment/total_trades 9022\n","train/episode_reward -0.0011373740932758664\n","---------------------------------\n","| explained_variance | 0.245    |\n","| fps                | 148      |\n","| nupdates           | 22600    |\n","| policy_entropy     | 41.4     |\n","| total_timesteps    | 452000   |\n","| value_loss         | 1.88e-05 |\n","---------------------------------\n","environment/nop_value 93821.56545302003\n","environment/total_reward -6178.434546979974\n","environment/total_reward_pct -6.1784345469799735\n","environment/total_cost 0.0\n","environment/total_trades 9057\n","train/episode_reward -0.003697780664403399\n","---------------------------------\n","| explained_variance | -0.00985 |\n","| fps                | 148      |\n","| nupdates           | 22700    |\n","| policy_entropy     | 41.4     |\n","| total_timesteps    | 454000   |\n","| value_loss         | 8.78e-06 |\n","---------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EeLJ-h8w5bdx"},"source":[" "],"execution_count":null,"outputs":[]}]}